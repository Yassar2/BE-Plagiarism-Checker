url,title,abstract,pdf,clean_text
https://join.if.uinsgd.ac.id/index.php/join/article/view/898,improving indonesian named entity recognition for domain zakat using conditional random fields,"in indonesia, where the majority of the population is muslim, one of the obligations of a muslim is zakat. to reduce illiteracy about zakat among muslims, they need to have access to basic information about it. in order to facilitate the acquisition of this information, this study utilized named entity recognition ner and defined named entity classes for the zakat domain, including the pillars of islam, various types of zakat, and zakat management institutions. the conditional random fields method was used for testing indonesian ner in three scenarios. in the specific context of the zakat domain, ner can extract information about organizations, individuals, and locations involved in collecting and distributing zakat funds. this information can improve the zakat systems efficiency and transparency and support research and analysis on zakat related topics. the average performance evaluation of the indonesian ner model showed a precision of . , recall of . , and an f1 score of . .",,"improving indonesian named entity recognition for domain zakat using conditional random fields. in indonesia, where the majority of the population is muslim, one of the obligations of a muslim is zakat. to reduce illiteracy about zakat among muslims, they need to have access to basic information about it. in order to facilitate the acquisition of this information, this study utilized named entity recognition ner and defined named entity classes for the zakat domain, including the pillars of islam, various types of zakat, and zakat management institutions. the conditional random fields method was used for testing indonesian ner in three scenarios. in the specific context of the zakat domain, ner can extract information about organizations, individuals, and locations involved in collecting and distributing zakat funds. this information can improve the zakat systems efficiency and transparency and support research and analysis on zakat related topics. the average performance evaluation of the indonesian ner model showed a precision of . , recall of . , and an f1 score of . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/959,user experience design and prototypes of mobile based learning media for children with special needs in the dyslexia category,"education is the right of all living things regardless of social status, gender, or physical condition. persons with disabilities have the same rights and obligations as citizens. based on the constitution article paragraph and law number of concerning the national education system, it can be concluded that the state provides full guarantees for children with special needs to obtain quality education services. children with special needs are divided into several categories, in this study the research team will focus on solving learning problems for children with disabilities in the dyslexia category. dyslexia also known as reading disorder, is a disorder characterized by reading below the expected level for one s age. this study aims to find learning solutions by developing user experience designs and prototypes of mobile based learning media for children with special needs in the dyslexia category. this research applies design thinking methodology to understand users, challenge assumptions, redefine problems, and create innovative solutions to prototype and test.",,"user experience design and prototypes of mobile based learning media for children with special needs in the dyslexia category. education is the right of all living things regardless of social status, gender, or physical condition. persons with disabilities have the same rights and obligations as citizens. based on the constitution article paragraph and law number of concerning the national education system, it can be concluded that the state provides full guarantees for children with special needs to obtain quality education services. children with special needs are divided into several categories, in this study the research team will focus on solving learning problems for children with disabilities in the dyslexia category. dyslexia also known as reading disorder, is a disorder characterized by reading below the expected level for one s age. this study aims to find learning solutions by developing user experience designs and prototypes of mobile based learning media for children with special needs in the dyslexia category. this research applies design thinking methodology to understand users, challenge assumptions, redefine problems, and create innovative solutions to prototype and test."
https://join.if.uinsgd.ac.id/index.php/join/article/view/963,implementation of dynamic topic modeling to discover topic evolution on customer reviews,"annotation and analysis of online customer reviews were identified as significant problems in various domains, including business intelligence, marketing, and e governance. in the last decade, various approaches based on topic modeling have been developed to solve this problem. the known solutions, however, often only work well on content with static topics. as a result, it is challenging to analyze customer reviews that include dynamic and constantly expanding collections of short and noisy texts. a method was proposed to handle such dynamic content. the proposed system applied a dynamic topic model using bertopic to monitor topics and word evolution over time. it would help decide when the topic model needs to be retrained to capture emerging topics. several experiments were conducted to test the practicality and effectiveness of the proposed framework. it demonstrated how a dynamic topic model could handle the emergence of new and over time correlated topics in customer review data. as a result, improved performance was achieved compared to the baseline static topic model, with of new segmented texts discovered using the dynamic topic model. experimental results have, therefore, convincingly demonstrated that the proposed framework can be used in practice to develop automatic review annotation tools.",,"implementation of dynamic topic modeling to discover topic evolution on customer reviews. annotation and analysis of online customer reviews were identified as significant problems in various domains, including business intelligence, marketing, and e governance. in the last decade, various approaches based on topic modeling have been developed to solve this problem. the known solutions, however, often only work well on content with static topics. as a result, it is challenging to analyze customer reviews that include dynamic and constantly expanding collections of short and noisy texts. a method was proposed to handle such dynamic content. the proposed system applied a dynamic topic model using bertopic to monitor topics and word evolution over time. it would help decide when the topic model needs to be retrained to capture emerging topics. several experiments were conducted to test the practicality and effectiveness of the proposed framework. it demonstrated how a dynamic topic model could handle the emergence of new and over time correlated topics in customer review data. as a result, improved performance was achieved compared to the baseline static topic model, with of new segmented texts discovered using the dynamic topic model. experimental results have, therefore, convincingly demonstrated that the proposed framework can be used in practice to develop automatic review annotation tools."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1002,artificial neural network for classification task in tabular datasets and image processing a systematic literature review,"artificial neural network ann is one of the machine learning algorithms that is widely used for classification cases. some examples of classification cases that can be handled with ann include classifications in the health sector, banking, and classification in image processing. this study presents a systematic literature review slr of the ann algorithm to find a research gap that can be used in future research. there are phases used in preparing the slr. those are planning, conducting, and reporting. formulation of research questions and establishing a review protocol is carried out in the planning phase. the second phase is conducted. in this phase, searching for relevant articles is carried out, determining the quality of the literature found and selecting particles according to what has been formulated in the planning phase. the selected literature is then carried out by the process of extracting data and information and then synthesizing the data. writing slr articles based on existing findings is carried out in the last phase, namely reporting. the results of data and information extraction from the reviewed articles show that the ann algorithm is powerful enough with satisfactory results to handle classification cases that use tabular datasets or image datasets. the challenges faced are the need for extensive training data so that ann performance can be better, the use of appropriate evaluation measures based on the cases studied does not only rely on accuracy scores, and the determination of the correct hyperparameters to get better performance in the case of image processing.",,"artificial neural network for classification task in tabular datasets and image processing a systematic literature review. artificial neural network ann is one of the machine learning algorithms that is widely used for classification cases. some examples of classification cases that can be handled with ann include classifications in the health sector, banking, and classification in image processing. this study presents a systematic literature review slr of the ann algorithm to find a research gap that can be used in future research. there are phases used in preparing the slr. those are planning, conducting, and reporting. formulation of research questions and establishing a review protocol is carried out in the planning phase. the second phase is conducted. in this phase, searching for relevant articles is carried out, determining the quality of the literature found and selecting particles according to what has been formulated in the planning phase. the selected literature is then carried out by the process of extracting data and information and then synthesizing the data. writing slr articles based on existing findings is carried out in the last phase, namely reporting. the results of data and information extraction from the reviewed articles show that the ann algorithm is powerful enough with satisfactory results to handle classification cases that use tabular datasets or image datasets. the challenges faced are the need for extensive training data so that ann performance can be better, the use of appropriate evaluation measures based on the cases studied does not only rely on accuracy scores, and the determination of the correct hyperparameters to get better performance in the case of image processing."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1073,the impact of data augmentation techniques on the recognition of script images in deep learning models,"deep learning technology is widely used for recognizing character images, including various regional characters and diverse ancient scripts. deep learning models require large data sets to recognize images accurately. however, creating a dataset has limitations in terms of quantity, including the komering script dataset used in this study. data augmentation techniques can be applied to expand the dataset by modifying existing images to increase data diversity. this study aims to investigate the impact of augmentation techniques on the performance of deep learning models in the case of komering script recognition. the dataset consists of images for five classes of komering script characters. three augmentation techniques, namely random rotation, height shift, and width shift, were applied to the five characters, which were then used to test the model trained to recognize characters in the komering dataset. this research contributes to providing insights into the effect of augmentation techniques on robust confidence prediction of deep learning models for recognizing newly augmented data. the results demonstrate that the deep learning model can recognize modified data using augmentation techniques with an average accuracy of . .",,"the impact of data augmentation techniques on the recognition of script images in deep learning models. deep learning technology is widely used for recognizing character images, including various regional characters and diverse ancient scripts. deep learning models require large data sets to recognize images accurately. however, creating a dataset has limitations in terms of quantity, including the komering script dataset used in this study. data augmentation techniques can be applied to expand the dataset by modifying existing images to increase data diversity. this study aims to investigate the impact of augmentation techniques on the performance of deep learning models in the case of komering script recognition. the dataset consists of images for five classes of komering script characters. three augmentation techniques, namely random rotation, height shift, and width shift, were applied to the five characters, which were then used to test the model trained to recognize characters in the komering dataset. this research contributes to providing insights into the effect of augmentation techniques on robust confidence prediction of deep learning models for recognizing newly augmented data. the results demonstrate that the deep learning model can recognize modified data using augmentation techniques with an average accuracy of . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1133,development of augmented reality programming language using agile scrum methodology,"the agile scrum methodology for augmented reality development increases project team efficiency. private campus are frequently confronted with the dilemma of new students with various backgrounds that come not only from vocational high schools but also from high schools. first year students in the informatics study programme come not only from vocational informatics high schools, but also from high schools that specialize in social studies and languages. this is a difficult task in terms of imparting a comprehension of the fundamentals of programming. this study develops augmented reality in order to teach html and javascript. by combining basic principles with gaming, the proposed augmented reality ar makes programming interesting. players must comprehend their programming logic in order to be immersed in a virtual environment by answering coding bug questions. during usability testing, the system usability scale sus assesses user happiness and ar knowledge. participants from various programming backgrounds were tested on their knowledge of programming languages. according to usability research, of people found ar programming languages useful for learning and understanding basic programming languages. ar and agile scrum make programming more enjoyable. this study demonstrates how augmented reality can be used to teach programming languages. these findings imply that agile scrum and ar methods can improve learning and programming foundations. more research and development could lead to more complete and complicated ar learning environments for programming instruction.",,"development of augmented reality programming language using agile scrum methodology. the agile scrum methodology for augmented reality development increases project team efficiency. private campus are frequently confronted with the dilemma of new students with various backgrounds that come not only from vocational high schools but also from high schools. first year students in the informatics study programme come not only from vocational informatics high schools, but also from high schools that specialize in social studies and languages. this is a difficult task in terms of imparting a comprehension of the fundamentals of programming. this study develops augmented reality in order to teach html and javascript. by combining basic principles with gaming, the proposed augmented reality ar makes programming interesting. players must comprehend their programming logic in order to be immersed in a virtual environment by answering coding bug questions. during usability testing, the system usability scale sus assesses user happiness and ar knowledge. participants from various programming backgrounds were tested on their knowledge of programming languages. according to usability research, of people found ar programming languages useful for learning and understanding basic programming languages. ar and agile scrum make programming more enjoyable. this study demonstrates how augmented reality can be used to teach programming languages. these findings imply that agile scrum and ar methods can improve learning and programming foundations. more research and development could lead to more complete and complicated ar learning environments for programming instruction."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1030,designing a virtual campus tour using image stitching techniques to provide information on college entrance test,"the university of bengkulu administers college entrance exams, however some test takers still require assistance in locating the correct room, despite the building being marked. it is crucial to avoid errors in finding the right test room, as it can cause potential students to waste valuable time. therefore, a more precise and practical solution is necessary to provide information on test locations. this study designs a location based virtual tour that offers a degree view, providing information on the location of each building and the conditions inside and outside each test room. the virtual tour encompasses buildings, including test rooms, with to images captured at each location, then stitched together using image stitching techniques. the goal of the virtual tour is to create a comprehensive view of the test location and provide more detailed information on the room s condition. furthermore, the usability of this virtual tour was tested on high school students as potential test participants, utilizing the system usability scale sus to evaluate its effectiveness, resulting in a score of . . in other words, the virtual tour was found to be an effective tool in helping users understand the test location.",,"designing a virtual campus tour using image stitching techniques to provide information on college entrance test. the university of bengkulu administers college entrance exams, however some test takers still require assistance in locating the correct room, despite the building being marked. it is crucial to avoid errors in finding the right test room, as it can cause potential students to waste valuable time. therefore, a more precise and practical solution is necessary to provide information on test locations. this study designs a location based virtual tour that offers a degree view, providing information on the location of each building and the conditions inside and outside each test room. the virtual tour encompasses buildings, including test rooms, with to images captured at each location, then stitched together using image stitching techniques. the goal of the virtual tour is to create a comprehensive view of the test location and provide more detailed information on the room s condition. furthermore, the usability of this virtual tour was tested on high school students as potential test participants, utilizing the system usability scale sus to evaluate its effectiveness, resulting in a score of . . in other words, the virtual tour was found to be an effective tool in helping users understand the test location."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1081,xgboost and convolutional neural network classification models on pronunciation of hijaiyah letters according to sanad,"according to sanad, the pronunciation of hijaiyah letters can serve as a benchmark for correct or valid reading based on the makhraj and properties of the letters. however, the limited number of qur anic sanad teachers remains one of the obstacles to learning the qur an. this study aims to identify the most practical combination of classification models in constructing a voice recognition system that facilitates learning without requiring direct interaction with a teacher. the methods employed include the xgboost algorithm and cnn. as a result, out of the letter trait labels, the cnn model was utilized for of them, specifically for traits s1, s2, s4, s5, t1, t2, t3, t4, t5, and t6, on trait labels s3 and t7 applying the xgboost model. furthermore, the inclusion of additional data yielded performance results for each property, with an average accuracy of . for property s letters with opposing properties , . for property t letters without opposing properties , and an overall average of . per letter.",,"xgboost and convolutional neural network classification models on pronunciation of hijaiyah letters according to sanad. according to sanad, the pronunciation of hijaiyah letters can serve as a benchmark for correct or valid reading based on the makhraj and properties of the letters. however, the limited number of qur anic sanad teachers remains one of the obstacles to learning the qur an. this study aims to identify the most practical combination of classification models in constructing a voice recognition system that facilitates learning without requiring direct interaction with a teacher. the methods employed include the xgboost algorithm and cnn. as a result, out of the letter trait labels, the cnn model was utilized for of them, specifically for traits s1, s2, s4, s5, t1, t2, t3, t4, t5, and t6, on trait labels s3 and t7 applying the xgboost model. furthermore, the inclusion of additional data yielded performance results for each property, with an average accuracy of . for property s letters with opposing properties , . for property t letters without opposing properties , and an overall average of . per letter."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1106,analysis of electrocardiogram dynamic features for arrhythmia classification,"arrhythmia is a deviation from the normal heart rate pattern. arrhythmias are usually harmless, but they can cause heart problems. some types of arrhythmias include atrial fibrillation af , premature atrial contractions pac , and premature ventricular contractions pvc . many studies have been conducted to identify the dynamic characteristics of electrocardiogram ecg irregular waves in the detection of arrhythmias. however, the accuracy obtained in these studies is less than optimal. this study aims to solve the problem by evaluating three main features of arrhythmias using ecg signals rr interval, pr interval, and qrs complex. experiments were conducted rigorously on these three features. the accuracy achieved was . , with a specificity of . and a sensitivity of . .",,"analysis of electrocardiogram dynamic features for arrhythmia classification. arrhythmia is a deviation from the normal heart rate pattern. arrhythmias are usually harmless, but they can cause heart problems. some types of arrhythmias include atrial fibrillation af , premature atrial contractions pac , and premature ventricular contractions pvc . many studies have been conducted to identify the dynamic characteristics of electrocardiogram ecg irregular waves in the detection of arrhythmias. however, the accuracy obtained in these studies is less than optimal. this study aims to solve the problem by evaluating three main features of arrhythmias using ecg signals rr interval, pr interval, and qrs complex. experiments were conducted rigorously on these three features. the accuracy achieved was . , with a specificity of . and a sensitivity of . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1138,implementation of recurrent neural network rnn for question similarity identification in indonesian language,"in a question and answer forum, the identification of question similarity is used to determine how similar two questions are. this procedure makes sure that user submitted questions are compared to the questions in a database for matches to improve system performance on the online q a platform. currently, question similarity is mostly done in foreign languages. the purpose of this research is to identify question similarities and evaluate the effectiveness of the methods used in indonesian language questions. the data used is a public dataset with labeled pairs of questions as and where label for different pairs of questions and label for the same pairs of questions. the method used is a recurrent neural network rnn with the manhattan distance approach to calculate the similarity distance between two questions. the question pairs are taken as two inputs with a reference label to identify the similarity distance between the two question inputs. we evaluated the model using three different optimizers namely rmsprop, adam, and adagrad. the best results were obtained using the adam optimizer with ratio split data and overall accuracy is , precision is , recall is . , and f1 score is . .",,"implementation of recurrent neural network rnn for question similarity identification in indonesian language. in a question and answer forum, the identification of question similarity is used to determine how similar two questions are. this procedure makes sure that user submitted questions are compared to the questions in a database for matches to improve system performance on the online q a platform. currently, question similarity is mostly done in foreign languages. the purpose of this research is to identify question similarities and evaluate the effectiveness of the methods used in indonesian language questions. the data used is a public dataset with labeled pairs of questions as and where label for different pairs of questions and label for the same pairs of questions. the method used is a recurrent neural network rnn with the manhattan distance approach to calculate the similarity distance between two questions. the question pairs are taken as two inputs with a reference label to identify the similarity distance between the two question inputs. we evaluated the model using three different optimizers namely rmsprop, adam, and adagrad. the best results were obtained using the adam optimizer with ratio split data and overall accuracy is , precision is , recall is . , and f1 score is . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1157,automate igp and egp routing protocol configuration using a network automation library,"data communication is sending data from client to client through a computer network. the increasing use of data communication makes computer networks more complex. complex computer networks make it difficult for network administrators to configure them, especially routing protocol configuration. network administrators are in charge of configuring routing protocols and managing networks. in addition, the more devices on the network, the greater the chance of human error from the administrator. therefore, network automation is one solution that helps network administrators overcome this. this study focuses on analyzing the performance of network automation using the paramiko and telnetlib libraries. the routing protocol used by ospf for igp and bgp for egp. the scenario in this study involves configuring ip addresses and configuring ospf and bgp routing. based on the test results, the telnetlib library is better than the paramiko library in terms of script delivery time, convergence time, and delay by . when applied to the igp and egp routing protocols.",,"automate igp and egp routing protocol configuration using a network automation library. data communication is sending data from client to client through a computer network. the increasing use of data communication makes computer networks more complex. complex computer networks make it difficult for network administrators to configure them, especially routing protocol configuration. network administrators are in charge of configuring routing protocols and managing networks. in addition, the more devices on the network, the greater the chance of human error from the administrator. therefore, network automation is one solution that helps network administrators overcome this. this study focuses on analyzing the performance of network automation using the paramiko and telnetlib libraries. the routing protocol used by ospf for igp and bgp for egp. the scenario in this study involves configuring ip addresses and configuring ospf and bgp routing. based on the test results, the telnetlib library is better than the paramiko library in terms of script delivery time, convergence time, and delay by . when applied to the igp and egp routing protocols."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1180,yolov5 and u net based character detection for nusantara script,"indonesia boasts a diverse range of indigenous scripts, called nusantara scripts, which encompass bali, batak, bugis, javanese, kawi, kerinci, lampung, pallava, rejang, and sundanese scripts. however, prevailing character detection techniques predominantly cater to latin or chinese scripts. in an extension of our prior work, which concentrated on the classification of script types and character recognition within nusantara script systems, this study advances our research by integrating object detection techniques, employing the yolov5 model, and enhancing performance through the incorporation of the u net model to facilitate the pinpointing of fundamental nusantara script s character locations within input document images. subsequently, our investigation delves into rearranging these character positions in alignment with the distinctive styles of nusantara scripts. experimental results reveal yolov5 s performance, yielding a loss rate of approximately . in character location detection. concurrently, the u net model exhibits an accuracy ranging from to for predicting character regions. while yolov5 may not achieve flawless detection of all nusantara scripts, integrating the u net model significantly enhances the detection rate by . .",,"yolov5 and u net based character detection for nusantara script. indonesia boasts a diverse range of indigenous scripts, called nusantara scripts, which encompass bali, batak, bugis, javanese, kawi, kerinci, lampung, pallava, rejang, and sundanese scripts. however, prevailing character detection techniques predominantly cater to latin or chinese scripts. in an extension of our prior work, which concentrated on the classification of script types and character recognition within nusantara script systems, this study advances our research by integrating object detection techniques, employing the yolov5 model, and enhancing performance through the incorporation of the u net model to facilitate the pinpointing of fundamental nusantara script s character locations within input document images. subsequently, our investigation delves into rearranging these character positions in alignment with the distinctive styles of nusantara scripts. experimental results reveal yolov5 s performance, yielding a loss rate of approximately . in character location detection. concurrently, the u net model exhibits an accuracy ranging from to for predicting character regions. while yolov5 may not achieve flawless detection of all nusantara scripts, integrating the u net model significantly enhances the detection rate by . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1205,"classification of bulughul maraam categories prohibitions, recommendations, and information using extreme learning machine and fasttext","hadith is the second source of islamic law after the quran. after the hadiths were compiled, imam of hadith created collections of hadiths, one of which is imam bukhari who compiled the book bulughul maraam, which is considered to have the highest level of authenticity. digital collections of hadiths can now be found in the form of e books and web pages, which help in the search for hadiths. the classification of hadiths is necessary to organize them by category, making it easier to search for hadiths based on their categories. text mining is needed to classify hadiths because it can identify patterns in unstructured text. this research aims to improve the accuracy of classifying recommended, prohibited, and informational hadiths using a dataset of hadiths, which consists of primary data taken from the book bulughul maraam in the indonesian language. previously, similar research was conducted in that classified recommended, prohibited, and obligatory hadiths with an accuracy of , but only for sahih bukhari hadiths. in this research, the same classification categories will be examined, proposing a different method, namely the extreme learning machine method and word2vec fasttext for text representation with a larger dataset. the results of this research show a model accuracy of . , precision, and recall, indicating that the proposed model performs well in classifying hadiths.",,"classification of bulughul maraam categories prohibitions, recommendations, and information using extreme learning machine and fasttext. hadith is the second source of islamic law after the quran. after the hadiths were compiled, imam of hadith created collections of hadiths, one of which is imam bukhari who compiled the book bulughul maraam, which is considered to have the highest level of authenticity. digital collections of hadiths can now be found in the form of e books and web pages, which help in the search for hadiths. the classification of hadiths is necessary to organize them by category, making it easier to search for hadiths based on their categories. text mining is needed to classify hadiths because it can identify patterns in unstructured text. this research aims to improve the accuracy of classifying recommended, prohibited, and informational hadiths using a dataset of hadiths, which consists of primary data taken from the book bulughul maraam in the indonesian language. previously, similar research was conducted in that classified recommended, prohibited, and obligatory hadiths with an accuracy of , but only for sahih bukhari hadiths. in this research, the same classification categories will be examined, proposing a different method, namely the extreme learning machine method and word2vec fasttext for text representation with a larger dataset. the results of this research show a model accuracy of . , precision, and recall, indicating that the proposed model performs well in classifying hadiths."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1193,retweet prediction using multi layer perceptron optimized by the swarm intelligence algorithm,"retweets are a way to spread information on twitter. a tweet is affected by several features which determine whether a tweet will be retweeted or not. in this research, we discuss the features that influence the spread of a tweet. these features are user based, time based and content based. user based features are related to the user who tweeted, time based features are related to when the tweet was uploaded, while content based features are features related to the content of the tweet. the classifier used to predict whether a tweet will be retweeted is multi layer perceptron mlp and mlp which is optimized by the swarm intelligence algorithm. in this research, data from indonesian twitter users with the hashtag fifa u was used. the results of this research show that the most influential feature in determining whether a tweet will be retweeted or not is the content based feature. furthermore, it was found that the mlp optimized with the swarm intelligence algorithm had better performance compared to the mlp.",,"retweet prediction using multi layer perceptron optimized by the swarm intelligence algorithm. retweets are a way to spread information on twitter. a tweet is affected by several features which determine whether a tweet will be retweeted or not. in this research, we discuss the features that influence the spread of a tweet. these features are user based, time based and content based. user based features are related to the user who tweeted, time based features are related to when the tweet was uploaded, while content based features are features related to the content of the tweet. the classifier used to predict whether a tweet will be retweeted is multi layer perceptron mlp and mlp which is optimized by the swarm intelligence algorithm. in this research, data from indonesian twitter users with the hashtag fifa u was used. the results of this research show that the most influential feature in determining whether a tweet will be retweeted or not is the content based feature. furthermore, it was found that the mlp optimized with the swarm intelligence algorithm had better performance compared to the mlp."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1196,optimizing yolov8 for real time cctv surveillance a trade off between speed and accuracy,"real time video surveillance, especially cctv systems, requires fast and accurate face detection. object detection models with slow inference times are ineffective in real time. this study addresses this challenge by improving the inference speed of the yolov8 model, a leading object detection framework known for its accuracy and speed. we focus on pruning the model s architecture, particularly the p5 head section, which detects larger objects. according to bochkovskiy s research, this modification enhances the model s performance specifically for medium and small objects in cctv footage. the standard yolov8 model and its modified version were compared for inference time, mean average precision map , and model weight. the pruned yolov8 model cuts inference time by . , from . ms to . ms, and reduces model weight. the advantages mentioned above are offset by a . decrease in mean average precision. this research advances object detection technology by demonstrating architectural modifications efficacy. these changes make the model faster and lighter, making it suitable for real time surveillance. the accuracy trade off is slight. the implications of these findings are crucial for implementing efficient object detection systems in cctv surveillance. these findings also lay the groundwork for future research to improve such systems speed accuracy trade off.",,"optimizing yolov8 for real time cctv surveillance a trade off between speed and accuracy. real time video surveillance, especially cctv systems, requires fast and accurate face detection. object detection models with slow inference times are ineffective in real time. this study addresses this challenge by improving the inference speed of the yolov8 model, a leading object detection framework known for its accuracy and speed. we focus on pruning the model s architecture, particularly the p5 head section, which detects larger objects. according to bochkovskiy s research, this modification enhances the model s performance specifically for medium and small objects in cctv footage. the standard yolov8 model and its modified version were compared for inference time, mean average precision map , and model weight. the pruned yolov8 model cuts inference time by . , from . ms to . ms, and reduces model weight. the advantages mentioned above are offset by a . decrease in mean average precision. this research advances object detection technology by demonstrating architectural modifications efficacy. these changes make the model faster and lighter, making it suitable for real time surveillance. the accuracy trade off is slight. the implications of these findings are crucial for implementing efficient object detection systems in cctv surveillance. these findings also lay the groundwork for future research to improve such systems speed accuracy trade off."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1031,regression analysis for crop production using clarans algorithm,"crop production rate relies on rainfall over rejang lebong district. data showed a discrepancy between increased crop production and rainfall in rejang lebong district. however, the spatiotemporal distribution of the crop variable s dependencies remains unclear. this study analyses the relationship between rainfall and crop production rate in the rejang lebong district based on the performance of the machine learning method. in addition, this research also performed regression analysis to carry out rainfall clusters and crop production. this order provides information in the form of cluster results to determine how much the rainfall variable influences the crop production rate in each cluster. harnessing the elbow, clarans, simple linear regression, and silhouette coefficient methods, this study used rainfall data sourced from the bengkulu bmkg and data for plant production obtained from bps bengkulu province from . this research found that the optimal clusters were clusters. c1 contains data with the largest regression value for chili . , c2 contains data with the largest regression value for mustard greens . , and c3 contains data with the largest regression value for cabbage . , eggplant . , and carrots . . furthermore, this research also found that the biggest correlation of crops with highly significant improvement would be cabbage commodity y .4114x . and chili plantation with high rsme . .",,"regression analysis for crop production using clarans algorithm. crop production rate relies on rainfall over rejang lebong district. data showed a discrepancy between increased crop production and rainfall in rejang lebong district. however, the spatiotemporal distribution of the crop variable s dependencies remains unclear. this study analyses the relationship between rainfall and crop production rate in the rejang lebong district based on the performance of the machine learning method. in addition, this research also performed regression analysis to carry out rainfall clusters and crop production. this order provides information in the form of cluster results to determine how much the rainfall variable influences the crop production rate in each cluster. harnessing the elbow, clarans, simple linear regression, and silhouette coefficient methods, this study used rainfall data sourced from the bengkulu bmkg and data for plant production obtained from bps bengkulu province from . this research found that the optimal clusters were clusters. c1 contains data with the largest regression value for chili . , c2 contains data with the largest regression value for mustard greens . , and c3 contains data with the largest regression value for cabbage . , eggplant . , and carrots . . furthermore, this research also found that the biggest correlation of crops with highly significant improvement would be cabbage commodity y .4114x . and chili plantation with high rsme . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/977,scalability testing of land forest fire patrol information systems,"the patrol information system for the prevention of forest land fires sipp karhutla in indonesia is a tool for assisting patrol activities for controlling forest and land fires in indonesia. the addition of karhutla sipp users causes the need for system scalability testing. this study aims to perform non functional testing that focuses on scalability testing. the steps in scalability testing include creating schemas, conducting tests, and analyzing results. there are five schemes with a total sample of samples. testing was carried out using the jmeter automation testing tool assisted by blazemeter in creating scripts. the scalability test parameter has three parameters average cpu usage, memory usage, and network usage. the test results show that the cpu capacity used can handle up to users, while with a memory capacity of 8gb it can handle up to users. all users is the user menu that has the highest value for each test parameter the average value of cpu usage is . , the average memory usage is . and the average network usage is . mb s. in minimizing server performance, the tile cache map method can be applied to the system and can increase the memory capacity used.",,"scalability testing of land forest fire patrol information systems. the patrol information system for the prevention of forest land fires sipp karhutla in indonesia is a tool for assisting patrol activities for controlling forest and land fires in indonesia. the addition of karhutla sipp users causes the need for system scalability testing. this study aims to perform non functional testing that focuses on scalability testing. the steps in scalability testing include creating schemas, conducting tests, and analyzing results. there are five schemes with a total sample of samples. testing was carried out using the jmeter automation testing tool assisted by blazemeter in creating scripts. the scalability test parameter has three parameters average cpu usage, memory usage, and network usage. the test results show that the cpu capacity used can handle up to users, while with a memory capacity of 8gb it can handle up to users. all users is the user menu that has the highest value for each test parameter the average value of cpu usage is . , the average memory usage is . and the average network usage is . mb s. in minimizing server performance, the tile cache map method can be applied to the system and can increase the memory capacity used."
https://join.if.uinsgd.ac.id/index.php/join/article/view/911,social network analysis identification of communication and information dissemination case study of holywings,"social media especially twitter has been used by corporation or organization as an effective tool to interact and communicate with the consumers. holywings is one of the popular restaurants in indonesia that use social media as a tool to promote and disseminate information regarding their products and services. however, one of their promotional items has gone viral and invited public protests which turned into a trending topic on twitter for a couple of weeks. holywings allegedly improperly promoted their products by using the most honorable names, muhammad and maria. social network analysis of twitter data is conducted to identify and examine information circulating among the users, which leads to wider public attention and law enforcement. in this study, we focused on the conversation about holywings on twitter from june to july . the analysis was carried out using python to retrieve data and gephi software to visualize the interactions and the intensity of the network group in viewing the spread of information. the findings reveal the centrality account that caused the news to go viral are the cnn indonesia cnnindonesia news media account and haris pertama knpiharis , with a centrality of . and . , respectively. there are also groups involved in the conversation with modularity of . .",,"social network analysis identification of communication and information dissemination case study of holywings. social media especially twitter has been used by corporation or organization as an effective tool to interact and communicate with the consumers. holywings is one of the popular restaurants in indonesia that use social media as a tool to promote and disseminate information regarding their products and services. however, one of their promotional items has gone viral and invited public protests which turned into a trending topic on twitter for a couple of weeks. holywings allegedly improperly promoted their products by using the most honorable names, muhammad and maria. social network analysis of twitter data is conducted to identify and examine information circulating among the users, which leads to wider public attention and law enforcement. in this study, we focused on the conversation about holywings on twitter from june to july . the analysis was carried out using python to retrieve data and gephi software to visualize the interactions and the intensity of the network group in viewing the spread of information. the findings reveal the centrality account that caused the news to go viral are the cnn indonesia cnnindonesia news media account and haris pertama knpiharis , with a centrality of . and . , respectively. there are also groups involved in the conversation with modularity of . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1000,run length encoding compresion on virtual tour campus to enhance load access performance,"virtual tour is one of the rapidly growing applications of multimedia technology which is used for various purposes, including the dissemination of information in an interesting way. the education sector is also not spared from using virtual tour media for promotional purposes, and campuses are no exception to this rule. large virtual tour content causes high access speed, ultimately reducing the level of comfort experienced by users. this study aims to compress panoramic images displayed on a campus virtual tour using a lossless compression method and the run length encoding rle algorithm. first, panoramic images are combined into one, then individual images are compressed. when recreating a virtual campus tour, compressed images are used so that the amount of data transferred is smaller. the load access speed index increases from , seconds to , seconds when images are compressed from bits to bits, with a compression percentage of . the findings from this research are that the rle algorithm has not been able to compress large files effectively even though it is quite successful in increasing the load access of the virtual tour website.",,"run length encoding compresion on virtual tour campus to enhance load access performance. virtual tour is one of the rapidly growing applications of multimedia technology which is used for various purposes, including the dissemination of information in an interesting way. the education sector is also not spared from using virtual tour media for promotional purposes, and campuses are no exception to this rule. large virtual tour content causes high access speed, ultimately reducing the level of comfort experienced by users. this study aims to compress panoramic images displayed on a campus virtual tour using a lossless compression method and the run length encoding rle algorithm. first, panoramic images are combined into one, then individual images are compressed. when recreating a virtual campus tour, compressed images are used so that the amount of data transferred is smaller. the load access speed index increases from , seconds to , seconds when images are compressed from bits to bits, with a compression percentage of . the findings from this research are that the rle algorithm has not been able to compress large files effectively even though it is quite successful in increasing the load access of the virtual tour website."
https://join.if.uinsgd.ac.id/index.php/join/article/view/917,the implementation of restricted boltzmann machine in choosing a specialization for informatics students,"choosing a specialization was not an easy task for some students, especially for those who lacked confidence in their skill and ability. specialization in tertiary education became the benchmark and key to success for students future careers. this study was conducted to provide the learning outcomes record, which showed the specialization classification for the informatics students by using the data from the students of who had graduated. the total data was students. the classification method used for this study was the restricted boltzmann machine rbm . however, the data showed imbalanced class distribution because the number of each field differed greatly. therefore, smote was added to classify the imbalanced class. the accuracy obtained from the combination of rbm and smote was with a . mean squared error.",,"the implementation of restricted boltzmann machine in choosing a specialization for informatics students. choosing a specialization was not an easy task for some students, especially for those who lacked confidence in their skill and ability. specialization in tertiary education became the benchmark and key to success for students future careers. this study was conducted to provide the learning outcomes record, which showed the specialization classification for the informatics students by using the data from the students of who had graduated. the total data was students. the classification method used for this study was the restricted boltzmann machine rbm . however, the data showed imbalanced class distribution because the number of each field differed greatly. therefore, smote was added to classify the imbalanced class. the accuracy obtained from the combination of rbm and smote was with a . mean squared error."
https://join.if.uinsgd.ac.id/index.php/join/article/view/790,implementation of generative adversarial network to generate fake face image,"in recent years, many crimes use technology to generate someone s face which has a bad effect on that person. generative adversarial network is a method to generate fake images using discriminators and generators. conventional gan involved binary cross entropy loss for discriminator training to classify original image from dataset and fake image that generated from generator. however, use of binary cross entropy loss cannot provided gradient information to generator in creating a good fake image. when generator creates a fake image, discriminator only gives a little feedback gradient information to generator update its model. it causes generator take a long time to update the model. to solve this problem, there is an lsgan that used a loss function least squared loss . discriminator can provide astrong gradient signal to generator update the model even though image was far from decision boundary. in making fake images, researchers used least squares gan lsgan with discriminator loss value is . , discriminator loss value is . , and generator loss value is . . with the small loss value of the three important components, discriminator accuracy value in terms of classification reaches for original image and for fake image. in classified original image and fake image in this studyusing a supervised contrastive loss classification model with an accuracy value of . .",,"implementation of generative adversarial network to generate fake face image. in recent years, many crimes use technology to generate someone s face which has a bad effect on that person. generative adversarial network is a method to generate fake images using discriminators and generators. conventional gan involved binary cross entropy loss for discriminator training to classify original image from dataset and fake image that generated from generator. however, use of binary cross entropy loss cannot provided gradient information to generator in creating a good fake image. when generator creates a fake image, discriminator only gives a little feedback gradient information to generator update its model. it causes generator take a long time to update the model. to solve this problem, there is an lsgan that used a loss function least squared loss . discriminator can provide astrong gradient signal to generator update the model even though image was far from decision boundary. in making fake images, researchers used least squares gan lsgan with discriminator loss value is . , discriminator loss value is . , and generator loss value is . . with the small loss value of the three important components, discriminator accuracy value in terms of classification reaches for original image and for fake image. in classified original image and fake image in this studyusing a supervised contrastive loss classification model with an accuracy value of . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1007,catbreedsnet an android application for cat breed classification using convolutional neural networks,"there are so many cat races in the world. ignorance in recognizing cat breeds will be dangerous if the cat being kept is affected by a disease, which allows mishandling of the cat being kept. in addition, many cat breeds have different foods from one race to another. the problem is that a cat caretaker cannot easily recognize the cat breed. therefore, technology needs to help a cat caretaker to treat cats appropriately. in this study, we proposed a machine learning approach to recognize cat breeds. this study aims to identify the cat breed from the cat images then deployed on an android smartphone. it was tested with data from cat images of races. the classification method applied in this study uses the convolutional neural network cnn algorithm using transfer learning. the base models tested are mobilenetv2, vgg16, and inceptionv3. the results tested using several models and through several experimental scenarios produced the best classification model with an accuracy of with mobilenetv2. the model with the best accuracy is then embedded in an application with the android operating system. then the application is named catbreednet.",,"catbreedsnet an android application for cat breed classification using convolutional neural networks. there are so many cat races in the world. ignorance in recognizing cat breeds will be dangerous if the cat being kept is affected by a disease, which allows mishandling of the cat being kept. in addition, many cat breeds have different foods from one race to another. the problem is that a cat caretaker cannot easily recognize the cat breed. therefore, technology needs to help a cat caretaker to treat cats appropriately. in this study, we proposed a machine learning approach to recognize cat breeds. this study aims to identify the cat breed from the cat images then deployed on an android smartphone. it was tested with data from cat images of races. the classification method applied in this study uses the convolutional neural network cnn algorithm using transfer learning. the base models tested are mobilenetv2, vgg16, and inceptionv3. the results tested using several models and through several experimental scenarios produced the best classification model with an accuracy of with mobilenetv2. the model with the best accuracy is then embedded in an application with the android operating system. then the application is named catbreednet."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1051,malware image classification using deep learning inceptionresnet v2 and vgg method,"malware is intentionally designed to damage computers, servers, clients or computer networks. malware is a general term used to describe any program designed to harm a computer or server. the goal is to commit a crime, such as gaining unauthorized access to a particular system, so as to compromise user security. most malware still uses the same code to produce another different form of malware variants. therefore, the ability to classify similar malware variant characteristics into malware families is a good strategy to stop malware. the research is useful for classifying malware on malware samples presented as bytemap grayscale images. the malware classification research focused on malware classes with a total of , images from the malimg dataset. this research implements the vgg and inceptionresnet v2 architectures by running different scenarios, scenario uses the original dataset and the other scenario uses the undersampled dataset. after building the model, each scenario will get an evaluation form such as accuracy, precision, recall, and f1 score. the highest score was obtained in scenario on the vgg method with a score of . and the lowest in scenario on the inceptionresnet v2 method with a score of . .",,"malware image classification using deep learning inceptionresnet v2 and vgg method. malware is intentionally designed to damage computers, servers, clients or computer networks. malware is a general term used to describe any program designed to harm a computer or server. the goal is to commit a crime, such as gaining unauthorized access to a particular system, so as to compromise user security. most malware still uses the same code to produce another different form of malware variants. therefore, the ability to classify similar malware variant characteristics into malware families is a good strategy to stop malware. the research is useful for classifying malware on malware samples presented as bytemap grayscale images. the malware classification research focused on malware classes with a total of , images from the malimg dataset. this research implements the vgg and inceptionresnet v2 architectures by running different scenarios, scenario uses the original dataset and the other scenario uses the undersampled dataset. after building the model, each scenario will get an evaluation form such as accuracy, precision, recall, and f1 score. the highest score was obtained in scenario on the vgg method with a score of . and the lowest in scenario on the inceptionresnet v2 method with a score of . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1035,comparative analysis of machine learning based forest fire characteristics in sumatra and borneo,"sumatra and borneo are areas consisting of rainforests with a high vulnerability to fire. both areas are in the tropics which experience rainy and dry seasons annually. the long dry season such as in triggered forest and land fires in borneo and sumatra, causing haze disasters in the exposed areas. this indicates that climate variables play a role in burning forests and land in borneo and sumatra, but how climate affects the fires in both areas is still questionable. this study investigates the climate variables temperature, humidity, precipitation, and wind speed in relation to the fires characteristics in borneo and sumatra. we use the random forest model to determine the characteristics of forest fires in sumatra and borneo based on the climate variables and carbon emission levels. according to the model, the fire event in sumatra is slightly better predicted than in borneo, indicating a climate fire dependence is more prominent in sumatra. nevertheless, a maximum temperature variable is seemingly an important indicator for forest and land fire in both domains as it gives the largest contribution to the carbon emission.",,"comparative analysis of machine learning based forest fire characteristics in sumatra and borneo. sumatra and borneo are areas consisting of rainforests with a high vulnerability to fire. both areas are in the tropics which experience rainy and dry seasons annually. the long dry season such as in triggered forest and land fires in borneo and sumatra, causing haze disasters in the exposed areas. this indicates that climate variables play a role in burning forests and land in borneo and sumatra, but how climate affects the fires in both areas is still questionable. this study investigates the climate variables temperature, humidity, precipitation, and wind speed in relation to the fires characteristics in borneo and sumatra. we use the random forest model to determine the characteristics of forest fires in sumatra and borneo based on the climate variables and carbon emission levels. according to the model, the fire event in sumatra is slightly better predicted than in borneo, indicating a climate fire dependence is more prominent in sumatra. nevertheless, a maximum temperature variable is seemingly an important indicator for forest and land fire in both domains as it gives the largest contribution to the carbon emission."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1055,implementation of ant colony optimization artificial neural network in predicting the activity of indenopyrazole derivative as anti cancer agent,"cancer is a disease induced by the abnormal growth of cells in body tissues. this disease is commonly treated by chemotherapy. however, at first, cancer cells can respond to the activity of chemotherapy over time, but over time, resistance to cancer cells appears. therefore, it is required to develop new anti cancer drugs. indenopyrazole and its derivative have been investigated to be a potential drug to treat cancer. this study aims to predict indenopyrazole derivative compounds as anti cancer drugs by using ant colony optimization aco and artificial neural network ann methods. we used compounds of indenopyrazole derivative with a total of descriptors. then, the descriptors were reduced by using the pearson correlation coefficient pcc and followed by the aco algorithm to get the most relevant features. we found that the best number of descriptors obtained from aco is ten descriptors. the ann prediction model was developed with three architectures, which are different in hidden layer number, i.e., , , and hidden layers. based on the results, we found that the model with three hidden layers gives the best performance, with the value of the r2 test, r2 train, and q2 train being . , . , and . , respectively.",,"implementation of ant colony optimization artificial neural network in predicting the activity of indenopyrazole derivative as anti cancer agent. cancer is a disease induced by the abnormal growth of cells in body tissues. this disease is commonly treated by chemotherapy. however, at first, cancer cells can respond to the activity of chemotherapy over time, but over time, resistance to cancer cells appears. therefore, it is required to develop new anti cancer drugs. indenopyrazole and its derivative have been investigated to be a potential drug to treat cancer. this study aims to predict indenopyrazole derivative compounds as anti cancer drugs by using ant colony optimization aco and artificial neural network ann methods. we used compounds of indenopyrazole derivative with a total of descriptors. then, the descriptors were reduced by using the pearson correlation coefficient pcc and followed by the aco algorithm to get the most relevant features. we found that the best number of descriptors obtained from aco is ten descriptors. the ann prediction model was developed with three architectures, which are different in hidden layer number, i.e., , , and hidden layers. based on the results, we found that the model with three hidden layers gives the best performance, with the value of the r2 test, r2 train, and q2 train being . , . , and . , respectively."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1027,data mining for heart disease prediction based on echocardiogram and electrocardiogram data,"traditional methods of detecting cardiac illness are often problematic in the medical field. the doctor must next study and interpret the findings of the patient s medical record received from the electrocardiogram and echocardiogram. these tasks often take a long time and require patience. the use of computational technology in medicine, especially the study of cardiac disease, is not new. scientists are continuously striving for the most reliable method of diagnosing a patient s cardiac illness, particularly when an integrated system is constructed. the study attempted to propose an alternative for identifying cardiac illness using a supervised learning technique, namely the multi layer perceptron mlp . the study started with the collection of patient medical record data, which yielded up to data points, followed by pre processing and transformation to provide up to data points suitable to be employed by learning algorithms. the last step is to create a heart disease classification model with distinct activation functions using mlp. the degree of classification accuracy, k fold cross validation, and bootstrap are all used to test the model. according to the findings of the study, mlp with the tanh activation function is a more accurate prediction model than logistics and relu. the classification accuracy level ca for mlp with tanh and k fold cross validation is . in a data sharing situation, while it is . with bootstrap. mlp using the tanh activation function is the best model based on the ca level and the auc value, with values of . k fold cross validation and . bootstrap .",,"data mining for heart disease prediction based on echocardiogram and electrocardiogram data. traditional methods of detecting cardiac illness are often problematic in the medical field. the doctor must next study and interpret the findings of the patient s medical record received from the electrocardiogram and echocardiogram. these tasks often take a long time and require patience. the use of computational technology in medicine, especially the study of cardiac disease, is not new. scientists are continuously striving for the most reliable method of diagnosing a patient s cardiac illness, particularly when an integrated system is constructed. the study attempted to propose an alternative for identifying cardiac illness using a supervised learning technique, namely the multi layer perceptron mlp . the study started with the collection of patient medical record data, which yielded up to data points, followed by pre processing and transformation to provide up to data points suitable to be employed by learning algorithms. the last step is to create a heart disease classification model with distinct activation functions using mlp. the degree of classification accuracy, k fold cross validation, and bootstrap are all used to test the model. according to the findings of the study, mlp with the tanh activation function is a more accurate prediction model than logistics and relu. the classification accuracy level ca for mlp with tanh and k fold cross validation is . in a data sharing situation, while it is . with bootstrap. mlp using the tanh activation function is the best model based on the ca level and the auc value, with values of . k fold cross validation and . bootstrap ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1062,classification of stunting in children using the c4. algorithm,"stunting is a disease caused by malnutrition in children, which results in slow growth. generally, stunting is characterized by a lack of weight and height in young children. this study aims to classify stunting in children aged months using the decision tree c4. method based on z score calculations with a sample size of records, consisting of attributes and label, namely gender, age, weight, height, and nutritional status. the results of the study obtained a c4. decision tree where the age variable influenced the classification of stunting with the highest gain ratio of . . meanwhile, the evaluation of the model using the confusion matrix resulted in the highest accuracy of . and auc of . .",,"classification of stunting in children using the c4. algorithm. stunting is a disease caused by malnutrition in children, which results in slow growth. generally, stunting is characterized by a lack of weight and height in young children. this study aims to classify stunting in children aged months using the decision tree c4. method based on z score calculations with a sample size of records, consisting of attributes and label, namely gender, age, weight, height, and nutritional status. the results of the study obtained a c4. decision tree where the age variable influenced the classification of stunting with the highest gain ratio of . . meanwhile, the evaluation of the model using the confusion matrix resulted in the highest accuracy of . and auc of . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1037,multi step vector output prediction of time series using ema lstm,"this research paper proposes a novel method, exponential moving average long short term memory ema lstm , for multi step vector output prediction of time series data using deep learning. the method combines the lstm with the exponential moving average ema technique to reduce noise in the data and improve the accuracy of prediction. the research compares the performance of ema lstm to other commonly used deep learning models, including lstm, gru, rnn, and cnn, and evaluates the results using statistical tests. the dataset used in this study contains daily stock market prices for several years, with inputs of , , and previous days, and predictions for the next and days. the results show that the ema lstm method outperforms other models in terms of accuracy, with lower rmse and mape values. this study has important implications for real world applications, such as stock market forecasting and climate prediction, and highlights the importance of careful preprocessing of the data to improve the performance of deep learning models.",,"multi step vector output prediction of time series using ema lstm. this research paper proposes a novel method, exponential moving average long short term memory ema lstm , for multi step vector output prediction of time series data using deep learning. the method combines the lstm with the exponential moving average ema technique to reduce noise in the data and improve the accuracy of prediction. the research compares the performance of ema lstm to other commonly used deep learning models, including lstm, gru, rnn, and cnn, and evaluates the results using statistical tests. the dataset used in this study contains daily stock market prices for several years, with inputs of , , and previous days, and predictions for the next and days. the results show that the ema lstm method outperforms other models in terms of accuracy, with lower rmse and mape values. this study has important implications for real world applications, such as stock market forecasting and climate prediction, and highlights the importance of careful preprocessing of the data to improve the performance of deep learning models."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1075,texture analysis of citrus leaf images using bemd for huanglongbing disease diagnosis,"plant diseases significantly threaten agricultural productivity, necessitating accurate identification and classification of plant lesions for improved crop quality. citrus plants, belonging to the rutaceae family, are highly susceptible to diseases such as citrus canker, black spot, and the devastating huanglongbing hlb disease. traditional approaches for disease detection rely on expert knowledge and time consuming laboratory tests, which hinder rapid and effective disease management. therefore, this study explores an alternative method that combines the bidimensional empirical mode decomposition bemd algorithm for texture feature extraction and support vector machine svm classification to improve hlb diagnosis. the bemd algorithm decomposes citrus leaf images into intrinsic mode functions imfs and a residue component. classification experiments were conducted using svm on the imfs and residue features. the results of the classification experiments demonstrate the effectiveness of the proposed method. the achieved classification accuracies, ranging from to for different numbers of classes, the results show that the residue component achieved the highest classification accuracy, outperforming the imf features. the combination of the bemd algorithm and svm classification presents a promising approach for accurate hlb diagnosis, surpassing the performance of previous studies that utilized glcm svm techniques. this research contributes to developing efficient and reliable methods for early detection and classification of hlb infected plants, essential for effective disease management and maintaining agricultural productivity.",,"texture analysis of citrus leaf images using bemd for huanglongbing disease diagnosis. plant diseases significantly threaten agricultural productivity, necessitating accurate identification and classification of plant lesions for improved crop quality. citrus plants, belonging to the rutaceae family, are highly susceptible to diseases such as citrus canker, black spot, and the devastating huanglongbing hlb disease. traditional approaches for disease detection rely on expert knowledge and time consuming laboratory tests, which hinder rapid and effective disease management. therefore, this study explores an alternative method that combines the bidimensional empirical mode decomposition bemd algorithm for texture feature extraction and support vector machine svm classification to improve hlb diagnosis. the bemd algorithm decomposes citrus leaf images into intrinsic mode functions imfs and a residue component. classification experiments were conducted using svm on the imfs and residue features. the results of the classification experiments demonstrate the effectiveness of the proposed method. the achieved classification accuracies, ranging from to for different numbers of classes, the results show that the residue component achieved the highest classification accuracy, outperforming the imf features. the combination of the bemd algorithm and svm classification presents a promising approach for accurate hlb diagnosis, surpassing the performance of previous studies that utilized glcm svm techniques. this research contributes to developing efficient and reliable methods for early detection and classification of hlb infected plants, essential for effective disease management and maintaining agricultural productivity."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1070,digital image processing using ycbcr colour space and neuro fuzzy to identify pornography,"pornography is a severe problem in indonesia, apart from drugs. this can be seen based on data from the ministry of communication and informatics in which found . million pornographic content online. the increasing number of access to pornographic content sites on the internet can prove this. several studies have been conducted to produce preventive formulas. however, this research flow has not been effective in solving the problem. this is because the results of the identification value in the output image obtained are not quite right. this study proposes a procedure for identifying pornographic content in digital images as an alternative approach for the early stages of a destructive content access prevention system. the formulation uses the ycbcr color space to analyze human skin on image objects that represent exposed body parts and the classification process with the neuro fuzzy approach. the performance of this formula was tested on digital images of random categories of human objects usually covered, skimpy, and naked taken from the internet. the test results are at a relatively good level of accuracy, with a weight of for the entire test data.",,"digital image processing using ycbcr colour space and neuro fuzzy to identify pornography. pornography is a severe problem in indonesia, apart from drugs. this can be seen based on data from the ministry of communication and informatics in which found . million pornographic content online. the increasing number of access to pornographic content sites on the internet can prove this. several studies have been conducted to produce preventive formulas. however, this research flow has not been effective in solving the problem. this is because the results of the identification value in the output image obtained are not quite right. this study proposes a procedure for identifying pornographic content in digital images as an alternative approach for the early stages of a destructive content access prevention system. the formulation uses the ycbcr color space to analyze human skin on image objects that represent exposed body parts and the classification process with the neuro fuzzy approach. the performance of this formula was tested on digital images of random categories of human objects usually covered, skimpy, and naked taken from the internet. the test results are at a relatively good level of accuracy, with a weight of for the entire test data."
https://join.if.uinsgd.ac.id/index.php/join/article/view/799,youtube x rating detection with bahasa slang title using query expansion and rule based approaches,"the detection of x rating content on the internet is still rarely done in indonesia and the performance of the existing work to detect x rating content, especially in video is still low. the largest video portal, youtube, does not yet have automatic x rating content detection through its content either. some x rating content prevention service providers in indonesia, such as the internet positive and nawala project, detect x rating content using the keyword detection method of a web page and then block the web page with dns filtering. however, that method does not pay attention to using bahasa slang. this work developed metasearch named safedio. safedio aims to detect x rating content on youtube content through video titles that contain bahasa slang. safedio utilizes query expansion and rule based approaches. the query expansion is a technique to get additional rules in search. in the end, safedio can detect x rating content through video titles in both bahasa and bahasa slang. the average results return with precision , recall and accuracy .",,"youtube x rating detection with bahasa slang title using query expansion and rule based approaches. the detection of x rating content on the internet is still rarely done in indonesia and the performance of the existing work to detect x rating content, especially in video is still low. the largest video portal, youtube, does not yet have automatic x rating content detection through its content either. some x rating content prevention service providers in indonesia, such as the internet positive and nawala project, detect x rating content using the keyword detection method of a web page and then block the web page with dns filtering. however, that method does not pay attention to using bahasa slang. this work developed metasearch named safedio. safedio aims to detect x rating content on youtube content through video titles that contain bahasa slang. safedio utilizes query expansion and rule based approaches. the query expansion is a technique to get additional rules in search. in the end, safedio can detect x rating content through video titles in both bahasa and bahasa slang. the average results return with precision , recall and accuracy ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/835,"development of a digital platform prototype, to facilitate inclusive learning for children with special needs","persons with disabilities have the same rights and responsibilities as citizens. based on the constitution republic of indonesia, article paragraph and law number of concerning the national education system, it can be concluded that the state provides full guarantees for children with special needs to obtain quality education services. many of the problems of inclusive learning that occurred during the covid pandemic, ranging from the unpreparedness of the school to various problems with environmental factors so that innovation was needed to overcome these problems. in this article, the author develops a prototype of a digital based learning platform as a solution to facilitate inclusive learning for children with special needs.",,"development of a digital platform prototype, to facilitate inclusive learning for children with special needs. persons with disabilities have the same rights and responsibilities as citizens. based on the constitution republic of indonesia, article paragraph and law number of concerning the national education system, it can be concluded that the state provides full guarantees for children with special needs to obtain quality education services. many of the problems of inclusive learning that occurred during the covid pandemic, ranging from the unpreparedness of the school to various problems with environmental factors so that innovation was needed to overcome these problems. in this article, the author develops a prototype of a digital based learning platform as a solution to facilitate inclusive learning for children with special needs."
https://join.if.uinsgd.ac.id/index.php/join/article/view/840,anti corruption disclosure prediction using deep learning,"corruption gives major problem to many countries. it gives negative impact to a nation economy. people also realized that corruption comes from two sides, demand from the authority and supply from corporate. on that regard, corporates may have their part in fight against corruption in the form of anti corruption disclosure acd . this study proposes new method of acd prediction in corporate using deep learning. the data in this study are taken from every companies listed in indonesia stock exchange idx from the year to . the companies can be categorized in categories and the data set has features. the overall data has items in which items are acd and the other items are non acd. in this study, the deep neural network or deep learning is composed from input layer, output layer and hidden layers. the deep neural network uses adam optimizer with learning rate . , batch size and epochs . the drop out is set to . . the accuracy result from deep learning in predicting acd is considered good with the average training accuracy is . and average testing accuracy is . . however, the loss result isnt good with average training loss and testing loss are respectively . and . . since the aim of the study to find the possibility of deep learning as alternative of logistic regression in acd prediction, accuracy comparison from deep learning and logistic regression is held. deep learning has average prediction accuracy of . is better than logistic regression with average accuracy of . . deep learning also has higher minimum accuracy and maximum accuracy compared to logistic regression. this study concludes that deep learning may give alternatives in acd prediction compared the more common method of logistic regression.",,"anti corruption disclosure prediction using deep learning. corruption gives major problem to many countries. it gives negative impact to a nation economy. people also realized that corruption comes from two sides, demand from the authority and supply from corporate. on that regard, corporates may have their part in fight against corruption in the form of anti corruption disclosure acd . this study proposes new method of acd prediction in corporate using deep learning. the data in this study are taken from every companies listed in indonesia stock exchange idx from the year to . the companies can be categorized in categories and the data set has features. the overall data has items in which items are acd and the other items are non acd. in this study, the deep neural network or deep learning is composed from input layer, output layer and hidden layers. the deep neural network uses adam optimizer with learning rate . , batch size and epochs . the drop out is set to . . the accuracy result from deep learning in predicting acd is considered good with the average training accuracy is . and average testing accuracy is . . however, the loss result isnt good with average training loss and testing loss are respectively . and . . since the aim of the study to find the possibility of deep learning as alternative of logistic regression in acd prediction, accuracy comparison from deep learning and logistic regression is held. deep learning has average prediction accuracy of . is better than logistic regression with average accuracy of . . deep learning also has higher minimum accuracy and maximum accuracy compared to logistic regression. this study concludes that deep learning may give alternatives in acd prediction compared the more common method of logistic regression."
https://join.if.uinsgd.ac.id/index.php/join/article/view/842,random forest method approach to customer classification based on non performing loan in micro business,"this study aims to classify potential customers characteristics based on non performing loans through the random forest method. this research uses data obtained from syariah mandiri bank branch in jambi, which includes data on micro financing customers in years . the random forest method is used for analysis. the novelty of this work is that, unlike existing researches that used other soft computing methods, we employ random forest method, specifically using an imbalanced class sampling technique. the obtained results show that credit risk can be estimated by taking into account factors such as age, monthly installments, margin, price of insurance, loan principal, occupation, and long installments. the research results indicate that the sensitivity, precision, and g mean value increase compared to using the original data. random forest with oversampling technique has the high area under the roc curve score that is equal to . .",,"random forest method approach to customer classification based on non performing loan in micro business. this study aims to classify potential customers characteristics based on non performing loans through the random forest method. this research uses data obtained from syariah mandiri bank branch in jambi, which includes data on micro financing customers in years . the random forest method is used for analysis. the novelty of this work is that, unlike existing researches that used other soft computing methods, we employ random forest method, specifically using an imbalanced class sampling technique. the obtained results show that credit risk can be estimated by taking into account factors such as age, monthly installments, margin, price of insurance, loan principal, occupation, and long installments. the research results indicate that the sensitivity, precision, and g mean value increase compared to using the original data. random forest with oversampling technique has the high area under the roc curve score that is equal to . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/846,multi rule based and corpus based for sundanese stemmer,"the purpose of this study is to develop a stemming method by involved several methods including morphological with affix and pro lexeme removal , syllable canonical pattern, and corpus data as a comparison of the final results of stemming. the algorithm checks a number of the string first and removes affixes, then check the syllable pattern according to the stripping result, then compares to the corpus data which determines the final stemming process. in this study, the corpus data was taken from sundanese dictionary consists of a single word used for the root word and the extracted dataset from the online sundanese magazine. the results showed that the stripping of affix and pro lexeme can remove the corresponding affixes and pro lexeme then compares words that have a syllable pattern then executes the basic words quickly and the use of corpus can improve accuracy and reduce the over stemming problems that occur in the stemming process.",,"multi rule based and corpus based for sundanese stemmer. the purpose of this study is to develop a stemming method by involved several methods including morphological with affix and pro lexeme removal , syllable canonical pattern, and corpus data as a comparison of the final results of stemming. the algorithm checks a number of the string first and removes affixes, then check the syllable pattern according to the stripping result, then compares to the corpus data which determines the final stemming process. in this study, the corpus data was taken from sundanese dictionary consists of a single word used for the root word and the extracted dataset from the online sundanese magazine. the results showed that the stripping of affix and pro lexeme can remove the corresponding affixes and pro lexeme then compares words that have a syllable pattern then executes the basic words quickly and the use of corpus can improve accuracy and reduce the over stemming problems that occur in the stemming process."
https://join.if.uinsgd.ac.id/index.php/join/article/view/858,pso based hyperparameter tuning of cnn multivariate time series analysis,"convolutional neural network cnn is an effective deep learning dl algorithm that solves various image identification problems. the use of cnn for time series data analysis is emerging. cnn learns filters, representations of repeated patterns in the series, and uses them to forecast future values. the network performance may depend on hyperparameter settings. this study optimizes the cnn architecture based on hyperparameter tuning using particle swarm optimization pso , pso cnn. the proposed method was evaluated using multivariate time series data of electronic journal visitor datasets. the cnn equation in image and time series problems is the input given to the model for processing numbers. the proposed method generated the lowest rmse . with neurons in the fully connected and hidden layers. the experimental results show that the pso cnn generates an architecture with better performance than ordinary cnn.",,"pso based hyperparameter tuning of cnn multivariate time series analysis. convolutional neural network cnn is an effective deep learning dl algorithm that solves various image identification problems. the use of cnn for time series data analysis is emerging. cnn learns filters, representations of repeated patterns in the series, and uses them to forecast future values. the network performance may depend on hyperparameter settings. this study optimizes the cnn architecture based on hyperparameter tuning using particle swarm optimization pso , pso cnn. the proposed method was evaluated using multivariate time series data of electronic journal visitor datasets. the cnn equation in image and time series problems is the input given to the model for processing numbers. the proposed method generated the lowest rmse . with neurons in the fully connected and hidden layers. the experimental results show that the pso cnn generates an architecture with better performance than ordinary cnn."
https://join.if.uinsgd.ac.id/index.php/join/article/view/875,performance analysis of cache replacement algorithm using virtual named data network nodes,"as a future internet candidate, named data network ndn provides more efficient communication than tcp ip network. unlike tcp ip, consumer requests in ndn are sent based on content, not the address. the previous study evaluated the ndn performance using a simulator. in this research, we modeled the system using virtual ndn nodes, making the model more relevant to the real ndn. as an essential component in every ndn router, the content store cs has a function to keep the data. we use first in first out fifo and least recetly used lru in our nodes as cache replacement algorithms. the in depth exploration is done using various scenarios. the result shows that the cache hit ratio chr increases if the size of the cs, the number of interests, and the number of consumers increases. chr decreases as the number of producers and the number of prefixes increase. as chr increases, round trip time rtt decreases. lru provides better performance for all cases higher chr of and lower rtt of than fifo.",,"performance analysis of cache replacement algorithm using virtual named data network nodes. as a future internet candidate, named data network ndn provides more efficient communication than tcp ip network. unlike tcp ip, consumer requests in ndn are sent based on content, not the address. the previous study evaluated the ndn performance using a simulator. in this research, we modeled the system using virtual ndn nodes, making the model more relevant to the real ndn. as an essential component in every ndn router, the content store cs has a function to keep the data. we use first in first out fifo and least recetly used lru in our nodes as cache replacement algorithms. the in depth exploration is done using various scenarios. the result shows that the cache hit ratio chr increases if the size of the cs, the number of interests, and the number of consumers increases. chr decreases as the number of producers and the number of prefixes increase. as chr increases, round trip time rtt decreases. lru provides better performance for all cases higher chr of and lower rtt of than fifo."
https://join.if.uinsgd.ac.id/index.php/join/article/view/871,the measurement and evaluation of information system success based on organizational hierarchical culture,"in this study, the adoption of the delone mclean information system success model and its adaptation using the organizational hierarchy culture theory is used to explore the state of information system success and examine the factors that suggest success. this research was conducted at universities in banten province, which currently rely on information systems in many ways, especially those related to university management. by measuring the evaluation of the success of information systems and the hierarchical culture in organizations using a model that the researcher built according to the integration of models. the results the measurement of the success of information systems were obtained from distributing questionnaires, there were still respondents, and . were satisfied with the performance of the information system success model. the least squares structural equation modeling analysis pls sem was then applied due to the sample size. the previous stage consisted of evaluating the reflective measurement model in evaluating the reliability of internal consistency using composite reliability, reliability indicators, convergent validity and discriminant validity, finally it was concluded that the success of information system by hierarchical culture integration model in the organization on could be passed on the more complex research terms, especially using samples, and different questionnaires.",,"the measurement and evaluation of information system success based on organizational hierarchical culture. in this study, the adoption of the delone mclean information system success model and its adaptation using the organizational hierarchy culture theory is used to explore the state of information system success and examine the factors that suggest success. this research was conducted at universities in banten province, which currently rely on information systems in many ways, especially those related to university management. by measuring the evaluation of the success of information systems and the hierarchical culture in organizations using a model that the researcher built according to the integration of models. the results the measurement of the success of information systems were obtained from distributing questionnaires, there were still respondents, and . were satisfied with the performance of the information system success model. the least squares structural equation modeling analysis pls sem was then applied due to the sample size. the previous stage consisted of evaluating the reflective measurement model in evaluating the reliability of internal consistency using composite reliability, reliability indicators, convergent validity and discriminant validity, finally it was concluded that the success of information system by hierarchical culture integration model in the organization on could be passed on the more complex research terms, especially using samples, and different questionnaires."
https://join.if.uinsgd.ac.id/index.php/join/article/view/919,"comparative analysis of naive bayes, k nearest neighbors knn , and support vector machine svm algorithms for classification of heart disease patients","heart disease is still the leading cause of death. in this study, we tried to test several factors that can identify patients with heart disease using classification algorithms naive bayes, k nearest neighbors knn , and support vector machine svm . the purpose of this study is to find out which algorithm can produce the highest accuracy in classifying, analyzing, and obtaining confusion matrix values along with the accuracy of predicting heart disease based on several factors or other comorbidities that the patient has, ranging from bmi to the patient s skin cancer status. from the results of trials conducted by the svm algorithm, it has the highest accuracy value, which is while the naive bayes algorithm is the lowest with an accuracy value of .",,"comparative analysis of naive bayes, k nearest neighbors knn , and support vector machine svm algorithms for classification of heart disease patients. heart disease is still the leading cause of death. in this study, we tried to test several factors that can identify patients with heart disease using classification algorithms naive bayes, k nearest neighbors knn , and support vector machine svm . the purpose of this study is to find out which algorithm can produce the highest accuracy in classifying, analyzing, and obtaining confusion matrix values along with the accuracy of predicting heart disease based on several factors or other comorbidities that the patient has, ranging from bmi to the patient s skin cancer status. from the results of trials conducted by the svm algorithm, it has the highest accuracy value, which is while the naive bayes algorithm is the lowest with an accuracy value of ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/925,delineation of the early election map sentiment analysis approach to twitter data,"as a democratic country, the people hold an important role in determining power in indonesia. the closest political agenda in indonesia is the election. a survey has been conducted by several private survey agencies regarding the political map which has revealed the top five names, namely prabowo subianto, ganjar pranowo, anies baswedan, sandiaga uno, and ridwan kamil. this study aims to describe the initial map of the election through a sentiment analysis approach to twitter data. this study uses tweet data that mentions five political figures during . in general, the demographic condition of twitter users that pros or cons to five political figures, among them located on the java, in the age group years old, and male. the sentiment analysis method used is supervised learning with different methods for each figure. the difference in methods adjusts the best evaluation value given in each figure. the results showed that the highest positive sentimental tweets and the highest number of pro accounts was about ganjar pranowo. on the other hand, the highest negative sentiment and the highest number of contra accounts was about prabowo subianto. many words that often appear on a figure s positive sentiment are expressions of hope, prayer, and support. on negative tweets, the word that comes up a lot relating to the work field or work region of the figures.",,"delineation of the early election map sentiment analysis approach to twitter data. as a democratic country, the people hold an important role in determining power in indonesia. the closest political agenda in indonesia is the election. a survey has been conducted by several private survey agencies regarding the political map which has revealed the top five names, namely prabowo subianto, ganjar pranowo, anies baswedan, sandiaga uno, and ridwan kamil. this study aims to describe the initial map of the election through a sentiment analysis approach to twitter data. this study uses tweet data that mentions five political figures during . in general, the demographic condition of twitter users that pros or cons to five political figures, among them located on the java, in the age group years old, and male. the sentiment analysis method used is supervised learning with different methods for each figure. the difference in methods adjusts the best evaluation value given in each figure. the results showed that the highest positive sentimental tweets and the highest number of pro accounts was about ganjar pranowo. on the other hand, the highest negative sentiment and the highest number of contra accounts was about prabowo subianto. many words that often appear on a figure s positive sentiment are expressions of hope, prayer, and support. on negative tweets, the word that comes up a lot relating to the work field or work region of the figures."
https://join.if.uinsgd.ac.id/index.php/join/article/view/951,internet of things iot for soil moisture detection using time series model,technology in agriculture has been widely and massively applied. one of them is automation technology and the use of big data through the internet of things iot . the use of iot allows a process to run automatically without human intervention. extreme weather changes and narrow land use are one of the main problems in agriculture. the development of iot devices has been widely developed regarding this subject. one of them is a soil moisture detection system. this study aims to build an iot soil moisture detection system. the system will use a sensor as input which is then processed in a microcontroller device and the prediction results are sent to the iot cloud platform. prediction results are obtained using a time series model and then its performance is evaluated using rmse. this model was chosen because the structure of the observed soil moisture data is based on time. the results of this study indicate that the soil moisture iot system can work well. this is supported by the results of the prediction evaluation value of the rmse .175682x10 model which is very small.,,internet of things iot for soil moisture detection using time series model. technology in agriculture has been widely and massively applied. one of them is automation technology and the use of big data through the internet of things iot . the use of iot allows a process to run automatically without human intervention. extreme weather changes and narrow land use are one of the main problems in agriculture. the development of iot devices has been widely developed regarding this subject. one of them is a soil moisture detection system. this study aims to build an iot soil moisture detection system. the system will use a sensor as input which is then processed in a microcontroller device and the prediction results are sent to the iot cloud platform. prediction results are obtained using a time series model and then its performance is evaluated using rmse. this model was chosen because the structure of the observed soil moisture data is based on time. the results of this study indicate that the soil moisture iot system can work well. this is supported by the results of the prediction evaluation value of the rmse .175682x10 model which is very small.
https://join.if.uinsgd.ac.id/index.php/join/article/view/970,diabetes risk prediction using extreme gradient boosting xgboost,"one of the uses of medical data from diabetes patients is to produce models that can be used by medical personnel to predict and identify diabetes in patients. various techniques are used to be able to provide a diabetes model as early as possible based on the symptoms experienced by diabetic patients, including using machine learning. the machine learning technique used to predict diabetes in this study is extreme gradient boosting xgboost . xgboost is an advanced implementation of gradient boosting along with multiple regularization factors to accurately predict target variables by combining simpler and weaker model set estimations. errors made by the previous model are tried to be corrected by the next model by adding some weight to the model. the diabetes prediction model using xgboost is shown in the form of a tree, with the accuracy of the model produced in this study of .",,"diabetes risk prediction using extreme gradient boosting xgboost. one of the uses of medical data from diabetes patients is to produce models that can be used by medical personnel to predict and identify diabetes in patients. various techniques are used to be able to provide a diabetes model as early as possible based on the symptoms experienced by diabetic patients, including using machine learning. the machine learning technique used to predict diabetes in this study is extreme gradient boosting xgboost . xgboost is an advanced implementation of gradient boosting along with multiple regularization factors to accurately predict target variables by combining simpler and weaker model set estimations. errors made by the previous model are tried to be corrected by the next model by adding some weight to the model. the diabetes prediction model using xgboost is shown in the form of a tree, with the accuracy of the model produced in this study of ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/994,ar make up filter for social media using the hsv color extraction,"choosing the appropriate cosmetics is an arduous task. because cosmetics are tested directly on the skin to ensure each persons preferences are met. the consumer repeatedly tries a sample and then discards it until he discovers one that meets his tastes. the cosmetics business and consumers are affected by this move. companies can utilize augmented reality ar technology as an alternative to mass producing cosmetic samples. the difficulty of deploying augmented reality is the difficulty of putting cosmetics into camera video streams. each individual bears the burden of skin color and its effect on light. hsv color extraction was the method employed for this study. the application of augmented reality intends to enable consumers to test cosmetics with their chosen color and assist businesses in competing in the industry by promoting items and engaging customers. this work makes it easier to choose cosmetics using augmented reality and social media. ar simulates the usage of the desired color cosmetics, whereas social media allows users to obtain feedback on their color preferences. the outcomes of this study indicate that augmented reality ar apps can display filters in bright, dim, and even wholly dark lighting conditions. this research contributes originality that cosmetic firms can utilize to market their products on social media.",,"ar make up filter for social media using the hsv color extraction. choosing the appropriate cosmetics is an arduous task. because cosmetics are tested directly on the skin to ensure each persons preferences are met. the consumer repeatedly tries a sample and then discards it until he discovers one that meets his tastes. the cosmetics business and consumers are affected by this move. companies can utilize augmented reality ar technology as an alternative to mass producing cosmetic samples. the difficulty of deploying augmented reality is the difficulty of putting cosmetics into camera video streams. each individual bears the burden of skin color and its effect on light. hsv color extraction was the method employed for this study. the application of augmented reality intends to enable consumers to test cosmetics with their chosen color and assist businesses in competing in the industry by promoting items and engaging customers. this work makes it easier to choose cosmetics using augmented reality and social media. ar simulates the usage of the desired color cosmetics, whereas social media allows users to obtain feedback on their color preferences. the outcomes of this study indicate that augmented reality ar apps can display filters in bright, dim, and even wholly dark lighting conditions. this research contributes originality that cosmetic firms can utilize to market their products on social media."
https://join.if.uinsgd.ac.id/index.php/join/article/view/794,a model driven is . development framework for railway supply chain,"railway industry ri in malaysia possess below average information system is skills and seldom use the is for decision making at their operation level while they likewise discover digital transformation adaption is crucial and hence ri in malaysia are in the slow mass of adapter classification. perceiving the significant task of is to ri in the economy, the government is resolved to assist and support the improvement of is to guarantee their sustainability and competitiveness. is framework being significant because it set up the computerized industry, lively digital, who can structure with simple to utilize and basic dynamic interaction. the present is model utilized in malaysia depends on the knowledge and experience of the specialist like system developers and academicians. the maximum of these is models to identify the visual view of performance in ri are precise and are not strategized toward railway utilize and do not give prescriptive evaluation. the issue is no transition development and the absence of industry capacity to do the transition phases. this research focuses on the technology parameters influencing the adaption of is to assist decision makers, administrative bodies, and is analysis to approach the advantages of its continued and expected improvement in the ri.",,"a model driven is . development framework for railway supply chain. railway industry ri in malaysia possess below average information system is skills and seldom use the is for decision making at their operation level while they likewise discover digital transformation adaption is crucial and hence ri in malaysia are in the slow mass of adapter classification. perceiving the significant task of is to ri in the economy, the government is resolved to assist and support the improvement of is to guarantee their sustainability and competitiveness. is framework being significant because it set up the computerized industry, lively digital, who can structure with simple to utilize and basic dynamic interaction. the present is model utilized in malaysia depends on the knowledge and experience of the specialist like system developers and academicians. the maximum of these is models to identify the visual view of performance in ri are precise and are not strategized toward railway utilize and do not give prescriptive evaluation. the issue is no transition development and the absence of industry capacity to do the transition phases. this research focuses on the technology parameters influencing the adaption of is to assist decision makers, administrative bodies, and is analysis to approach the advantages of its continued and expected improvement in the ri."
https://join.if.uinsgd.ac.id/index.php/join/article/view/736,data visualization of covid vaccination progress and prediction using linear regression,"this paper provides a data visualization and analysis of the covid vaccination program. important information such as which countries have the highest vaccination rates and numbers. in addition to the types of vaccines used and used by countries in the world, an infographic on the geographic distribution of vaccine use is also shown. to model the obtained data, daily vaccination rates were modeled by linear regression in which five sample countries with different vaccination ranges were processed using data science approach, namely, linear regression. the modeling results show a gradient coefficient that represents an increase in vaccine rates. the prediction results showed that the highest rate of increase in daily vaccination was , , additional vaccines per day.",,"data visualization of covid vaccination progress and prediction using linear regression. this paper provides a data visualization and analysis of the covid vaccination program. important information such as which countries have the highest vaccination rates and numbers. in addition to the types of vaccines used and used by countries in the world, an infographic on the geographic distribution of vaccine use is also shown. to model the obtained data, daily vaccination rates were modeled by linear regression in which five sample countries with different vaccination ranges were processed using data science approach, namely, linear regression. the modeling results show a gradient coefficient that represents an increase in vaccine rates. the prediction results showed that the highest rate of increase in daily vaccination was , , additional vaccines per day."
https://join.if.uinsgd.ac.id/index.php/join/article/view/762,classification of the fluency multipurpose of bank mandiri credit payments based on debtor preferences using naive bayes and neural network method,"one that has an important role in generating bank profits is providing credit to customers, but credit also carries a very high risk. for this reason, in providing credit to debtors, of course the bank will utilize the personal data of prospective debtors in detail to avoid the risk of problems that will arise in the future. one of the appropriate risks for banks in providing credit is the behavior of customers who do not pay installments at the time which causes bad loans. to overcome and overcome the many bad events, there is an algorithmic calculation method with an intelligent computing system that helps banks in selecting prospective debtors who will be given credit. there are many algorithmic methods that can be used in this kind of research. this study analyzes the classification of staffing credit based on the criteria that become the bank s standard.the data used by the author in this study uses existing debtor credit data from to , the modeling process is carried out using split validation with the naive bayes algorithm and neural network, with this algorithm the , datasets is divided into parts, namely used as training data and used as testing data.the results showed that the neural network algorithm has better results with a correct value of . , while the naive bayes algorithm only produces a value of .",,"classification of the fluency multipurpose of bank mandiri credit payments based on debtor preferences using naive bayes and neural network method. one that has an important role in generating bank profits is providing credit to customers, but credit also carries a very high risk. for this reason, in providing credit to debtors, of course the bank will utilize the personal data of prospective debtors in detail to avoid the risk of problems that will arise in the future. one of the appropriate risks for banks in providing credit is the behavior of customers who do not pay installments at the time which causes bad loans. to overcome and overcome the many bad events, there is an algorithmic calculation method with an intelligent computing system that helps banks in selecting prospective debtors who will be given credit. there are many algorithmic methods that can be used in this kind of research. this study analyzes the classification of staffing credit based on the criteria that become the bank s standard.the data used by the author in this study uses existing debtor credit data from to , the modeling process is carried out using split validation with the naive bayes algorithm and neural network, with this algorithm the , datasets is divided into parts, namely used as training data and used as testing data.the results showed that the neural network algorithm has better results with a correct value of . , while the naive bayes algorithm only produces a value of ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/814,evaluation of information technology governance using cobit and iso iec,"infrastructure section, information and communication technology development division, south tangerang city communication and information office, one of the main tasks and functions is to provide services and management of internet network infrastructure for all regional apparatus organizations opd in south tangerang city. the implementation of the infrastructure section is constrained by the problem of employee competence that has not reached the standard in internet network management and service, from these problems the researcher intends to evaluate governance using the cobit framework and iso iec with recommendations for improvement in the infrastructure section. this study uses pam process assessment model with the guttman scale to determine the results and level of capability. the use of cobit in this research will focus on the domain of edm evaluate direct monitor point , ensure resource management and mea monitor, evaluate and assessment point , performance and conformance. the results and the level of capability obtained during the research were level managed process with a value of . with a gap of . . the level expected by the infrastructure section is at level established process with a value of . . recommendations for achieving level are used iso iec .",,"evaluation of information technology governance using cobit and iso iec. infrastructure section, information and communication technology development division, south tangerang city communication and information office, one of the main tasks and functions is to provide services and management of internet network infrastructure for all regional apparatus organizations opd in south tangerang city. the implementation of the infrastructure section is constrained by the problem of employee competence that has not reached the standard in internet network management and service, from these problems the researcher intends to evaluate governance using the cobit framework and iso iec with recommendations for improvement in the infrastructure section. this study uses pam process assessment model with the guttman scale to determine the results and level of capability. the use of cobit in this research will focus on the domain of edm evaluate direct monitor point , ensure resource management and mea monitor, evaluate and assessment point , performance and conformance. the results and the level of capability obtained during the research were level managed process with a value of . with a gap of . . the level expected by the infrastructure section is at level established process with a value of . . recommendations for achieving level are used iso iec ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/813,automatic plant watering system for local red onion palu using arduino,"central sulawesi province in indonesia has great potential for horticultural commodities, namely local red onion palu. in the current climate change, local farmers are still watering plants in the conventional way. the automatic watering system simplifies the work of local farmers. this device uses a soil moisture sensor as a soil moisture detector and arduino as a program brain. this study aims to determine the position of soil moisture sensor, the optimal length of watering time and analyze the quality of data stored. the experiment was carried out using a completely randomized design crd . the position of the soil moisture sensor was analyzed by profile analysis. the optimal length of watering time was determined by analysis of variance anova and least significant difference lsd . the quality of data stored was determined by a number of missing values and frequency of watering. the results showed that in soil planting media the position of soil moisture sensor had no significant effect, while in others planting media water and combination of water and soil the position of the sensor had a significant effect. the optimal watering time was seconds. the stored data has low quality in terms of missing values and lack of consistency.",,"automatic plant watering system for local red onion palu using arduino. central sulawesi province in indonesia has great potential for horticultural commodities, namely local red onion palu. in the current climate change, local farmers are still watering plants in the conventional way. the automatic watering system simplifies the work of local farmers. this device uses a soil moisture sensor as a soil moisture detector and arduino as a program brain. this study aims to determine the position of soil moisture sensor, the optimal length of watering time and analyze the quality of data stored. the experiment was carried out using a completely randomized design crd . the position of the soil moisture sensor was analyzed by profile analysis. the optimal length of watering time was determined by analysis of variance anova and least significant difference lsd . the quality of data stored was determined by a number of missing values and frequency of watering. the results showed that in soil planting media the position of soil moisture sensor had no significant effect, while in others planting media water and combination of water and soil the position of the sensor had a significant effect. the optimal watering time was seconds. the stored data has low quality in terms of missing values and lack of consistency."
https://join.if.uinsgd.ac.id/index.php/join/article/view/804,systematic literature review of particle swarm optimization implementation for time dependent vehicle routing problem,"time dependent vrp tdvrp is one of the three vrp variants that have not been widely explored in research in the field of operational research, while particle swarm optimization pso is an optimization algorithm in the field of operational research that uses many variables in its application. there is much research conducted about tdvrp, but few of them discuss pso s implementation. this article presented as a literature review which aimed to find a research gap about implementation of pso to resolve tdvrp cases. the research was conducted in five stages. the first stage, a review protocol defined in the form of research questions and methods to perform the review. the second stage is references searching. the third stage is screening the search result. the fourth stage is extracting data from references based on research questions. the fifth stage is reporting the study literature results. the results obtained from the screening process were eligible reference articles, from search results articles. the results of extraction and analysis of reference articles show that research on tdvrp discusses the duration of travel time between locations. the route optimization parameter is determined from the cost of the trip, including the total distance traveled, the total travel time, the number of routes, and the number used vehicles. the datasets that are used in research consist of types, real world datasets and simulation datasets. solomon benchmark is a simulation dataset that is widely used in the case of tdvrp. research on pso in the tdvrp case is dominated by the discussion of modifications to determine random values of pso variables.",,"systematic literature review of particle swarm optimization implementation for time dependent vehicle routing problem. time dependent vrp tdvrp is one of the three vrp variants that have not been widely explored in research in the field of operational research, while particle swarm optimization pso is an optimization algorithm in the field of operational research that uses many variables in its application. there is much research conducted about tdvrp, but few of them discuss pso s implementation. this article presented as a literature review which aimed to find a research gap about implementation of pso to resolve tdvrp cases. the research was conducted in five stages. the first stage, a review protocol defined in the form of research questions and methods to perform the review. the second stage is references searching. the third stage is screening the search result. the fourth stage is extracting data from references based on research questions. the fifth stage is reporting the study literature results. the results obtained from the screening process were eligible reference articles, from search results articles. the results of extraction and analysis of reference articles show that research on tdvrp discusses the duration of travel time between locations. the route optimization parameter is determined from the cost of the trip, including the total distance traveled, the total travel time, the number of routes, and the number used vehicles. the datasets that are used in research consist of types, real world datasets and simulation datasets. solomon benchmark is a simulation dataset that is widely used in the case of tdvrp. research on pso in the tdvrp case is dominated by the discussion of modifications to determine random values of pso variables."
https://join.if.uinsgd.ac.id/index.php/join/article/view/809,poincar plot method for physiological analysis of the gadget use effect on children stress level,"stress in children can affect the way they think, act, and feel. the habit of using gadgets has several advantages and disadvantages, but there has been no in depth study of the effect of using gadgets on stress levels in children. this study aims to determine the representation of the physiological condition of using gadgets on stress levels in children. a total of electrocardiogram data were extracted with poincar plot features. this research has found that there is no difference in the level of stress in children between before and after using gadgets in terms of autonomic nervous activity sig. . . however, there is an increase in sympathetic activity that occurs in children even though they have finished using gadgets. such conditions certainly need to get more attention, especially related to the duration of gadget use and accessible content.",,"poincar plot method for physiological analysis of the gadget use effect on children stress level. stress in children can affect the way they think, act, and feel. the habit of using gadgets has several advantages and disadvantages, but there has been no in depth study of the effect of using gadgets on stress levels in children. this study aims to determine the representation of the physiological condition of using gadgets on stress levels in children. a total of electrocardiogram data were extracted with poincar plot features. this research has found that there is no difference in the level of stress in children between before and after using gadgets in terms of autonomic nervous activity sig. . . however, there is an increase in sympathetic activity that occurs in children even though they have finished using gadgets. such conditions certainly need to get more attention, especially related to the duration of gadget use and accessible content."
https://join.if.uinsgd.ac.id/index.php/join/article/view/817,a tourism introduction application using augmented reality,"tourism is a journey from one place to another. whether it is an individual, a group, or a company, participants on this trip are interested in mental balance, such as reducing stress, entertaining themselves, and refreshing. a tourist attraction is one of the products or advantages of an area, where the region can create income and attract tourists to their tourist destinations. one way to promote tourism more attractively is with augmented reality media. this tourism introduction application using augmented reality technology aims to make it easier for tourists to get to know tourism with interactive media. this tourism introduction application is needed for promotional media, including video playback features of augmented reality technology and information about tourism. augmented reality is a real object in an area map that will become a marker object by detailing the tourist plan. a scan can be carried out to display 2d images, text, audio, and video with the android platform so that it can make it easier for users to use it. this research aims to design and build a tourism introduction application with the application of augmented reality technology. this research uses the multimedia development life cycle method, with six stages concept, design, material collecting, assembly, testing, and distribution, with the testing method using alpha and beta tests. the results of this research are in the form of an android based tourism introduction augmented reality application. this application can give contributions to assist tourists in finding information about tourism in an area and help the department of tourism and culture promote tourism in the region more attractively.",,"a tourism introduction application using augmented reality. tourism is a journey from one place to another. whether it is an individual, a group, or a company, participants on this trip are interested in mental balance, such as reducing stress, entertaining themselves, and refreshing. a tourist attraction is one of the products or advantages of an area, where the region can create income and attract tourists to their tourist destinations. one way to promote tourism more attractively is with augmented reality media. this tourism introduction application using augmented reality technology aims to make it easier for tourists to get to know tourism with interactive media. this tourism introduction application is needed for promotional media, including video playback features of augmented reality technology and information about tourism. augmented reality is a real object in an area map that will become a marker object by detailing the tourist plan. a scan can be carried out to display 2d images, text, audio, and video with the android platform so that it can make it easier for users to use it. this research aims to design and build a tourism introduction application with the application of augmented reality technology. this research uses the multimedia development life cycle method, with six stages concept, design, material collecting, assembly, testing, and distribution, with the testing method using alpha and beta tests. the results of this research are in the form of an android based tourism introduction augmented reality application. this application can give contributions to assist tourists in finding information about tourism in an area and help the department of tourism and culture promote tourism in the region more attractively."
https://join.if.uinsgd.ac.id/index.php/join/article/view/839,analysis of the combination of nave bayes and mhr mean of horners rule for classification of keystroke dynamic authentication,"keystroke dynamics authentication kda is a technique used to recognize somebody dependent on typing pattern or typing rhythm in a system. everyone s typing behavior is considered unique. one of the numerous approaches to secure private information is by utilizing a password. the development of technology is trailed by the human requirement for security concerning information and protection since hacker ability of information burglary has gotten further developed hack the password . so that hackers can use this information for their benefit and can disadvantage others. hence, for better security, for example, fingerprint, retina scan, et cetera are enthusiastically suggested. but these techniques are considered costly. the advantage of kda is the user would not realize that the system is using kda. accordingly, we proposed the combination of nave bayes and mhr mean of horners rule to classify the individual as an attacker or a nonattacker. we use nave bayes because it is better for classification and simple to implement than another. furthermore, mhr is better for kda if combined with the classification method which is based on previous research. this research showed that false acceptance rate far and accuracy are improving than the previous research.",,"analysis of the combination of nave bayes and mhr mean of horners rule for classification of keystroke dynamic authentication. keystroke dynamics authentication kda is a technique used to recognize somebody dependent on typing pattern or typing rhythm in a system. everyone s typing behavior is considered unique. one of the numerous approaches to secure private information is by utilizing a password. the development of technology is trailed by the human requirement for security concerning information and protection since hacker ability of information burglary has gotten further developed hack the password . so that hackers can use this information for their benefit and can disadvantage others. hence, for better security, for example, fingerprint, retina scan, et cetera are enthusiastically suggested. but these techniques are considered costly. the advantage of kda is the user would not realize that the system is using kda. accordingly, we proposed the combination of nave bayes and mhr mean of horners rule to classify the individual as an attacker or a nonattacker. we use nave bayes because it is better for classification and simple to implement than another. furthermore, mhr is better for kda if combined with the classification method which is based on previous research. this research showed that false acceptance rate far and accuracy are improving than the previous research."
https://join.if.uinsgd.ac.id/index.php/join/article/view/841,pattern analysis of drug procurement system with fp growth algorithm,"the medan marelan health center is one of the health centers in the city of medan. the supply of medicines is considered necessary so that these medicines can still be available at any time with various types and functions. in order not to experience difficulties in distributing medicines and anticipating the supply of medicines in the puskesmas, research was carried out using the data mining method. in this study, a test will be carried out on the association rule which is used as a solution to problems with the pattern of the drug procurement system, and will display information about the value of support and confidence from each data mining process. tests in this study using weka software to determine the procurement of drugs that are often needed. information obtained from the stages of the fp growth algorithm is to produce patterns in the procurement of medicines, and an itemset combination pattern has been formed using the fp growth algorithm method so that the results of this study can be used in drug supply effectively and efficiently.",,"pattern analysis of drug procurement system with fp growth algorithm. the medan marelan health center is one of the health centers in the city of medan. the supply of medicines is considered necessary so that these medicines can still be available at any time with various types and functions. in order not to experience difficulties in distributing medicines and anticipating the supply of medicines in the puskesmas, research was carried out using the data mining method. in this study, a test will be carried out on the association rule which is used as a solution to problems with the pattern of the drug procurement system, and will display information about the value of support and confidence from each data mining process. tests in this study using weka software to determine the procurement of drugs that are often needed. information obtained from the stages of the fp growth algorithm is to produce patterns in the procurement of medicines, and an itemset combination pattern has been formed using the fp growth algorithm method so that the results of this study can be used in drug supply effectively and efficiently."
https://join.if.uinsgd.ac.id/index.php/join/article/view/853,technology acceptance model in government context a systematic review on the implementation of it governance in a government institution,"recent trends of studies on technology acceptance in local government had recently been popular the studies focused on identifying the predictors of human behavior in potential acceptance or rejection of technology. this study investigated the use of information technology information system henceforth, it is acceptance in government as a means to improve the quality of public service and strive for transparent governance. a mixed methods quantitative and qualitative study was conducted, and data were collected through questionnaires involving respondents, interviews, and observations. technology acceptance model tam is used as a theoretical framework for behavioral information systems and smart partial least square smart pls analysis was employed in elaborating the complex correlation between the determinants. the result showed that the perceived ease of use peou contributed positively to the perceived usefulness pu and attitude towards using technology atut . moreover, the atut significantly contributed to behavioral intention of use bitu further, the bitu also contributed to actual technology use atu . the pu, however, possessed a negative impact on the atut. these results further the information regarding the quality and performance of it is services that can be used as a basis for higher level decision making.",,"technology acceptance model in government context a systematic review on the implementation of it governance in a government institution. recent trends of studies on technology acceptance in local government had recently been popular the studies focused on identifying the predictors of human behavior in potential acceptance or rejection of technology. this study investigated the use of information technology information system henceforth, it is acceptance in government as a means to improve the quality of public service and strive for transparent governance. a mixed methods quantitative and qualitative study was conducted, and data were collected through questionnaires involving respondents, interviews, and observations. technology acceptance model tam is used as a theoretical framework for behavioral information systems and smart partial least square smart pls analysis was employed in elaborating the complex correlation between the determinants. the result showed that the perceived ease of use peou contributed positively to the perceived usefulness pu and attitude towards using technology atut . moreover, the atut significantly contributed to behavioral intention of use bitu further, the bitu also contributed to actual technology use atu . the pu, however, possessed a negative impact on the atut. these results further the information regarding the quality and performance of it is services that can be used as a basis for higher level decision making."
https://join.if.uinsgd.ac.id/index.php/join/article/view/825,e commerce for village information system using agile methodology,"with the entry into the era of industrial revolution . , the development of digitization of various aspects at the village level began. the level of use of mobile devices in the commercial transactions of society is now a massive number of users. it happens not only in large transactions but also in small transactions. with the community s high interest in the use of smartphone devices, this is a different opportunity to explore the potential of each village by helping the community, tiny and medium enterprises in conducting transactions, sales, and marketing online through the village government website. the village information system itself requires an e commerce feature on its page to help small and medium enterprises in the area to sell products online through a simple page display. this research aims to design and develop new features of the village system that plays a role in the field of e commerce with the direct message transaction method. the system development methodology used is agile with scrum as a framework. the agile model is a short term development model that requires rapid adaptation and development to changes in any form. this e commerce feature is for local communities, especially micro, small, and medium enterprises, so their products marketing reach is even more outstanding while being recorded in the village system.",,"e commerce for village information system using agile methodology. with the entry into the era of industrial revolution . , the development of digitization of various aspects at the village level began. the level of use of mobile devices in the commercial transactions of society is now a massive number of users. it happens not only in large transactions but also in small transactions. with the community s high interest in the use of smartphone devices, this is a different opportunity to explore the potential of each village by helping the community, tiny and medium enterprises in conducting transactions, sales, and marketing online through the village government website. the village information system itself requires an e commerce feature on its page to help small and medium enterprises in the area to sell products online through a simple page display. this research aims to design and develop new features of the village system that plays a role in the field of e commerce with the direct message transaction method. the system development methodology used is agile with scrum as a framework. the agile model is a short term development model that requires rapid adaptation and development to changes in any form. this e commerce feature is for local communities, especially micro, small, and medium enterprises, so their products marketing reach is even more outstanding while being recorded in the village system."
https://join.if.uinsgd.ac.id/index.php/join/article/view/797,performance analysis of aco and fa algorithms on parameter variation scenarios in determining alternative routes for cars as a solution to traffic jams,"this study proposes several alternative optimal routes on traffic prone routes using ant colony optimization aco and firefly algorithm fa . two methods are classified as the metaheuristic method, which means that they can solve problems with complex optimization and will get the solution with the best results. comparison of alternative routes generated by the two algorithms is measured based on several parameters, namely alpha and beta in determination of the best alternative route. the results obtained are that the alternative route produced by fa is superior to aco, with an accuracy of . this is also supported by the performance of the fa algorithm which is generally superior, where the resulting alternative route is shorter in distance, time, running time and there is no influence on the alpha parameter value. but in each iteration, the number of alternative routes generated is less. the contribution of this research is to provide information about the best algorithm between aco and fa in providing the most optimal alternative route based on the fastest travel time. the recommended alternative path is a path that is sufficient for cars to pass, because the selection takes into account the size of the road capacity.",,"performance analysis of aco and fa algorithms on parameter variation scenarios in determining alternative routes for cars as a solution to traffic jams. this study proposes several alternative optimal routes on traffic prone routes using ant colony optimization aco and firefly algorithm fa . two methods are classified as the metaheuristic method, which means that they can solve problems with complex optimization and will get the solution with the best results. comparison of alternative routes generated by the two algorithms is measured based on several parameters, namely alpha and beta in determination of the best alternative route. the results obtained are that the alternative route produced by fa is superior to aco, with an accuracy of . this is also supported by the performance of the fa algorithm which is generally superior, where the resulting alternative route is shorter in distance, time, running time and there is no influence on the alpha parameter value. but in each iteration, the number of alternative routes generated is less. the contribution of this research is to provide information about the best algorithm between aco and fa in providing the most optimal alternative route based on the fastest travel time. the recommended alternative path is a path that is sufficient for cars to pass, because the selection takes into account the size of the road capacity."
https://join.if.uinsgd.ac.id/index.php/join/article/view/819,implementation of apriori algorithm for music genre recommendation,"music interest is diverse yet enticing to be a part of knowledge discovery. it influences how people feel, study, work, etc. a lot of things are to be considered in producing brand new music with its correlation to its genre. we have already collected the dataset that we can utilize in this research, which is the history of every song listened to by several users in a total of . records from a million song dataset. this study implements the apriori algorithm which can handle a large amount of data while simplifying the data to create a recommendation system where the result is a pattern from the music genre according to the interests of each user with the help of the rapidminer tool. the purpose of this research is that the pattern which has been found can become a reference for music producers in terms of making or distributing their brand new music. the result of the best combination of genres states that listeners of the rock genre will also hear the pop genre with a combination frequency of , support value of . , and confidence value of .",,"implementation of apriori algorithm for music genre recommendation. music interest is diverse yet enticing to be a part of knowledge discovery. it influences how people feel, study, work, etc. a lot of things are to be considered in producing brand new music with its correlation to its genre. we have already collected the dataset that we can utilize in this research, which is the history of every song listened to by several users in a total of . records from a million song dataset. this study implements the apriori algorithm which can handle a large amount of data while simplifying the data to create a recommendation system where the result is a pattern from the music genre according to the interests of each user with the help of the rapidminer tool. the purpose of this research is that the pattern which has been found can become a reference for music producers in terms of making or distributing their brand new music. the result of the best combination of genres states that listeners of the rock genre will also hear the pop genre with a combination frequency of , support value of . , and confidence value of ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/669,sentiment analysis from indonesian twitter data using support vector machine and query expansion ranking,"sentiment analysis is a computational study of a sentiment opinion and an overflow of feelings expressed in textual form. twitter has become a popular social network among indonesians. as a public figure running for president of indonesia, public opinion is very important to see and consider the popularity of a presidential candidate. media has become one of the important tools used to increase electability. however, it is not easy to analyze sentiments from tweets on twitter apps, because it contains unstructured text, especially indonesian text. the purpose of this research is to classify indonesian twitter data into positive and negative sentiments polarity using support vector machine and query expansion ranking so that the information contained therein can be extracted and from the observed data can provide useful information for those in need. several stages in the research include crawling data, data preprocessing, term frequency inverse document frequency tf idf , feature selection query expansion ranking, and data classification using the support vector machine svm method. to find out the performance of this classification process, it will be entered into a configuration matrix. by using a discussion matrix, the results show that calcification using the proposed reached accuracy and f measure score in and respectively.",,"sentiment analysis from indonesian twitter data using support vector machine and query expansion ranking. sentiment analysis is a computational study of a sentiment opinion and an overflow of feelings expressed in textual form. twitter has become a popular social network among indonesians. as a public figure running for president of indonesia, public opinion is very important to see and consider the popularity of a presidential candidate. media has become one of the important tools used to increase electability. however, it is not easy to analyze sentiments from tweets on twitter apps, because it contains unstructured text, especially indonesian text. the purpose of this research is to classify indonesian twitter data into positive and negative sentiments polarity using support vector machine and query expansion ranking so that the information contained therein can be extracted and from the observed data can provide useful information for those in need. several stages in the research include crawling data, data preprocessing, term frequency inverse document frequency tf idf , feature selection query expansion ranking, and data classification using the support vector machine svm method. to find out the performance of this classification process, it will be entered into a configuration matrix. by using a discussion matrix, the results show that calcification using the proposed reached accuracy and f measure score in and respectively."
https://join.if.uinsgd.ac.id/index.php/join/article/view/882,automatic detection of hijaiyah letters pronunciation using convolutional neural network algorithm,"abstract speech recognition technology is used in learning to read letters in the qur an. this study aims to implement the cnn algorithm in recognizing the results of introducing the pronunciation of the hijaiyah letters. the pronunciation sound is extracted using the mel frequency cepstral coefficients mfcc model and then classified using a deep learning model with the cnn algorithm. this system was developed using the crisp dm model. based on the results of testing voice data of hijaiyah letters, the best value was obtained for accuracy of . , precision of , recall of and f1 score of .",,"automatic detection of hijaiyah letters pronunciation using convolutional neural network algorithm. abstract speech recognition technology is used in learning to read letters in the qur an. this study aims to implement the cnn algorithm in recognizing the results of introducing the pronunciation of the hijaiyah letters. the pronunciation sound is extracted using the mel frequency cepstral coefficients mfcc model and then classified using a deep learning model with the cnn algorithm. this system was developed using the crisp dm model. based on the results of testing voice data of hijaiyah letters, the best value was obtained for accuracy of . , precision of , recall of and f1 score of ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/900,sentiment analysis for the brazilian anesthesiologist using multi layer perceptron classifier and random forest methods,"sexual harassment is defined as giving sexual attention both verbally, either in speech or writing, and physically to victims who are predominantly women, on july , , there was a tweet featuring a video of sexual harassment that made it trend in various countries. the video irritated twitter users and made various comments resulting in various sentiments that can be analyzed using sentiment analysis. the purpose of this study is to see what the public thinks about the sexual harassment case of brazilian anesthesiologist. besides the sentiment analysis, another aim of this study is to see how objective are those sentiments based on their polarity. this study uses a comparison of two methods in sentiment analysis, namely multi layer perceptron classifier and random forest, and labeling automatically using textblob. this results in . accuracy, . precision, recall and f1 score. for mlp classifier and accuracy . , precision . , recall . and f1 score . for random forest. sentiment polarity score from the textblob is . and subjectivity is . which indicates that most statements are negative and subjective score is . , which means those sentiments are subjective in nature.",,"sentiment analysis for the brazilian anesthesiologist using multi layer perceptron classifier and random forest methods. sexual harassment is defined as giving sexual attention both verbally, either in speech or writing, and physically to victims who are predominantly women, on july , , there was a tweet featuring a video of sexual harassment that made it trend in various countries. the video irritated twitter users and made various comments resulting in various sentiments that can be analyzed using sentiment analysis. the purpose of this study is to see what the public thinks about the sexual harassment case of brazilian anesthesiologist. besides the sentiment analysis, another aim of this study is to see how objective are those sentiments based on their polarity. this study uses a comparison of two methods in sentiment analysis, namely multi layer perceptron classifier and random forest, and labeling automatically using textblob. this results in . accuracy, . precision, recall and f1 score. for mlp classifier and accuracy . , precision . , recall . and f1 score . for random forest. sentiment polarity score from the textblob is . and subjectivity is . which indicates that most statements are negative and subjective score is . , which means those sentiments are subjective in nature."
https://join.if.uinsgd.ac.id/index.php/join/article/view/912,data analysis of social media s impact on covid19 pandemic users mental health,"social media has a significant impact on people s daily lives and spread widely. unrestrained usage of social media could have worsening consequences on mental health. the majority of covid users who were exposed to social media learned numerous facts, which made their anxiety and depression related mental health disorders worse. this study aims to determine how social media usage affects users mental health during the covid19 pandemic. through surveys and expert interviews, this study collects both quantitative and qualitative data. the total number of respondents involved was with the average age group of year old. using reliability testing cronbach alpha test and inferential statistic pearson correlation and chi square , results show that during the covid19 pandemic, there is a significant link between social media use and mental health. anxiety and depression brought on by social media are more common among young adults, predominantly female, between the ages of and than in men. additionally, correlation plot analysis with a variety of queries reveals the mental health issues and activities on social media.",,"data analysis of social media s impact on covid19 pandemic users mental health. social media has a significant impact on people s daily lives and spread widely. unrestrained usage of social media could have worsening consequences on mental health. the majority of covid users who were exposed to social media learned numerous facts, which made their anxiety and depression related mental health disorders worse. this study aims to determine how social media usage affects users mental health during the covid19 pandemic. through surveys and expert interviews, this study collects both quantitative and qualitative data. the total number of respondents involved was with the average age group of year old. using reliability testing cronbach alpha test and inferential statistic pearson correlation and chi square , results show that during the covid19 pandemic, there is a significant link between social media use and mental health. anxiety and depression brought on by social media are more common among young adults, predominantly female, between the ages of and than in men. additionally, correlation plot analysis with a variety of queries reveals the mental health issues and activities on social media."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1252,levels of iot architecture for smart irrigation rice fields,"water is one of the main components in the agricultural sector. traditional irrigation systems are often inefficient and ineffective, which can lead to water wastage and require huge resources. intelligent irrigation systems based on the internet of things iot offer a solution to overcome these problems. the purpose of this research is to create a layer iot architecture for smart irrigation in gadon village. the method used in this research uses research and development methods, starting from literature study, field survey, design, assembly, and testing. design of internet of things iot architecture using esp8266 for irrigation of rice fields in gadon village dlingo, bantul. the design of this system aims to facilitate irrigation. this system utilizes iot technology in its implementation. this system consists of four iot layers, namely the smart things layer which consists of a water level sensor, water ph sensor, with control using esp8266. networks and gateways layer, which consists of a router to connect smart things with the internet, middleware layer, and application layer which consists of an android application for the system interface. this system contributes directly to the form of convenience for farmers to manage irrigation of rice fields using esp8266 based iot applications. in addition, this system also provides water level information to facilitate farmers in the irrigation process.",,"levels of iot architecture for smart irrigation rice fields. water is one of the main components in the agricultural sector. traditional irrigation systems are often inefficient and ineffective, which can lead to water wastage and require huge resources. intelligent irrigation systems based on the internet of things iot offer a solution to overcome these problems. the purpose of this research is to create a layer iot architecture for smart irrigation in gadon village. the method used in this research uses research and development methods, starting from literature study, field survey, design, assembly, and testing. design of internet of things iot architecture using esp8266 for irrigation of rice fields in gadon village dlingo, bantul. the design of this system aims to facilitate irrigation. this system utilizes iot technology in its implementation. this system consists of four iot layers, namely the smart things layer which consists of a water level sensor, water ph sensor, with control using esp8266. networks and gateways layer, which consists of a router to connect smart things with the internet, middleware layer, and application layer which consists of an android application for the system interface. this system contributes directly to the form of convenience for farmers to manage irrigation of rice fields using esp8266 based iot applications. in addition, this system also provides water level information to facilitate farmers in the irrigation process."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1557,performance evaluation of nas parallel and high performance conjugate gradient benchmarks in mahameru,"high performance computing hpc plays a crucial role in accelerating scientific advancement across numerous fields of research and in effectively implementing various complex scientific applications. mahameru is one of the largest national hpc systems in indonesia and has been utilized by many sectors. however, it has not undergone proper benchmarking evaluation, which is vital for identifying issues related to hardware and software configurations and confirming system reliability. therefore, this study aims to evaluate the performance, efficiency, and capabilities of mahameru. we present a benchmarking system on mahameru utilizing two benchmark suites the nas parallel benchmarks npb and the high performance conjugate gradient hpcg benchmark. our results indicate that the npb exhibits a lower speedup in message passing interface mpi compared to openmp, which can be attributed to the communication overhead and the nature of the computational tasks. additionally, the hpcg benchmark demonstrates that mahameru performance can compete with the lower tiers of the top supercomputers. when operating at full capacity, mahameru can achieve approximately . of its theoretical peak performance. while the system generally performs reliably with parallel algorithms, it may not fully leverage hyperthreading with certain algorithms. this benchmark result can serve as a basis for decision making regarding potential upgrades or changes to a system.",,"performance evaluation of nas parallel and high performance conjugate gradient benchmarks in mahameru. high performance computing hpc plays a crucial role in accelerating scientific advancement across numerous fields of research and in effectively implementing various complex scientific applications. mahameru is one of the largest national hpc systems in indonesia and has been utilized by many sectors. however, it has not undergone proper benchmarking evaluation, which is vital for identifying issues related to hardware and software configurations and confirming system reliability. therefore, this study aims to evaluate the performance, efficiency, and capabilities of mahameru. we present a benchmarking system on mahameru utilizing two benchmark suites the nas parallel benchmarks npb and the high performance conjugate gradient hpcg benchmark. our results indicate that the npb exhibits a lower speedup in message passing interface mpi compared to openmp, which can be attributed to the communication overhead and the nature of the computational tasks. additionally, the hpcg benchmark demonstrates that mahameru performance can compete with the lower tiers of the top supercomputers. when operating at full capacity, mahameru can achieve approximately . of its theoretical peak performance. while the system generally performs reliably with parallel algorithms, it may not fully leverage hyperthreading with certain algorithms. this benchmark result can serve as a basis for decision making regarding potential upgrades or changes to a system."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1499,comparative analysis of indobert and lstm for multi label text classification of indonesian motivation letter,"the evaluation of motivation letters is a crucial step in the student admission process for one of vocational institutions in indonesia. however, the current manual assessment method is prone to subjectivity and inconsistency, making it less reliable for fair student selection. this research presents a comparative analysis of two deep learning models, indobert and long short term memory lstm , for multi label text classification of motivation letters written in indonesian. using a dataset of motivation letters labeled with nine predefined categories, we evaluate the models based on their classification performance. the results indicate that indobert outperforms lstm, achieving an f1 score of , compared to for lstm. this research provides insights into the effectiveness of indobert for multi label classification tasks in the indonesian language and serves as a benchmark for future research in automating motivation letter evaluations.",,"comparative analysis of indobert and lstm for multi label text classification of indonesian motivation letter. the evaluation of motivation letters is a crucial step in the student admission process for one of vocational institutions in indonesia. however, the current manual assessment method is prone to subjectivity and inconsistency, making it less reliable for fair student selection. this research presents a comparative analysis of two deep learning models, indobert and long short term memory lstm , for multi label text classification of motivation letters written in indonesian. using a dataset of motivation letters labeled with nine predefined categories, we evaluate the models based on their classification performance. the results indicate that indobert outperforms lstm, achieving an f1 score of , compared to for lstm. this research provides insights into the effectiveness of indobert for multi label classification tasks in the indonesian language and serves as a benchmark for future research in automating motivation letter evaluations."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1590,optimizing machine learning models for graduation on time prediction a comparative study with resampling and hyperparameter tuning,"timely graduation prediction is a crucial issue in higher education, especially when academic, demographic, and behavioral factors interact in complex ways. however, many previous studies rely on default machine learning ml parameters and fail to consider the class imbalance problem, leading to suboptimal predictions. this study aims to build a comprehensive framework to evaluate the effectiveness of seven ml algorithms, which are adaboost, k nearest neighbors, nave bayes, neural network, random forest, svm rbf, and xgboost, for predicting graduation on time by incorporating five resampling techniques and hyperparameter tuning. resampling methods include random undersampling rus , random oversampling ros , smotenc, and two hybrid approaches rus ros and smotenc rus . hyperparameter tuning was conducted using grid search, and model performance was evaluated through cross validation and hold out methods. the results show that random forest combined with rus ros achieved the best performance, with an average metric score of . . statistical analysis using permanova p . and bonferroni s post hoc pairwise tests confirmed significant differences between certain models. this study contributes to the educational data mining literature by demonstrating that combining resampling and hyperparameter tuning improves classification performance in imbalanced educational datasets.",,"optimizing machine learning models for graduation on time prediction a comparative study with resampling and hyperparameter tuning. timely graduation prediction is a crucial issue in higher education, especially when academic, demographic, and behavioral factors interact in complex ways. however, many previous studies rely on default machine learning ml parameters and fail to consider the class imbalance problem, leading to suboptimal predictions. this study aims to build a comprehensive framework to evaluate the effectiveness of seven ml algorithms, which are adaboost, k nearest neighbors, nave bayes, neural network, random forest, svm rbf, and xgboost, for predicting graduation on time by incorporating five resampling techniques and hyperparameter tuning. resampling methods include random undersampling rus , random oversampling ros , smotenc, and two hybrid approaches rus ros and smotenc rus . hyperparameter tuning was conducted using grid search, and model performance was evaluated through cross validation and hold out methods. the results show that random forest combined with rus ros achieved the best performance, with an average metric score of . . statistical analysis using permanova p . and bonferroni s post hoc pairwise tests confirmed significant differences between certain models. this study contributes to the educational data mining literature by demonstrating that combining resampling and hyperparameter tuning improves classification performance in imbalanced educational datasets."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1612,land cover classification in mountainous regions using multi scale fusion and convolutional neural networks a case study on mount slamet,"mount slamet, located in central java, indonesia, is a high risk volcanic region where accurate land cover classification is essential for disaster mitigation and sustainable land management. however, satellite imagery in this area often suffers from haze and cloud cover, posing challenges to reliable classification. this study aims to develop an effective land cover classification model using sentinel imagery by addressing these visual distortions. the specific goal is to classify land cover into five classesforest, settlements, summit, ricefield, and riverusing enhanced satellite images. a total of labeled images were processed through dehazing with multi scale fusion msf and smoothing using a guided filter to improve image quality. the classification was performed using three convolutional neural network cnn architectures vgg , mobilenetv2, and densenet121. the main contribution of this study is the integration of a tailored preprocessing pipeline with cnn based modeling for haze affected mountainous satellite imagery. among the models tested, mobilenetv2 achieved the highest accuracy of . , outperforming densenet121 . and vgg . . the results demonstrate the effectiveness of combining image enhancement techniques with lightweight cnn architectures for land cover classification in challenging environments with limited and imbalanced dataset.",,"land cover classification in mountainous regions using multi scale fusion and convolutional neural networks a case study on mount slamet. mount slamet, located in central java, indonesia, is a high risk volcanic region where accurate land cover classification is essential for disaster mitigation and sustainable land management. however, satellite imagery in this area often suffers from haze and cloud cover, posing challenges to reliable classification. this study aims to develop an effective land cover classification model using sentinel imagery by addressing these visual distortions. the specific goal is to classify land cover into five classesforest, settlements, summit, ricefield, and riverusing enhanced satellite images. a total of labeled images were processed through dehazing with multi scale fusion msf and smoothing using a guided filter to improve image quality. the classification was performed using three convolutional neural network cnn architectures vgg , mobilenetv2, and densenet121. the main contribution of this study is the integration of a tailored preprocessing pipeline with cnn based modeling for haze affected mountainous satellite imagery. among the models tested, mobilenetv2 achieved the highest accuracy of . , outperforming densenet121 . and vgg . . the results demonstrate the effectiveness of combining image enhancement techniques with lightweight cnn architectures for land cover classification in challenging environments with limited and imbalanced dataset."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1568,performance evaluation of vehicular ad hoc networks considering malicious node impact on quality of services metrics,"vehicular ad hoc networks vanets , a subset of mobile ad hoc networks manets , is essential for enabling communication between vehicles in intelligent transportation systems. however, their dynamic and decentralized nature exposes them to significant security threats, particularly from malicious nodes. attacks such as black holes and wormholes can severely degrade network performance by causing packet loss and increasing end to end delays. this paper aims to evaluate the impact of malicious node behavior on vanet performance using key quality of service qos parameters, including throughput, end to end delay, jitter, packet delivery ratio pdr , and packet loss ratio plr . the specific objective is to analyze how black hole and wormhole attacks affect communication efficiency in vanet environments. the main contribution of this work lies in the integration of simulation of urban mobility sumo for realistic traffic scenario generation with network simulator ns for detailed network performance evaluation. this approach enables comprehensive simulation of vanet behavior under attack conditions. the findings provide valuable insights into the vulnerabilities of vanets and form a basis for the design of more robust and secure vehicular communication systems.",,"performance evaluation of vehicular ad hoc networks considering malicious node impact on quality of services metrics. vehicular ad hoc networks vanets , a subset of mobile ad hoc networks manets , is essential for enabling communication between vehicles in intelligent transportation systems. however, their dynamic and decentralized nature exposes them to significant security threats, particularly from malicious nodes. attacks such as black holes and wormholes can severely degrade network performance by causing packet loss and increasing end to end delays. this paper aims to evaluate the impact of malicious node behavior on vanet performance using key quality of service qos parameters, including throughput, end to end delay, jitter, packet delivery ratio pdr , and packet loss ratio plr . the specific objective is to analyze how black hole and wormhole attacks affect communication efficiency in vanet environments. the main contribution of this work lies in the integration of simulation of urban mobility sumo for realistic traffic scenario generation with network simulator ns for detailed network performance evaluation. this approach enables comprehensive simulation of vanet behavior under attack conditions. the findings provide valuable insights into the vulnerabilities of vanets and form a basis for the design of more robust and secure vehicular communication systems."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1606,a comparison analysis between resnet50 and xception for handwritten hangeul character using transfer learning,"the enthusiasm for korean pop culture in indonesia has contributed to a growing interest in learning the korean language, including its writing system, hangeul, which currently ranks as the 6th most studied language. hangeul has a unique structure, where each character is arranged in syllabic blocks of consonants and vowel combinations. the main challenge in korean character classification lies in the similarity between characters and the complex structure, making it more difficult for models to recognize. this study aims to compare two deep convolutional neural networks are resnet50 and xception, using transfer learning for handwritten hangeul character classification. while previous studies have examined cnn based character recognition, this study highlights the effectiveness of deeper architectures with limited yet augmented data. unlike earlier works, it incorporates grad cam visualizations, transfer learning with partial fine tuning, and multiple train test ratios to analyze model behavior. a total of , images across classes were evaluated using fold cross validation, with extensive augmentation and preprocessing to simulate variation. the machine learning life cycle mllc framework assessed model performance through accuracy, precision, recall, f1 score, and auc. both models achieved high performance, with resnet50 consistently outperforming xception in most folds, especially in precision and f1 score. resnet50 achieved perfect scores across all metrics, while xception also performed strongly with up to . accuracy. these results indicate that resnet50 is more effective in classifying korean letters on the dataset used in this study. for future research, a robustness evaluation can be applied using data that was not included in previous training or testing.",,"a comparison analysis between resnet50 and xception for handwritten hangeul character using transfer learning. the enthusiasm for korean pop culture in indonesia has contributed to a growing interest in learning the korean language, including its writing system, hangeul, which currently ranks as the 6th most studied language. hangeul has a unique structure, where each character is arranged in syllabic blocks of consonants and vowel combinations. the main challenge in korean character classification lies in the similarity between characters and the complex structure, making it more difficult for models to recognize. this study aims to compare two deep convolutional neural networks are resnet50 and xception, using transfer learning for handwritten hangeul character classification. while previous studies have examined cnn based character recognition, this study highlights the effectiveness of deeper architectures with limited yet augmented data. unlike earlier works, it incorporates grad cam visualizations, transfer learning with partial fine tuning, and multiple train test ratios to analyze model behavior. a total of , images across classes were evaluated using fold cross validation, with extensive augmentation and preprocessing to simulate variation. the machine learning life cycle mllc framework assessed model performance through accuracy, precision, recall, f1 score, and auc. both models achieved high performance, with resnet50 consistently outperforming xception in most folds, especially in precision and f1 score. resnet50 achieved perfect scores across all metrics, while xception also performed strongly with up to . accuracy. these results indicate that resnet50 is more effective in classifying korean letters on the dataset used in this study. for future research, a robustness evaluation can be applied using data that was not included in previous training or testing."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1603,forensic analysis of web scraping documents on carding forums and shops using latent dirichlet allocation,"this research is based on the massive cybercrime activity in carding forums and carding shops. based on the many victims and losses from these activities a cybercrime investigation action is needed by a digital forensic investigator. the purpose of this study is to develop a forensic carding investigation framework based on document analysis of web scraping results on carding forums and carding shops, which applies forensic profiling analysis methods and natural language processing based on the latent dirichlet allocation lda algorithm. the tools used for web scraping in this study are webharvy version . . . . the tools used for data processing in this study are microsoft excel and orange data mining. the conclusion of this study shows that the application of web scraping investigation techniques on carding forums and carding shops based on an carding investigation framework has been effective in collecting relevant data and analyzing the activities of cybercriminal appropriately. overall, this study has succeeded in developing a more organized and data driven approach to dealing with crimes in carding forums and carding shops, which can be a reference for further research and application in the field of digital forensic investigation.",,"forensic analysis of web scraping documents on carding forums and shops using latent dirichlet allocation. this research is based on the massive cybercrime activity in carding forums and carding shops. based on the many victims and losses from these activities a cybercrime investigation action is needed by a digital forensic investigator. the purpose of this study is to develop a forensic carding investigation framework based on document analysis of web scraping results on carding forums and carding shops, which applies forensic profiling analysis methods and natural language processing based on the latent dirichlet allocation lda algorithm. the tools used for web scraping in this study are webharvy version . . . . the tools used for data processing in this study are microsoft excel and orange data mining. the conclusion of this study shows that the application of web scraping investigation techniques on carding forums and carding shops based on an carding investigation framework has been effective in collecting relevant data and analyzing the activities of cybercriminal appropriately. overall, this study has succeeded in developing a more organized and data driven approach to dealing with crimes in carding forums and carding shops, which can be a reference for further research and application in the field of digital forensic investigation."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1170,developing an ai enhanced enterprise architecture model for strategic decision making in malaysias railway industry,"most developing nations, including malaysia, still lack a model for the decision making process that is comprehensive enough to account for a wide variety of potential effects and failures. the implementation of this investigation is crucial for enterprise architecture ea parameters for railway industry ri supplier performance that emphasize strategic decision making processes to help the organizations become more competitive. in response to this need, the research integrates artificial intelligence ai as an enabler within the ea model to support intelligent and data driven decision making. this research has implemented a strategic decision making process in the ri context and conducted it from a developing country perspective. the study identifies several elements of the decision making process faced and experienced by the ri and the potential gaps for further observations in adopting the ea model. as a result, a fresh conceptual model enhanced with ai driven analytics and intelligent decision support was created and assessed. by fulfilling the aims of the study, this research makes important contributions to the ri in terms of the use of ea, aligned with the worldwide standard of the four fundamental ea criteria, and explores the transformative potential of ai integration to accelerate ea adoption. the study s findings will impact both theory and practice, providing a pathway for developing nations to harness ai for strategic advantage and digital maturity.",,"developing an ai enhanced enterprise architecture model for strategic decision making in malaysias railway industry. most developing nations, including malaysia, still lack a model for the decision making process that is comprehensive enough to account for a wide variety of potential effects and failures. the implementation of this investigation is crucial for enterprise architecture ea parameters for railway industry ri supplier performance that emphasize strategic decision making processes to help the organizations become more competitive. in response to this need, the research integrates artificial intelligence ai as an enabler within the ea model to support intelligent and data driven decision making. this research has implemented a strategic decision making process in the ri context and conducted it from a developing country perspective. the study identifies several elements of the decision making process faced and experienced by the ri and the potential gaps for further observations in adopting the ea model. as a result, a fresh conceptual model enhanced with ai driven analytics and intelligent decision support was created and assessed. by fulfilling the aims of the study, this research makes important contributions to the ri in terms of the use of ea, aligned with the worldwide standard of the four fundamental ea criteria, and explores the transformative potential of ai integration to accelerate ea adoption. the study s findings will impact both theory and practice, providing a pathway for developing nations to harness ai for strategic advantage and digital maturity."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1631,cyberbullying detection in the libyan dialect using convolutional neural networks,"ecently, the widespread use of social media has increased, leading to increased concerns about cyberbullying. it has become imperative to intensify efforts and methods to detect and manage cyberbullying through social media. arabic has recently received increasing attention to improve the classification of arabic texts. given the multitude of arabic dialects used on social media platforms by arabic speakers to express their opinions and communicate with each other, applying this approach to arabic becomes extremely challenging due to its structural and morphological complexity. analyzing arabic dialects using natural language processing nlp tools can be more challenging than standard arabic. in this paper, the impact of using stopword removal and derivation techniques on detecting cyberbullying in the libyan dialect was presented. the efficiency of text classification was compared when using a libyan dialect word list alongside pre generated modern standard arabic msa lists. the texts were classified using convolutional neural network cnn classifiers, and the experiments showed that when using libyan dialect words, the accuracy results were and , and when using only standard arabic stop words, the accuracy results were dropped to and . based on these results, the higher accuracy was obtained when using the presented stop words list which it is specific to the libyan dialect, and they had a positive impact on the results, better than standard arabic stop words.",,"cyberbullying detection in the libyan dialect using convolutional neural networks. ecently, the widespread use of social media has increased, leading to increased concerns about cyberbullying. it has become imperative to intensify efforts and methods to detect and manage cyberbullying through social media. arabic has recently received increasing attention to improve the classification of arabic texts. given the multitude of arabic dialects used on social media platforms by arabic speakers to express their opinions and communicate with each other, applying this approach to arabic becomes extremely challenging due to its structural and morphological complexity. analyzing arabic dialects using natural language processing nlp tools can be more challenging than standard arabic. in this paper, the impact of using stopword removal and derivation techniques on detecting cyberbullying in the libyan dialect was presented. the efficiency of text classification was compared when using a libyan dialect word list alongside pre generated modern standard arabic msa lists. the texts were classified using convolutional neural network cnn classifiers, and the experiments showed that when using libyan dialect words, the accuracy results were and , and when using only standard arabic stop words, the accuracy results were dropped to and . based on these results, the higher accuracy was obtained when using the presented stop words list which it is specific to the libyan dialect, and they had a positive impact on the results, better than standard arabic stop words."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1632,a trust based reputation system for security in the internet of vehicles iov,"the internet of vehicles iov integrates with different nodes, like for example connected vehicles, roadside units, etc. due to communication exchange, they are exposed to various attacks on the network, which poses a security risk. nevertheless, security is a major concern in iov networks, especially during data transmission. to address this issue, our team suggest an innovative approach. reputation management schema in an iov environment to detect attacks at an early stage based on vehicle and driver behavior along with network state. our algorithm combines direct and indirect trust with various metrics like packet lost rate plr , vehicle speed distance between neighbors, alert content, and link quality. these metrics are used to compute a reputation score to identify malicious nodes. based on its reputation, vehicles communicate with only trusted nodes. after assessment, we see that our solution surpassed the others solution and has demonstrated superior effectiveness in detecting abnormal vehicles. furthermore, the computed delay, equal to . ms, does not affect the network communications, which is interesting for the introduced safety features.",,"a trust based reputation system for security in the internet of vehicles iov. the internet of vehicles iov integrates with different nodes, like for example connected vehicles, roadside units, etc. due to communication exchange, they are exposed to various attacks on the network, which poses a security risk. nevertheless, security is a major concern in iov networks, especially during data transmission. to address this issue, our team suggest an innovative approach. reputation management schema in an iov environment to detect attacks at an early stage based on vehicle and driver behavior along with network state. our algorithm combines direct and indirect trust with various metrics like packet lost rate plr , vehicle speed distance between neighbors, alert content, and link quality. these metrics are used to compute a reputation score to identify malicious nodes. based on its reputation, vehicles communicate with only trusted nodes. after assessment, we see that our solution surpassed the others solution and has demonstrated superior effectiveness in detecting abnormal vehicles. furthermore, the computed delay, equal to . ms, does not affect the network communications, which is interesting for the introduced safety features."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1633,a data science approach to exploring the relationship between tiktok engagement and revenue in malaysia a case study of the beauty and personal care sector,"tiktok has reshaped digital marketing in the beauty and personal care sector, yet the relationship between engagement metrics and revenue outcomes remains unclear. this study aims to examine how public engagement metrics likes, comments, shares, and live interactions relate to revenue performance among tiktok influencers. using the data science trajectories dst framework, data from malaysian influencers across celebrity, macro, meso, and micro categories were analyzed through descriptive statistics and machine learning models implemented in python. the findings reveal that high engagement does not consistently lead to higher revenue. live sessions were more effective than standard videos in driving sales due to real time interaction. while celebrity influencers led in revenue, meso influencers recorded the highest engagement rates. a random forest regression model showed strong predictive power r . , demonstrating that public facing metrics can be used to estimate revenue. the study also introduces category based engagement rate benchmarks and highlights the unique value of live content in converting engagement into sales. this research contributes to the growing body of work on tiktok marketing by combining statistical and predictive techniques to link engagement behavior with commercial outcomes, offering actionable insights for both practitioners and scholars.",,"a data science approach to exploring the relationship between tiktok engagement and revenue in malaysia a case study of the beauty and personal care sector. tiktok has reshaped digital marketing in the beauty and personal care sector, yet the relationship between engagement metrics and revenue outcomes remains unclear. this study aims to examine how public engagement metrics likes, comments, shares, and live interactions relate to revenue performance among tiktok influencers. using the data science trajectories dst framework, data from malaysian influencers across celebrity, macro, meso, and micro categories were analyzed through descriptive statistics and machine learning models implemented in python. the findings reveal that high engagement does not consistently lead to higher revenue. live sessions were more effective than standard videos in driving sales due to real time interaction. while celebrity influencers led in revenue, meso influencers recorded the highest engagement rates. a random forest regression model showed strong predictive power r . , demonstrating that public facing metrics can be used to estimate revenue. the study also introduces category based engagement rate benchmarks and highlights the unique value of live content in converting engagement into sales. this research contributes to the growing body of work on tiktok marketing by combining statistical and predictive techniques to link engagement behavior with commercial outcomes, offering actionable insights for both practitioners and scholars."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1471,modified hash to obtain random subset tree mhorst using merkle tree and mersenne twister,"the development of quantum computing triggers new challenges in data security, particularly in addressing attacks that can solve complex mathematical problems on the fly. several hash based data security methods have been proposed to deal with this threat, one of them being hash to obtain random subset tree horst . however, horst has drawbacks, such as low security, because it only uses one hash round. the security of horst is already improved by hash to obtain random subset and integer composition horsic . however, horsics execution time is significantly increased. the problem of this research is the low security horst and the high execution time of horsic. this research proposes a new method, modified hash to obtain random subset tree mhorst , which aims to improve the security of horst and reduce the execution time to less than horsis. mhorst uses merkle tree, sha hashes, and mersenne twister to build public keys and digital signatures. based on the experiment results, mhorst reduces the signing time by more than . times compared to horst. mhorst reduces the verification time by more than . times horst and times horsic. although the security level of mhorst decreases slightly compared to horsic, this method is still more secure than horst against signature forgery.",,"modified hash to obtain random subset tree mhorst using merkle tree and mersenne twister. the development of quantum computing triggers new challenges in data security, particularly in addressing attacks that can solve complex mathematical problems on the fly. several hash based data security methods have been proposed to deal with this threat, one of them being hash to obtain random subset tree horst . however, horst has drawbacks, such as low security, because it only uses one hash round. the security of horst is already improved by hash to obtain random subset and integer composition horsic . however, horsics execution time is significantly increased. the problem of this research is the low security horst and the high execution time of horsic. this research proposes a new method, modified hash to obtain random subset tree mhorst , which aims to improve the security of horst and reduce the execution time to less than horsis. mhorst uses merkle tree, sha hashes, and mersenne twister to build public keys and digital signatures. based on the experiment results, mhorst reduces the signing time by more than . times compared to horst. mhorst reduces the verification time by more than . times horst and times horsic. although the security level of mhorst decreases slightly compared to horsic, this method is still more secure than horst against signature forgery."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1628,hybrid squeeze and excitation convolutional neural network with elastic weight consolidation for longitudinal learning in high accuracy waste classification,"waste management has become a global issue. increased urbanization and per capita consumption have caused unprecedented garbage growth. sustainability has always been about proper waste management within the ecological framework. recently, numerous studies have been conducted on automating the identification of waste items. in this study, a convolutional neural network cnn model equipped with squeeze and excitation se module is proposed based on hybrid squeezing methods for waste item classification. the core aim of this research is to improve the accuracy of classification by highlighting intricate relations between various features encoded within the dataset. based on extensive tests on a waste dataset, the cnn model with the se module using hybrid squeezing outperforms all other models. the suggested method s . accuracy proves its efficacy and robustness. furthermore, we incorporate elastic weight consolidation ewc to enable longitudinal learning, allowing the model to adapt to emerging waste types e.g., e waste, biodegradable materials while retaining prior knowledge with minimal forgetting . ablation studies validate the critical role of hybrid squeezing, showing a . accuracy drop when spatial wise components are omitted. this revelation affects automated recycling, waste sorting, and intelligent waste management. the proposed technology s accuracy shows its applicability and dependability, advancing sustainable waste management. by automating waste classification with unprecedented precision, the proposed framework can reduce landfill reliance, enhance recycling rates, and inform policy decisions for sustainable urban planning.",,"hybrid squeeze and excitation convolutional neural network with elastic weight consolidation for longitudinal learning in high accuracy waste classification. waste management has become a global issue. increased urbanization and per capita consumption have caused unprecedented garbage growth. sustainability has always been about proper waste management within the ecological framework. recently, numerous studies have been conducted on automating the identification of waste items. in this study, a convolutional neural network cnn model equipped with squeeze and excitation se module is proposed based on hybrid squeezing methods for waste item classification. the core aim of this research is to improve the accuracy of classification by highlighting intricate relations between various features encoded within the dataset. based on extensive tests on a waste dataset, the cnn model with the se module using hybrid squeezing outperforms all other models. the suggested method s . accuracy proves its efficacy and robustness. furthermore, we incorporate elastic weight consolidation ewc to enable longitudinal learning, allowing the model to adapt to emerging waste types e.g., e waste, biodegradable materials while retaining prior knowledge with minimal forgetting . ablation studies validate the critical role of hybrid squeezing, showing a . accuracy drop when spatial wise components are omitted. this revelation affects automated recycling, waste sorting, and intelligent waste management. the proposed technology s accuracy shows its applicability and dependability, advancing sustainable waste management. by automating waste classification with unprecedented precision, the proposed framework can reduce landfill reliance, enhance recycling rates, and inform policy decisions for sustainable urban planning."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1610,enhanced agricultural decision making machine learning approaches for crop prediction and analysis in india,"this paper addresses the critical aspects of agriculture in the indian economy and the challenges faced by this sector, including soil quality decline, unpredictable weather, and the need for efficient decision making. it presents machine learning as a transformative approach for improved agricultural decision making, enabling enhanced crop prediction and productivity. machine learning ml algorithms are shown to effectively analyze vast datasets to generate predictive models that aid in crop selection optimization, disease outbreak prediction, and market fluctuation anticipation, thus leading to increased yields and profitability. focusing on crop prediction, the paper discusses models leveraging historical data and advanced algorithms to forecast crop yields. additionally, the application of machine learning in precision farming, such as optimizing fertilizer application, is explored. the paper uses a mixed method approach on a dataset encompassing various crops and environmental parameters. in this paper the various techniques such as k nearest neighbor knn , support vector machines svm , decision tree dt and random forest rf algorithms have been employed to demonstrate the utility of ml in the agricultural fields. the knn at the value of k and svm with polynomial kernel resulted the accuracy of . and . respectively. whereas dt and rt gave the results in terms of accuracy of . and . respectively. overall, it can be said that all these techniques used in the present work showed the better accuracy for agricultural sustainability.",,"enhanced agricultural decision making machine learning approaches for crop prediction and analysis in india. this paper addresses the critical aspects of agriculture in the indian economy and the challenges faced by this sector, including soil quality decline, unpredictable weather, and the need for efficient decision making. it presents machine learning as a transformative approach for improved agricultural decision making, enabling enhanced crop prediction and productivity. machine learning ml algorithms are shown to effectively analyze vast datasets to generate predictive models that aid in crop selection optimization, disease outbreak prediction, and market fluctuation anticipation, thus leading to increased yields and profitability. focusing on crop prediction, the paper discusses models leveraging historical data and advanced algorithms to forecast crop yields. additionally, the application of machine learning in precision farming, such as optimizing fertilizer application, is explored. the paper uses a mixed method approach on a dataset encompassing various crops and environmental parameters. in this paper the various techniques such as k nearest neighbor knn , support vector machines svm , decision tree dt and random forest rf algorithms have been employed to demonstrate the utility of ml in the agricultural fields. the knn at the value of k and svm with polynomial kernel resulted the accuracy of . and . respectively. whereas dt and rt gave the results in terms of accuracy of . and . respectively. overall, it can be said that all these techniques used in the present work showed the better accuracy for agricultural sustainability."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1638,blockchain enabled secure healthcare data management with modified gazelle optimization and dlt trained rnn bilstm approach,"the growth of the healthcare system has posed challenges in safeguarding patient privacy amidst the storage, distribution and management of medical data. blockchain bc offers a promising result by securely enabling the exchange of medical information. utilizing block chain technology ensures the security of individuals confidential health information. the use of a decentralized, immutable ledger using blockchain technology provides a secure, impenetrable platform for storing and retrieving private medical information, protecting patient privacy. the application of modified gazelle optimization enables the determination of the shortest path for efficient data transfers within the block chain network. by adopting a specialized routing protocol called modified gazelle optimized routing, this approach minimizes latency and maximizes throughput, facilitating continuous and expedited transfer of health data across the network. to assure the data confidentiality and integrity of network nodes, a distributed ledger technology dlt trained recurrent neural network with bidirectional long short term memory rnn bilstm approach is implemented. this advanced deep learning dl technique enhances the security and reliability of the network by detecting and preventing unauthorized access and tampering attempts. the proposed rnn bilstm based intrusion detection system ids efficiently detects different types of attacks with high accuracy. by analyzing network traffic and patterns in real time, the ids have the ability to identify and mitigate harmful internet of things iot requests and various stealthy attack types, including previously unknown threats. the outcomes of this research prove an efficacy and consistency of the proposed strategy in enhancing the security, efficiency and performance matrix with an accuracy of and comparative analysis is done with traditional methods, thereby ensuring an availability and integrity of healthcare data.",,"blockchain enabled secure healthcare data management with modified gazelle optimization and dlt trained rnn bilstm approach. the growth of the healthcare system has posed challenges in safeguarding patient privacy amidst the storage, distribution and management of medical data. blockchain bc offers a promising result by securely enabling the exchange of medical information. utilizing block chain technology ensures the security of individuals confidential health information. the use of a decentralized, immutable ledger using blockchain technology provides a secure, impenetrable platform for storing and retrieving private medical information, protecting patient privacy. the application of modified gazelle optimization enables the determination of the shortest path for efficient data transfers within the block chain network. by adopting a specialized routing protocol called modified gazelle optimized routing, this approach minimizes latency and maximizes throughput, facilitating continuous and expedited transfer of health data across the network. to assure the data confidentiality and integrity of network nodes, a distributed ledger technology dlt trained recurrent neural network with bidirectional long short term memory rnn bilstm approach is implemented. this advanced deep learning dl technique enhances the security and reliability of the network by detecting and preventing unauthorized access and tampering attempts. the proposed rnn bilstm based intrusion detection system ids efficiently detects different types of attacks with high accuracy. by analyzing network traffic and patterns in real time, the ids have the ability to identify and mitigate harmful internet of things iot requests and various stealthy attack types, including previously unknown threats. the outcomes of this research prove an efficacy and consistency of the proposed strategy in enhancing the security, efficiency and performance matrix with an accuracy of and comparative analysis is done with traditional methods, thereby ensuring an availability and integrity of healthcare data."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1330,plant disease detection using digital image processing opportunities and challenges,"diseases in plants affect the yield of the plant itself. agriculture is essential in human life, and if plant conditions are left unchecked, it will result in crop failure, which can affect the economy. many researchers have developed methods to detect plant diseases, ranging from expert systems to deep learning algorithms. machine learning is particularly effective for this task as it relies on datasets composed of plant images, making image processing crucial for the identification process. this article reviews the current literature and identifies several research gaps, opportunities, and challenges that must be addressed. specifically, the article outlines potential avenues for future research in detecting plant diseases using image processing techniques. a significant opportunity exists to develop more effective algorithmic models for detecting plant diseases.",,"plant disease detection using digital image processing opportunities and challenges. diseases in plants affect the yield of the plant itself. agriculture is essential in human life, and if plant conditions are left unchecked, it will result in crop failure, which can affect the economy. many researchers have developed methods to detect plant diseases, ranging from expert systems to deep learning algorithms. machine learning is particularly effective for this task as it relies on datasets composed of plant images, making image processing crucial for the identification process. this article reviews the current literature and identifies several research gaps, opportunities, and challenges that must be addressed. specifically, the article outlines potential avenues for future research in detecting plant diseases using image processing techniques. a significant opportunity exists to develop more effective algorithmic models for detecting plant diseases."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1623,random forest based classification of greywater filtration media for intelligent biofiltration systems,"the increasing volume of domestic wastewater, particularly greywater, has raised the demand for intelligent and adaptive treatment systems to support efficient water reuse. this study aims to develop a classification model for filtration media types physical, chemical, and biological based on water quality data using the random forest algorithm. initial labeling was conducted using the k means clustering method on a publicly available dataset simulated as greywater, based on ten key water quality parameters relevant to irrigation and environmental standards. model evaluation demonstrated excellent classification performance, with a macro f1 score reaching . and consistent results in both fold and fold cross validation. these findings indicate that the proposed model can be integrated into an iot based biofiltration system as an automated classification logic to support adaptive, efficient, and reusable household wastewater treatment in the context of irrigation.",,"random forest based classification of greywater filtration media for intelligent biofiltration systems. the increasing volume of domestic wastewater, particularly greywater, has raised the demand for intelligent and adaptive treatment systems to support efficient water reuse. this study aims to develop a classification model for filtration media types physical, chemical, and biological based on water quality data using the random forest algorithm. initial labeling was conducted using the k means clustering method on a publicly available dataset simulated as greywater, based on ten key water quality parameters relevant to irrigation and environmental standards. model evaluation demonstrated excellent classification performance, with a macro f1 score reaching . and consistent results in both fold and fold cross validation. these findings indicate that the proposed model can be integrated into an iot based biofiltration system as an automated classification logic to support adaptive, efficient, and reusable household wastewater treatment in the context of irrigation."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1516,the application of ai technology in vocational high school curriculum design based on individual student skills in facing the challenges of the 21st century industry,"vocational high schools smk are confronted with the challenge of adapting their curricula to align with the demands of industrial development in the 21st century. an inappropriate curriculum may result in students being inadequately prepared to navigate the demands of the professional world. consequently, the objective of this research is to optimize the smk curriculum through the utilization of an ai based system, thereby enabling students the curriculum to be tailored to the specific skill requirements of individual. the methodology employed is design based research dbr , which entails the analysis of student skill data, the design of an adaptive curriculum, and the evaluation of said curriculum through trials. the research comprised several phases, beginning with data collection and student skills analysis and concluding with an evaluation of student satisfaction with the implemented curriculum. the findings indicated that the introduction of an ai assisted personalized curriculum resulted in an average improvement of in students practical skills over a six month period. furthermore, student satisfaction with the implemented curriculum increased by , from at the outset of implementation to following the introduction of the ai based system. this research can serve as a reference point for the development of more adaptive and responsive smk curricula.",,"the application of ai technology in vocational high school curriculum design based on individual student skills in facing the challenges of the 21st century industry. vocational high schools smk are confronted with the challenge of adapting their curricula to align with the demands of industrial development in the 21st century. an inappropriate curriculum may result in students being inadequately prepared to navigate the demands of the professional world. consequently, the objective of this research is to optimize the smk curriculum through the utilization of an ai based system, thereby enabling students the curriculum to be tailored to the specific skill requirements of individual. the methodology employed is design based research dbr , which entails the analysis of student skill data, the design of an adaptive curriculum, and the evaluation of said curriculum through trials. the research comprised several phases, beginning with data collection and student skills analysis and concluding with an evaluation of student satisfaction with the implemented curriculum. the findings indicated that the introduction of an ai assisted personalized curriculum resulted in an average improvement of in students practical skills over a six month period. furthermore, student satisfaction with the implemented curriculum increased by , from at the outset of implementation to following the introduction of the ai based system. this research can serve as a reference point for the development of more adaptive and responsive smk curricula."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1609,k means based pseudo labeling technique in supervised learning models for regional classification based on types of non communicable diseases,"non communicable diseases ncds pose a critical threat to global public health, with indonesia experiencing significant challenges due to high mortality rates and uneven regional distribution. in banten province, limited access to labeled health data hampers effective, data driven intervention strategies. this study proposes a semi supervised learning approach to develop a regional classification model for ncds. the methodology begins with k means clustering applied to data from community health centers puskesmas to generate pseudo labels. various cluster configurations k to were evaluated, with the optimal result being two clusters based on a silhouette score of . . these clusters were then used to create a semi labeled dataset for supervised learning. eight classification algorithmscn2 rule inducer, k nearest neighbor knn , logistic regression, nave bayes, neural network, random forest, support vector machine svm , and decision treewere trained and compared. among them, the neural network model achieved the highest performance, with an auc of . and an mcc of . , indicating excellent stability and predictive accuracy. the findings validate the effectiveness of semi supervised learning for health classification tasks when labeled data is scarce. this approach can serve as a valuable decision support tool for regional health planning and targeted interventions, enhancing the precision and efficiency of public health responses.",,"k means based pseudo labeling technique in supervised learning models for regional classification based on types of non communicable diseases. non communicable diseases ncds pose a critical threat to global public health, with indonesia experiencing significant challenges due to high mortality rates and uneven regional distribution. in banten province, limited access to labeled health data hampers effective, data driven intervention strategies. this study proposes a semi supervised learning approach to develop a regional classification model for ncds. the methodology begins with k means clustering applied to data from community health centers puskesmas to generate pseudo labels. various cluster configurations k to were evaluated, with the optimal result being two clusters based on a silhouette score of . . these clusters were then used to create a semi labeled dataset for supervised learning. eight classification algorithmscn2 rule inducer, k nearest neighbor knn , logistic regression, nave bayes, neural network, random forest, support vector machine svm , and decision treewere trained and compared. among them, the neural network model achieved the highest performance, with an auc of . and an mcc of . , indicating excellent stability and predictive accuracy. the findings validate the effectiveness of semi supervised learning for health classification tasks when labeled data is scarce. this approach can serve as a valuable decision support tool for regional health planning and targeted interventions, enhancing the precision and efficiency of public health responses."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1333,variational quantum circuit based quantum machine learning approach for predicting corrosion inhibition efficiency of expired pharmaceuticals,"this study examines the potential of quantum machine learning qml to predict the corrosion inhibition capacity of expired pharmaceutical compounds. the investigation employs a qspr model, using features generated from density functional theory dft calculations as input. at the same time, corrosion inhibition efficiency cie values obtained from experimental data serve as the target output. the vqc model demonstrates varied performance across evaluation metrics, especially with encoding and ansatz design. the model achieves fine scores in evaluation metrics, with root mean square error rmse of . , mean absolute error mae of . , and mean absolute deviation mad of . . the research underscores the significance of larger datasets for enhancing predictive accuracy and points to qml s potential in exploring anti corrosion materials. although there are some limitations, this study provides a foundational framework for using qml to predict anti corrosive properties.",,"variational quantum circuit based quantum machine learning approach for predicting corrosion inhibition efficiency of expired pharmaceuticals. this study examines the potential of quantum machine learning qml to predict the corrosion inhibition capacity of expired pharmaceutical compounds. the investigation employs a qspr model, using features generated from density functional theory dft calculations as input. at the same time, corrosion inhibition efficiency cie values obtained from experimental data serve as the target output. the vqc model demonstrates varied performance across evaluation metrics, especially with encoding and ansatz design. the model achieves fine scores in evaluation metrics, with root mean square error rmse of . , mean absolute error mae of . , and mean absolute deviation mad of . . the research underscores the significance of larger datasets for enhancing predictive accuracy and points to qml s potential in exploring anti corrosion materials. although there are some limitations, this study provides a foundational framework for using qml to predict anti corrosive properties."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1362,comparison airport traffic prediction performance using bigru and cnn bigru models,"covid pandemic has significantly disrupted the aviation industry, highlighting the critical need for accurate airport traffic predictions. this study compares the performance of bigru and cnn bigru models to enhance airport traffic forecasting accuracy models from march to december . data preprocessing was performed using python s pandas library. this involved filtering, scaling using min max normalization, and splitting the data into training testing split using python s pandas library. various optimization techniquesrmsprop, adam, nadam, adamax, adamw, and lionwere applied, along with reducelronplateau, to optimize model performance. the models were evaluated using mean absolute percentage error mape , mean absolute error mae , and mean squared error mse . the best predictive performance was observed in the united states using the cnn bigru model with the adam optimizer, achieving the lowest mae of . , mse of . , and mape of . . the use of a balanced dataset, representing each airport s traffic as a percentage of a baseline period, significantly improved prediction accuracy. this research provides valuable insights for stakeholders seeking effective airport traffic prediction methods during unprecedented times.",,"comparison airport traffic prediction performance using bigru and cnn bigru models. covid pandemic has significantly disrupted the aviation industry, highlighting the critical need for accurate airport traffic predictions. this study compares the performance of bigru and cnn bigru models to enhance airport traffic forecasting accuracy models from march to december . data preprocessing was performed using python s pandas library. this involved filtering, scaling using min max normalization, and splitting the data into training testing split using python s pandas library. various optimization techniquesrmsprop, adam, nadam, adamax, adamw, and lionwere applied, along with reducelronplateau, to optimize model performance. the models were evaluated using mean absolute percentage error mape , mean absolute error mae , and mean squared error mse . the best predictive performance was observed in the united states using the cnn bigru model with the adam optimizer, achieving the lowest mae of . , mse of . , and mape of . . the use of a balanced dataset, representing each airport s traffic as a percentage of a baseline period, significantly improved prediction accuracy. this research provides valuable insights for stakeholders seeking effective airport traffic prediction methods during unprecedented times."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1392,synergistic disruption harnessing ai and blockchain for enhanced privacy and security in federated learning,"combining blockchain technology with artificial intelligence ai offers revolutionary possibilities for developing strong solutions that capitalize on each technology s own advantages. blockchain technology makes self executing agreements possible by enabling smart contracts, which reduce the need for middlemen and increase efficiency by precisely encoding contractual terms in code. by using ai oracles, these contracts can communicate with outside data sources and make well informed decisions based on actual occurrences. additionally, there is a lot of potential for improving machine learning and data interchange in terms of privacy, security, and transparency through the integration of blockchain with federated learning. in order to provide accountability and transparency, the blockchain s immutable ledger can painstakingly record every transaction that takes place during the federated learning process, from data submissions to model modifications and remuneration. participants in federated learning networks also develop trust because of blockchain s transparency and resistance to tampering. strong participant verification procedures are put in place to strengthen data integrity and model updates, which raises the system s overall reliability. in the end, this chapter examines novel research avenues for combining blockchain technology with federated learning, providing practical methods and strategies to improve transaction security and privacy and opening the door to a new era of reliable and effective machine learning applications.",,"synergistic disruption harnessing ai and blockchain for enhanced privacy and security in federated learning. combining blockchain technology with artificial intelligence ai offers revolutionary possibilities for developing strong solutions that capitalize on each technology s own advantages. blockchain technology makes self executing agreements possible by enabling smart contracts, which reduce the need for middlemen and increase efficiency by precisely encoding contractual terms in code. by using ai oracles, these contracts can communicate with outside data sources and make well informed decisions based on actual occurrences. additionally, there is a lot of potential for improving machine learning and data interchange in terms of privacy, security, and transparency through the integration of blockchain with federated learning. in order to provide accountability and transparency, the blockchain s immutable ledger can painstakingly record every transaction that takes place during the federated learning process, from data submissions to model modifications and remuneration. participants in federated learning networks also develop trust because of blockchain s transparency and resistance to tampering. strong participant verification procedures are put in place to strengthen data integrity and model updates, which raises the system s overall reliability. in the end, this chapter examines novel research avenues for combining blockchain technology with federated learning, providing practical methods and strategies to improve transaction security and privacy and opening the door to a new era of reliable and effective machine learning applications."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1486,llm based information retrieval for disease detection using semantic similarity,"information retrieval systems are vital for disease prediction, but traditional methods like tf idf struggle with word meanings and produce long, complex vectors. this research uses large language models llms and follows the crisp dm methodology to improve accuracy. using health forum discussions labeled with specific diseases, we split the data into queries and a corpus. semantic similarity is used to retrieve the most relevant text from the corpus. after preprocessing, we compare llms and tf idf, with llms achieving an accuracy of . top k , outperforming tf idf. llms excel by creating shorter, meaningful vectors that preserve context, enabling precise semantic matching. these results demonstrate llms potential to enhance healthcare information retrieval, offering more accurate and context aware solutions. this research highlights how advanced ai can overcome traditional methods limitations, opening new possibilities for medical informatics.",,"llm based information retrieval for disease detection using semantic similarity. information retrieval systems are vital for disease prediction, but traditional methods like tf idf struggle with word meanings and produce long, complex vectors. this research uses large language models llms and follows the crisp dm methodology to improve accuracy. using health forum discussions labeled with specific diseases, we split the data into queries and a corpus. semantic similarity is used to retrieve the most relevant text from the corpus. after preprocessing, we compare llms and tf idf, with llms achieving an accuracy of . top k , outperforming tf idf. llms excel by creating shorter, meaningful vectors that preserve context, enabling precise semantic matching. these results demonstrate llms potential to enhance healthcare information retrieval, offering more accurate and context aware solutions. this research highlights how advanced ai can overcome traditional methods limitations, opening new possibilities for medical informatics."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1549,adoption of artificial intelligence and digital resources among academicians of islamic higher education institutions in indonesia,"this study aimed to assess the readiness, attitudes, knowledge, and skills of lecturers in using artificial intelligence ai and electronic resources er to enhance academic capacity. understanding this adoption level is crucial for effectively integrating ai and er into educational practices. in addition, this study contributes both theoretically and practically to digital scholarship by enhancing digital adoption and competence in education. this mixed method study captured individual experiences and statistical trends related to digital scholarship in higher education. the qualitative method includes interviews, while the quantitative method involves survey questionnaires. the study focuses on lecturers from islamic higher education institutions iheis in indonesia. the results indicate that while lecturers rarely use ai and es, they recognize the potential of digital technology in academic tasks. despite limited exposure to ai and er, ihei lecturers in indonesia can define these technologies accurately. most lecturers actively update their knowledge and consider bias and ethical aspects in ai and es usage. regarding skills, over of respondents reported proficiency in using ai and es, suggesting a growing level of digital competence. these findings suggest that while many ihei lecturers in indonesia are prepared to adopt ai and er, further support may be needed to ensure widespread acceptance.",,"adoption of artificial intelligence and digital resources among academicians of islamic higher education institutions in indonesia. this study aimed to assess the readiness, attitudes, knowledge, and skills of lecturers in using artificial intelligence ai and electronic resources er to enhance academic capacity. understanding this adoption level is crucial for effectively integrating ai and er into educational practices. in addition, this study contributes both theoretically and practically to digital scholarship by enhancing digital adoption and competence in education. this mixed method study captured individual experiences and statistical trends related to digital scholarship in higher education. the qualitative method includes interviews, while the quantitative method involves survey questionnaires. the study focuses on lecturers from islamic higher education institutions iheis in indonesia. the results indicate that while lecturers rarely use ai and es, they recognize the potential of digital technology in academic tasks. despite limited exposure to ai and er, ihei lecturers in indonesia can define these technologies accurately. most lecturers actively update their knowledge and consider bias and ethical aspects in ai and es usage. regarding skills, over of respondents reported proficiency in using ai and es, suggesting a growing level of digital competence. these findings suggest that while many ihei lecturers in indonesia are prepared to adopt ai and er, further support may be needed to ensure widespread acceptance."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1495,modality based modeling with data balancing and dimensionality reduction for early stunting detection,"in indonesia, the stunting rate has reached , significantly higher than the world health organization s who standard of . this high prevalence underscores the urgent need for effective early detection methods. traditional data mining approaches for stunting detection have primarily focused on unimodal data, either tabular or image data alone, limiting the comprehensiveness and accuracy of the detection models. modality based modeling, which integrates image and tabular data, can provide a more holistic view and improve detection accuracy. this research aims to analyze modality based modeling for the early detection of stunting. two modalities, unimodal and multimodal, are used in this study. the main contributions of this research are the development of a comprehensive framework for modality based analysis, the application of advanced data preprocessing techniques, and the comparison of various machine learning algorithms to identify the best model for stunting detection. the dataset, comprising images and tabular data, is sourced from posyandu in sidoarjo, indonesia. image data undergoes preprocessing, including background segmentation and feature extraction using the gray level co occurrence matrix glcm , while tabular data is processed through categorical encoding. the synthetic minority oversampling technique smote addresses class imbalance, and principal component analysis pca is used for dimensionality reduction. unimodal modeling uses tabular or image data alone, while multimodal modeling combines both before classification. the study achieves the best f1 scores of . , . , and . for tabular only, image only, and image tabular modalities, respectively, demonstrating the effectiveness of data balancing and dimensionality reduction techniques.",,"modality based modeling with data balancing and dimensionality reduction for early stunting detection. in indonesia, the stunting rate has reached , significantly higher than the world health organization s who standard of . this high prevalence underscores the urgent need for effective early detection methods. traditional data mining approaches for stunting detection have primarily focused on unimodal data, either tabular or image data alone, limiting the comprehensiveness and accuracy of the detection models. modality based modeling, which integrates image and tabular data, can provide a more holistic view and improve detection accuracy. this research aims to analyze modality based modeling for the early detection of stunting. two modalities, unimodal and multimodal, are used in this study. the main contributions of this research are the development of a comprehensive framework for modality based analysis, the application of advanced data preprocessing techniques, and the comparison of various machine learning algorithms to identify the best model for stunting detection. the dataset, comprising images and tabular data, is sourced from posyandu in sidoarjo, indonesia. image data undergoes preprocessing, including background segmentation and feature extraction using the gray level co occurrence matrix glcm , while tabular data is processed through categorical encoding. the synthetic minority oversampling technique smote addresses class imbalance, and principal component analysis pca is used for dimensionality reduction. unimodal modeling uses tabular or image data alone, while multimodal modeling combines both before classification. the study achieves the best f1 scores of . , . , and . for tabular only, image only, and image tabular modalities, respectively, demonstrating the effectiveness of data balancing and dimensionality reduction techniques."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1438,application of self organizing map and k means to cluster bandwidth usage patterns in campus environment,"unequal bandwidth distribution in campus environments often stems from a lack of understanding of wifi usage patterns, as seen at itenas bandung. here, bandwidth is allocated equally across all buildings, ignoring differences in demand, leading to inefficiencies in high usage areas and poor money management due to unnecessary allocation of resources to low demand buildings. this study aims to optimize bandwidth allocation by analyzing usage patterns using a combination of self organizing map som and k means clustering methods. som is used to group buildings into low, medium, and high bandwidth usage categories, while k means refines these clusters to enhance accuracy. the proposed approach demonstrated significant improvements in clustering quality, with the silhouette index increasing from . to . and the davies bouldin index dropping from . to . in the first test. similar enhancements were observed in subsequent tests, highlighting the effectiveness of this method in addressing unequal bandwidth distribution. this research offers a practical solution for more efficient network and financial management in educational institutions.",,"application of self organizing map and k means to cluster bandwidth usage patterns in campus environment. unequal bandwidth distribution in campus environments often stems from a lack of understanding of wifi usage patterns, as seen at itenas bandung. here, bandwidth is allocated equally across all buildings, ignoring differences in demand, leading to inefficiencies in high usage areas and poor money management due to unnecessary allocation of resources to low demand buildings. this study aims to optimize bandwidth allocation by analyzing usage patterns using a combination of self organizing map som and k means clustering methods. som is used to group buildings into low, medium, and high bandwidth usage categories, while k means refines these clusters to enhance accuracy. the proposed approach demonstrated significant improvements in clustering quality, with the silhouette index increasing from . to . and the davies bouldin index dropping from . to . in the first test. similar enhancements were observed in subsequent tests, highlighting the effectiveness of this method in addressing unequal bandwidth distribution. this research offers a practical solution for more efficient network and financial management in educational institutions."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1409,the impact of online reviews to predict the number of international tourists,"the tourism sector is a potential resource for advancing the indonesian economy. the development of the tourism industry is represented by the number of international tourist arrivals. therefore, this indicator becomes an objective in development programs. to accomplish this goal and assess the demand aspect of the tourism sector, it is a must to have a precise forecast of the number of international visitors. this research attempts to develop precise methods and models for estimating the number of international tourists based on this premise. this study chooses bali province as its focus since nearly half, or , of the tourists who visit indonesia arrive through the entry point in bali province. this research uses the lstm method and big data online reviews in building prediction models. the results of this study show that sentiment analysis of tourist attractions in bali using the bert model has an accuracy of . the results also depict that reviews by visitors about tourist attractions in bali province during the period contain more positive sentiments. furthermore, the best model to predict the number of international tourists, with the smallest rmse and mape values , . and . , respectively , includes inflation, rupiah exchange rates, tpk, monthly sentiment scores, and the number of reviews as dependent variables. the prediction model also show that the review variables sentiment score and number of reviews can improve prediction accuracy.",,"the impact of online reviews to predict the number of international tourists. the tourism sector is a potential resource for advancing the indonesian economy. the development of the tourism industry is represented by the number of international tourist arrivals. therefore, this indicator becomes an objective in development programs. to accomplish this goal and assess the demand aspect of the tourism sector, it is a must to have a precise forecast of the number of international visitors. this research attempts to develop precise methods and models for estimating the number of international tourists based on this premise. this study chooses bali province as its focus since nearly half, or , of the tourists who visit indonesia arrive through the entry point in bali province. this research uses the lstm method and big data online reviews in building prediction models. the results of this study show that sentiment analysis of tourist attractions in bali using the bert model has an accuracy of . the results also depict that reviews by visitors about tourist attractions in bali province during the period contain more positive sentiments. furthermore, the best model to predict the number of international tourists, with the smallest rmse and mape values , . and . , respectively , includes inflation, rupiah exchange rates, tpk, monthly sentiment scores, and the number of reviews as dependent variables. the prediction model also show that the review variables sentiment score and number of reviews can improve prediction accuracy."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1390,a comparison of yolov8 series performance in student facial expressions detection on online learning,"student engagement in online learning is an important factor that can affect learning outcomes. one indicator of engagement is facial expression. however, research on facial expression detection in online learning environments is still limited, especially in the use of the yolov8 algorithm. this study aims to compare the performance of several yolov8 variants, namely yolov8x, yolov8m, yolov8s, yolov8n, and yolov8l in recognizing six facial expressions happy, sad, angry, surprised, afraid, and neutral. student facial expression data was collected through the moodle platform every seconds during the learning process. all models were trained using 640x640 pixel images for epochs to improve facial expression detection capabilities. the main contribution of this study is to provide a comprehensive analysis of the effectiveness of yolov8 in detecting student facial expressions, which can be used to improve the online learning experience. the evaluation results show that the yolov8s model has the best performance with the highest map of . and the fastest inference speed of . ms per image. yolov8m and yolov8x also performed well with map of . and . , respectively. although yolov8x had the slowest inference speed, it was superior in detecting fear, happiness, and sadness expressions with map above . . yolov8n had map of . , while yolov8l achieved map of . with an inference speed of . ms per image. this study shows that the yolov8 algorithm, especially yolov8s, can be an effective solution to analyze student engagement based on their facial expressions during online learning.",,"a comparison of yolov8 series performance in student facial expressions detection on online learning. student engagement in online learning is an important factor that can affect learning outcomes. one indicator of engagement is facial expression. however, research on facial expression detection in online learning environments is still limited, especially in the use of the yolov8 algorithm. this study aims to compare the performance of several yolov8 variants, namely yolov8x, yolov8m, yolov8s, yolov8n, and yolov8l in recognizing six facial expressions happy, sad, angry, surprised, afraid, and neutral. student facial expression data was collected through the moodle platform every seconds during the learning process. all models were trained using 640x640 pixel images for epochs to improve facial expression detection capabilities. the main contribution of this study is to provide a comprehensive analysis of the effectiveness of yolov8 in detecting student facial expressions, which can be used to improve the online learning experience. the evaluation results show that the yolov8s model has the best performance with the highest map of . and the fastest inference speed of . ms per image. yolov8m and yolov8x also performed well with map of . and . , respectively. although yolov8x had the slowest inference speed, it was superior in detecting fear, happiness, and sadness expressions with map above . . yolov8n had map of . , while yolov8l achieved map of . with an inference speed of . ms per image. this study shows that the yolov8 algorithm, especially yolov8s, can be an effective solution to analyze student engagement based on their facial expressions during online learning."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1228,"anatomy of sentiment analysis in ontological, epistemological, and axiological perspectives","the aim of this article was to examine sentiment analysis methods from the perspective of the philosophy of science with three approaches, ontological, epistemological and axiological. this research used a qualitative research method descriptive analysis with an ontological, epistemological and axiological approach that uses library research and document studies of previous research results. data collection was carried out through books and reputable scientific journals on scopus, sciencedirect, ieeexplore and springer link. the results of this research showed that sentiment analysis from an ontological perspective describes the definition, development and relationship of sentiment with social reality. meanwhile, from an epistemological perspective, sentiment analysis is viewed from how the source of knowledge is obtained, explaining the production of sentiment analysis knowledge, and several ways of working that can be applied in studies. axiologically, sentiment analysis can see the function and value resulting from sentiment analysis, as well as discussing the results of interpretation from sentiment analysis studies. these findings showed the development of sentiment analysis in answering various problems to improve the quality of sustainable services in various fields.",,"anatomy of sentiment analysis in ontological, epistemological, and axiological perspectives. the aim of this article was to examine sentiment analysis methods from the perspective of the philosophy of science with three approaches, ontological, epistemological and axiological. this research used a qualitative research method descriptive analysis with an ontological, epistemological and axiological approach that uses library research and document studies of previous research results. data collection was carried out through books and reputable scientific journals on scopus, sciencedirect, ieeexplore and springer link. the results of this research showed that sentiment analysis from an ontological perspective describes the definition, development and relationship of sentiment with social reality. meanwhile, from an epistemological perspective, sentiment analysis is viewed from how the source of knowledge is obtained, explaining the production of sentiment analysis knowledge, and several ways of working that can be applied in studies. axiologically, sentiment analysis can see the function and value resulting from sentiment analysis, as well as discussing the results of interpretation from sentiment analysis studies. these findings showed the development of sentiment analysis in answering various problems to improve the quality of sustainable services in various fields."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1481,road damage detection using yolov7 with cluster weighted distance iou nms,"road damage can occur everywhere. potholes are one of the most common types of road damage. previous research that used images as input for pothole detection used the faster regional convolutional neural network r cnn method. it has a large inference time because it is a two stage detection method. the object detection method requires post processing for its detection results to save only the best prediction from the method, namely, non maximum suppression nms . however, the original nms could not properly detect small, far, and two objects close to each other. therefore, this research uses the yolov7 method as the object detection method because it has better mean average precision map results and a lower inference time than other object detection methods with an improved nms method, namely cluster weighted distance intersection over union diou nms cwd nms , to solve small or close potholes. when training yolov7, we combined a new, independently collected pothole dataset, with previous public research datasets, where the detection results of the yolov7 method were better than those of faster r cnn. the yolov7 method was trained using various scenarios. the best scenario during training is using the best checkpoint without using a scheduler. the map. and map. . value of cwd nms was . and . with . millisecond per image for inference time.",,"road damage detection using yolov7 with cluster weighted distance iou nms. road damage can occur everywhere. potholes are one of the most common types of road damage. previous research that used images as input for pothole detection used the faster regional convolutional neural network r cnn method. it has a large inference time because it is a two stage detection method. the object detection method requires post processing for its detection results to save only the best prediction from the method, namely, non maximum suppression nms . however, the original nms could not properly detect small, far, and two objects close to each other. therefore, this research uses the yolov7 method as the object detection method because it has better mean average precision map results and a lower inference time than other object detection methods with an improved nms method, namely cluster weighted distance intersection over union diou nms cwd nms , to solve small or close potholes. when training yolov7, we combined a new, independently collected pothole dataset, with previous public research datasets, where the detection results of the yolov7 method were better than those of faster r cnn. the yolov7 method was trained using various scenarios. the best scenario during training is using the best checkpoint without using a scheduler. the map. and map. . value of cwd nms was . and . with . millisecond per image for inference time."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1472,study of the application of text augmentation with paraphrasing to overcome imbalanced data in indonesian text classification,"data imbalance in text classification often leads to poor recognition of minority classes, as classifiers tend to favor majority categories. this study addresses the data imbalance issue in indonesian text classification by proposing a novel text augmentation approach using fine tuned pre trained models indogpt2, indobart v2, and mbart50. unlike back translation, which struggles with informal text, text augmentation using pre trained models significantly improves the f1 score of minority labels, with fine tuned mbart50 outperforming back translation and other models by balancing semantic preservation and lexical diversity. however, the approach faces limitations, including the risk of overfitting due to synthetic text s lack of natural variations, restricted generalizability from reliance on datasets such as paracotta, and the high computational costs associated with fine tuning large models like mbart50. future research should explore hybrid methods that integrate synthetic and real world data to enhance text quality and diversity, as well as develop smaller, more efficient models to reduce computational demands. the findings underscore the potential of pre trained models for text augmentation while emphasizing the importance of considering dataset characteristics, language style, and augmentation volume to achieve optimal results.",,"study of the application of text augmentation with paraphrasing to overcome imbalanced data in indonesian text classification. data imbalance in text classification often leads to poor recognition of minority classes, as classifiers tend to favor majority categories. this study addresses the data imbalance issue in indonesian text classification by proposing a novel text augmentation approach using fine tuned pre trained models indogpt2, indobart v2, and mbart50. unlike back translation, which struggles with informal text, text augmentation using pre trained models significantly improves the f1 score of minority labels, with fine tuned mbart50 outperforming back translation and other models by balancing semantic preservation and lexical diversity. however, the approach faces limitations, including the risk of overfitting due to synthetic text s lack of natural variations, restricted generalizability from reliance on datasets such as paracotta, and the high computational costs associated with fine tuning large models like mbart50. future research should explore hybrid methods that integrate synthetic and real world data to enhance text quality and diversity, as well as develop smaller, more efficient models to reduce computational demands. the findings underscore the potential of pre trained models for text augmentation while emphasizing the importance of considering dataset characteristics, language style, and augmentation volume to achieve optimal results."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1578,pyramid quantum neural network based resource allocation with iot a deep learning method,"as more smart devices are connected and collecting massive quantities of data, the internet of things is growing rapidly. resource management is another crucial issue since iot networks are very diverse and often built and rebuilt dynamically. this study introduces a new kind of deep learning model known as the pyramid quantum neural network py qnn to solve the problem of resource allocation in internet of things systems. py qnn builds on quantum computing to improve the accuracy, scalability, and computation performance of deep learning. because of superposition and entanglement, which increase generalization and provide faster convergence, qnns enhance learning capabilities. the pyramid structure also helps manage the hierarchy of iot networks. in order to forecast efficient resource assignment and implement this as soon as feasible to lower latency and boost efficiency, py qnn uses simulated resource and network requirements. experimental findings demonstrate that py qnn outperforms baseline common deep learning techniques by reducing resource waste and offering online solutions, especially in large and complex iot networks.",,"pyramid quantum neural network based resource allocation with iot a deep learning method. as more smart devices are connected and collecting massive quantities of data, the internet of things is growing rapidly. resource management is another crucial issue since iot networks are very diverse and often built and rebuilt dynamically. this study introduces a new kind of deep learning model known as the pyramid quantum neural network py qnn to solve the problem of resource allocation in internet of things systems. py qnn builds on quantum computing to improve the accuracy, scalability, and computation performance of deep learning. because of superposition and entanglement, which increase generalization and provide faster convergence, qnns enhance learning capabilities. the pyramid structure also helps manage the hierarchy of iot networks. in order to forecast efficient resource assignment and implement this as soon as feasible to lower latency and boost efficiency, py qnn uses simulated resource and network requirements. experimental findings demonstrate that py qnn outperforms baseline common deep learning techniques by reducing resource waste and offering online solutions, especially in large and complex iot networks."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1441,multi platform detection of melon leaf abnormalities using avgheq and yolov7,"this research develops a multiplatform system for detecting abnormalities in melon leaves, integrating an internet of things iot approach using jetson nano, a streamlit based website, and a mobile application for real time monitoring. the system employs preprocessing with average histogram equalization avgheq to enhance image quality, followed by modeling with the yolov7 algorithm on a dataset of training images and test images, validated through fold cross validation. the model achieved a mean average precision map of with an inference detection time of . milliseconds. implementation on jetson nano resulted in a increase in cpu usage from to and a increase in ram usage from to . by combining these platforms and leveraging robust data preprocessing and modeling techniques, the system provides an accessible, efficient, and scalable solution for agricultural monitoring, enabling farmers to address plant health issues promptly and effectively.",,"multi platform detection of melon leaf abnormalities using avgheq and yolov7. this research develops a multiplatform system for detecting abnormalities in melon leaves, integrating an internet of things iot approach using jetson nano, a streamlit based website, and a mobile application for real time monitoring. the system employs preprocessing with average histogram equalization avgheq to enhance image quality, followed by modeling with the yolov7 algorithm on a dataset of training images and test images, validated through fold cross validation. the model achieved a mean average precision map of with an inference detection time of . milliseconds. implementation on jetson nano resulted in a increase in cpu usage from to and a increase in ram usage from to . by combining these platforms and leveraging robust data preprocessing and modeling techniques, the system provides an accessible, efficient, and scalable solution for agricultural monitoring, enabling farmers to address plant health issues promptly and effectively."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1422,forecasting shallot prices in indonesia using news based sentiment indicators,"the volatile price changes of shallots are a challenge in controlling their prices. the fluctuation in the price of shallots is always reported in the media because it affects people s lives. the news is released online via the internet and has beneficial information so it can be utilized. this study aims to provide a comparative analysis of forecasting models for shallot prices in indonesia, evaluating the impact of using the most effective sentiment indicators derived from four lexicon based methods. data were collected by scraping method on three news portals and one food price information source website during the period from to . the correlation and causality analysis was conducted to determine the relationship between food prices and sentiment indicators that was obtained using four sentiment analysis methods. the selected sentiment indicators for each day were used as an additional variable in forecasting using arima, sarima, and bsts models. the results showed that the use of news sentiment could reduce rmse, mape, and mae in forecasting shallot food prices.",,"forecasting shallot prices in indonesia using news based sentiment indicators. the volatile price changes of shallots are a challenge in controlling their prices. the fluctuation in the price of shallots is always reported in the media because it affects people s lives. the news is released online via the internet and has beneficial information so it can be utilized. this study aims to provide a comparative analysis of forecasting models for shallot prices in indonesia, evaluating the impact of using the most effective sentiment indicators derived from four lexicon based methods. data were collected by scraping method on three news portals and one food price information source website during the period from to . the correlation and causality analysis was conducted to determine the relationship between food prices and sentiment indicators that was obtained using four sentiment analysis methods. the selected sentiment indicators for each day were used as an additional variable in forecasting using arima, sarima, and bsts models. the results showed that the use of news sentiment could reduce rmse, mape, and mae in forecasting shallot food prices."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1545,reviewing the blockchains framework and its role in sustainable industries,"blockchain technology is often regarded as a highly advanced and pioneering breakthrough in modern times. blockchain technology is a distributed ledger that uses encryption to prevent security breaches and securely stores data across many systems. this facilitates collaborative transactions by providing a solitary, dependable reference point, revealing the purported trust intermediaries. this study aims to investigate the core principles of blockchain technology and assess its potential to support sustainability across various sectors. it seeks to examine how blockchain technology enhances reliability, effectiveness, and transparency in industries such as supply chain management and the energy sector. this study addresses these concerns by assessing the valuable applications, advantages, and drawbacks of blockchain in promoting sustainable industrial practices. bitcoin and other cryptocurrencies rely on hashing as the foundation of their blockchain technology. blockchain is a digital ledger that documents and tracks financial transactions. blockchain technology has become prevalent across several sectors, encompassing artificial intelligence, machine learning, and the internet of things. therefore, once the blockchain is prepared for dissemination, the data cannot be modified by anyone. this implies that it is immutable. hyperledger offers a neutral platform for facilitating collaborative operations among organisations that frequently engage in competitive activities. hyperledger is specifically designed to provide explicit support for blockchains as a means of business agreements. authorisation is a prerequisite for a framework, ensuring that only those with proper authorisation can join the organisation. the ability of the manager to impose limitations on user access to the blockchain enhances security measures. moreover, instead of being universally accessible through online platforms, trades are maintained secretly, limiting access to only essential participants. using distributed code bases and open source record upgrades facilitates enhanced efficiency in corporate activities. the fast expansion of blockchain technology has led to its widespread adoption across several industries worldwide. illustrations encompass various domains, including logistics, copyright, finance, medicine, and supply chain management. furthermore, we offer an introductory overview of blockchain technology, encompassing topics such as different types of blockchains and their utilisation across many sectors.",,"reviewing the blockchains framework and its role in sustainable industries. blockchain technology is often regarded as a highly advanced and pioneering breakthrough in modern times. blockchain technology is a distributed ledger that uses encryption to prevent security breaches and securely stores data across many systems. this facilitates collaborative transactions by providing a solitary, dependable reference point, revealing the purported trust intermediaries. this study aims to investigate the core principles of blockchain technology and assess its potential to support sustainability across various sectors. it seeks to examine how blockchain technology enhances reliability, effectiveness, and transparency in industries such as supply chain management and the energy sector. this study addresses these concerns by assessing the valuable applications, advantages, and drawbacks of blockchain in promoting sustainable industrial practices. bitcoin and other cryptocurrencies rely on hashing as the foundation of their blockchain technology. blockchain is a digital ledger that documents and tracks financial transactions. blockchain technology has become prevalent across several sectors, encompassing artificial intelligence, machine learning, and the internet of things. therefore, once the blockchain is prepared for dissemination, the data cannot be modified by anyone. this implies that it is immutable. hyperledger offers a neutral platform for facilitating collaborative operations among organisations that frequently engage in competitive activities. hyperledger is specifically designed to provide explicit support for blockchains as a means of business agreements. authorisation is a prerequisite for a framework, ensuring that only those with proper authorisation can join the organisation. the ability of the manager to impose limitations on user access to the blockchain enhances security measures. moreover, instead of being universally accessible through online platforms, trades are maintained secretly, limiting access to only essential participants. using distributed code bases and open source record upgrades facilitates enhanced efficiency in corporate activities. the fast expansion of blockchain technology has led to its widespread adoption across several industries worldwide. illustrations encompass various domains, including logistics, copyright, finance, medicine, and supply chain management. furthermore, we offer an introductory overview of blockchain technology, encompassing topics such as different types of blockchains and their utilisation across many sectors."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1506,performance of machine learning algorithms on automatic summarization of indonesian language texts,"automatic text summarization ats has become an essential task for processing huge amounts of information efficiently. ats has been extensively studied in resource rich languages like english, but research on summarization for under resourced languages, such as bahasa indonesia, is still limited. indonesian presents unique linguistic challenges, including its agglutinative structure, borrowed vocabulary, and limited availability of high quality training data. this study conducts a comparative evaluation of extractive, abstractive, and hybrid models for indonesian text summarization, utilizing the indosum dataset which contains , text summary pairs. we tested several models including lsa latent semantic analysis , lexrank, t5, and bart, to assess their effectiveness in generating summaries. the results show that the lexrank bert hybrid model outperforms traditional extractive methods, achieving better rouge precision, recall, and f measure scores. among the abstractive methods, the t5 large model demonstrated the best performance, producing more coherent and semantically rich summaries compared to other models. these findings suggest that hybrid and abstractive approaches are better suited for indonesian text summarization, especially when leveraging large scale pre trained language models.",,"performance of machine learning algorithms on automatic summarization of indonesian language texts. automatic text summarization ats has become an essential task for processing huge amounts of information efficiently. ats has been extensively studied in resource rich languages like english, but research on summarization for under resourced languages, such as bahasa indonesia, is still limited. indonesian presents unique linguistic challenges, including its agglutinative structure, borrowed vocabulary, and limited availability of high quality training data. this study conducts a comparative evaluation of extractive, abstractive, and hybrid models for indonesian text summarization, utilizing the indosum dataset which contains , text summary pairs. we tested several models including lsa latent semantic analysis , lexrank, t5, and bart, to assess their effectiveness in generating summaries. the results show that the lexrank bert hybrid model outperforms traditional extractive methods, achieving better rouge precision, recall, and f measure scores. among the abstractive methods, the t5 large model demonstrated the best performance, producing more coherent and semantically rich summaries compared to other models. these findings suggest that hybrid and abstractive approaches are better suited for indonesian text summarization, especially when leveraging large scale pre trained language models."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1576,generative adversarial networks in object detection a systematic literature review,"the intersection of generative adversarial networks gans and object detection represents one of the most promising developments in modern computer vision, offering innovative solutions to longstanding challenges in visual recognition systems. this review presents a systematic analysis of how gans are transforming these challenges, examining their applications from to . the paper investigates three primary domains where gans have demonstrated remarkable potential data augmentation for addressing data scarcity, occlusion handling techniques designed to manage visually obstructed objects, and enhancement methods specifically focused on improving small object detection performance. analysis reveals significant performance improvements resulting from these gan applications data augmentation methods consistently boost detection metrics such as map and f1 score on scarce datasets, occlusion handling techniques successfully reconstruct hidden features with high psnr and ssim values, and small object detection techniques increase detection accuracy by up to average precision in some studies. collectively, these findings demonstrate how gans, integrated with modern detectors, are greatly advancing object detection capabilities. despite this progress, persistent challenges including computational cost and training stability remain. by critically analyzing these advancements and limitations, this paper provides crucial insights into the current state and potential future developments of gan based object detection systems.",,"generative adversarial networks in object detection a systematic literature review. the intersection of generative adversarial networks gans and object detection represents one of the most promising developments in modern computer vision, offering innovative solutions to longstanding challenges in visual recognition systems. this review presents a systematic analysis of how gans are transforming these challenges, examining their applications from to . the paper investigates three primary domains where gans have demonstrated remarkable potential data augmentation for addressing data scarcity, occlusion handling techniques designed to manage visually obstructed objects, and enhancement methods specifically focused on improving small object detection performance. analysis reveals significant performance improvements resulting from these gan applications data augmentation methods consistently boost detection metrics such as map and f1 score on scarce datasets, occlusion handling techniques successfully reconstruct hidden features with high psnr and ssim values, and small object detection techniques increase detection accuracy by up to average precision in some studies. collectively, these findings demonstrate how gans, integrated with modern detectors, are greatly advancing object detection capabilities. despite this progress, persistent challenges including computational cost and training stability remain. by critically analyzing these advancements and limitations, this paper provides crucial insights into the current state and potential future developments of gan based object detection systems."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1356,simulation and empirical studies of long short term memory performance to deal with limited data,"this research is proposed to determine the performance of time series machine learning in the presence of noise, where this approach is intended to forecast time series data. the approach method chosen is long short term memory lstm , a development of recurrent neural network rnn . another problem is the availability of data, which is not limited to high dimensional data but also limited data. therefore, this study tests the performance of long short term memory using simulated data, where the simulated data used in this study are data generated from the functional autoregressive far model and data generated from the functional autoregressive model of order far which is given additional noise. simulation results show that the long short term memory method in analyzing time series data in the presence of noise outperforms by the method without noise and data with limited observations. the best performance of the method is determined by testing the analysis of variance against the mean absolute percentage error. in addition, the empirical data used in this study are the percentage of poverty, unemployment, and economic growth in java. the method that has the best performance in analyzing each poverty data is used to forecast the data. the comparison result for the empirical data is that the m lstm method outperforms the lstm in analyzing the poverty percentage data. the best method performance is determined based on the average value of the mean absolute percentage error of .",,"simulation and empirical studies of long short term memory performance to deal with limited data. this research is proposed to determine the performance of time series machine learning in the presence of noise, where this approach is intended to forecast time series data. the approach method chosen is long short term memory lstm , a development of recurrent neural network rnn . another problem is the availability of data, which is not limited to high dimensional data but also limited data. therefore, this study tests the performance of long short term memory using simulated data, where the simulated data used in this study are data generated from the functional autoregressive far model and data generated from the functional autoregressive model of order far which is given additional noise. simulation results show that the long short term memory method in analyzing time series data in the presence of noise outperforms by the method without noise and data with limited observations. the best performance of the method is determined by testing the analysis of variance against the mean absolute percentage error. in addition, the empirical data used in this study are the percentage of poverty, unemployment, and economic growth in java. the method that has the best performance in analyzing each poverty data is used to forecast the data. the comparison result for the empirical data is that the m lstm method outperforms the lstm in analyzing the poverty percentage data. the best method performance is determined based on the average value of the mean absolute percentage error of ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1571,enhancing weather monitoring for agriculture with deep learning anomaly detection in east java using lstm autoencoder and ocsvm,"agricultural productivity in east java is under threat from unpredictable and harsh weather patterns, particularly rapid variations in sunlight length and rainfall intensity. these abnormalities can interrupt agricultural cycles, lower yields, and make farming communities more vulnerable to climatic calamities. however, current weather monitoring systems frequently fall short of detecting small anomalies in time series weather data that could serve as early warning signs of such disasters. this study seeks to close this gap by creating a robust anomaly detection methodology adapted to time dependent weather variables important to agriculture. in this study, a hybrid model combining long short term memory lstm autoencoder and one class support vector machine ocsvm is proposed. the lstm autoencoder s structure reconstructs time series data and signifiesanomalies through reconstruction errors mse , while ocsvm validates these anomalies to reduce false positives. the model was applied to daily weather data from east java spanning . the results showed that the model effectively detected anomalies in sunlight duration and in rainfall, with f1 scores of . and . , respectively. several of these anomalies corresponded to actual disaster events such as floods, landslides, and droughts. this research contributed to the field by demonstrating the effectiveness of combining deep learning and machine learning for weather anomaly detection. the proposed framework offers valuable insights for early warning systems and can support local governments and farmers in improving disaster preparedness and enhancing agricultural resilience in east java.",,"enhancing weather monitoring for agriculture with deep learning anomaly detection in east java using lstm autoencoder and ocsvm. agricultural productivity in east java is under threat from unpredictable and harsh weather patterns, particularly rapid variations in sunlight length and rainfall intensity. these abnormalities can interrupt agricultural cycles, lower yields, and make farming communities more vulnerable to climatic calamities. however, current weather monitoring systems frequently fall short of detecting small anomalies in time series weather data that could serve as early warning signs of such disasters. this study seeks to close this gap by creating a robust anomaly detection methodology adapted to time dependent weather variables important to agriculture. in this study, a hybrid model combining long short term memory lstm autoencoder and one class support vector machine ocsvm is proposed. the lstm autoencoder s structure reconstructs time series data and signifiesanomalies through reconstruction errors mse , while ocsvm validates these anomalies to reduce false positives. the model was applied to daily weather data from east java spanning . the results showed that the model effectively detected anomalies in sunlight duration and in rainfall, with f1 scores of . and . , respectively. several of these anomalies corresponded to actual disaster events such as floods, landslides, and droughts. this research contributed to the field by demonstrating the effectiveness of combining deep learning and machine learning for weather anomaly detection. the proposed framework offers valuable insights for early warning systems and can support local governments and farmers in improving disaster preparedness and enhancing agricultural resilience in east java."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1300,cassava diseases classification using efficientnet model with imbalance data handling,"this research highlights the urgent need for classifying cassava diseases into five classes, such as cassava bacterial blight cbb , cassava brown streak disease cbsd , cassava green mottle cgm , and cassava mosaic disease cmd , and healthy. the study proposes the utilization of the efficientnet model, a lightweight deep learning architecture, for classifying cassava diseases based on leaf images. however, the datasets available for this classification task are all unbalanced, made it difficult for researchers to perform. to tackle this imbalance issue, the authors compared several imbalance data handling methods commonly used for image classification, including smote synthetic minority oversampling technique , basic augmentation, and neural style transfer, to be applied before fed into efficientnet. initially, efficientnet model without addressing dataset imbalances, the f1 score stands at , with most images misclassified into the majority class. integration with smote notably boosts the f1 score to , showcasing the efficacy of oversampling methods in enhancing model performance. conversely, employing data augmentation, both basic and deep learning based, lowers the f1 score to and respectively, yet it results in a more balanced distribution of true positives across disease classes. the findings suggest that smote surpasses the other methods in handling imbalanced data.",,"cassava diseases classification using efficientnet model with imbalance data handling. this research highlights the urgent need for classifying cassava diseases into five classes, such as cassava bacterial blight cbb , cassava brown streak disease cbsd , cassava green mottle cgm , and cassava mosaic disease cmd , and healthy. the study proposes the utilization of the efficientnet model, a lightweight deep learning architecture, for classifying cassava diseases based on leaf images. however, the datasets available for this classification task are all unbalanced, made it difficult for researchers to perform. to tackle this imbalance issue, the authors compared several imbalance data handling methods commonly used for image classification, including smote synthetic minority oversampling technique , basic augmentation, and neural style transfer, to be applied before fed into efficientnet. initially, efficientnet model without addressing dataset imbalances, the f1 score stands at , with most images misclassified into the majority class. integration with smote notably boosts the f1 score to , showcasing the efficacy of oversampling methods in enhancing model performance. conversely, employing data augmentation, both basic and deep learning based, lowers the f1 score to and respectively, yet it results in a more balanced distribution of true positives across disease classes. the findings suggest that smote surpasses the other methods in handling imbalanced data."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1305,strengthening the authentication mechanism of blockchain based e voting system using post quantum cryptography,"election systems often face severe challenges regarding security and trust. threats such as vote falsification and lack of transparency in vote counting have shaken the integrity of elections in various countries. the use of blockchain technology in e voting has been proposed as an attractive solution to overcome this problem. several studies use blockchain for the security of electronic voting systems. the existing methods are not resistant against impersonation attacks and man in the middle attacks. this research proposes a new scheme to strengthen a blockchain based e voting system. the blockchain used in the proposed method is ethereum. the proposed scheme uses the modified framework and the goldreich goldwasser halevi ggh signature scheme. digital signatures generated using goldreich goldwasser halevi ggh can strengthen the identity of the message sender so that enemies cannot imitate someone. in this research, the voter s public key and anonymous id are used by the voter to maintain the voter s anonymity. based on the experimental results, it can be concluded that the proposed scheme is stronger than the previous scheme because the probability of success in impersonating the sender with the proposed scheme using an impersonation attack and man in the middle attack is small.",,"strengthening the authentication mechanism of blockchain based e voting system using post quantum cryptography. election systems often face severe challenges regarding security and trust. threats such as vote falsification and lack of transparency in vote counting have shaken the integrity of elections in various countries. the use of blockchain technology in e voting has been proposed as an attractive solution to overcome this problem. several studies use blockchain for the security of electronic voting systems. the existing methods are not resistant against impersonation attacks and man in the middle attacks. this research proposes a new scheme to strengthen a blockchain based e voting system. the blockchain used in the proposed method is ethereum. the proposed scheme uses the modified framework and the goldreich goldwasser halevi ggh signature scheme. digital signatures generated using goldreich goldwasser halevi ggh can strengthen the identity of the message sender so that enemies cannot imitate someone. in this research, the voter s public key and anonymous id are used by the voter to maintain the voter s anonymity. based on the experimental results, it can be concluded that the proposed scheme is stronger than the previous scheme because the probability of success in impersonating the sender with the proposed scheme using an impersonation attack and man in the middle attack is small."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1324,catboost optimization using recursive feature elimination,"catboost is a powerful machine learning algorithm capable of classification and regression application. there are many studies focusing on its application but are still lacking on how to enhance its performance, especially when using rfe as a feature selection. this study examines the catboost optimization for regression tasks by using recursive feature elimination rfe for feature selection in combination with several regression algorithm. furthermore, an isolation forest algorithm is employed at preprocessing to identify and eliminate outliers from the dataset. the experiment is conducted by comparing the catboost regression model s performances with and without the use of rfe feature selection. the outcomes of the experiments indicate that catboost with rfe, which selects features using random forests, performs better than the baseline model without feature selection. catboost rfe outperformed the baseline with notable gains of over . in training time, . in rmse score, and . in r2 score. furthermore, compared to adaboost, gradient boosting, xgboost, and artificial neural networks ann , it demonstrated better prediction accuracy. the catboost improvement has a substantial implication for predicting the exhaust temperature in a coal fired power plant.",,"catboost optimization using recursive feature elimination. catboost is a powerful machine learning algorithm capable of classification and regression application. there are many studies focusing on its application but are still lacking on how to enhance its performance, especially when using rfe as a feature selection. this study examines the catboost optimization for regression tasks by using recursive feature elimination rfe for feature selection in combination with several regression algorithm. furthermore, an isolation forest algorithm is employed at preprocessing to identify and eliminate outliers from the dataset. the experiment is conducted by comparing the catboost regression model s performances with and without the use of rfe feature selection. the outcomes of the experiments indicate that catboost with rfe, which selects features using random forests, performs better than the baseline model without feature selection. catboost rfe outperformed the baseline with notable gains of over . in training time, . in rmse score, and . in r2 score. furthermore, compared to adaboost, gradient boosting, xgboost, and artificial neural networks ann , it demonstrated better prediction accuracy. the catboost improvement has a substantial implication for predicting the exhaust temperature in a coal fired power plant."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1327,the effect of the number of nodes on data communication performance in nomad clusters using the gossip protocol,"this research aims to understand the effect of the number of nodes on the performance of data communication in nomad clusters using the gossip protocol. through a series of tests, it can be concluded that data communication performance is greatly affected by the number of nodes in the cluster. tests were conducted using two clusters, where one cluster consists of three nodes. the results show that when using a cluster with three nodes, no packet loss occurs in all data transmissions performed, indicating a reliable communication system. the average latency in one data communication cycle varied in each test, but generally remained within the acceptable range of below 100ms based on data communication quality of service parameters. cpu and disc usage remained relatively stable throughout the experiment. although there were slight differences in throughput between clusters, the throughput generally remained above mbps, which is still in the good category according to the research parameters. these results show the importance of taking into account the number of nodes in the cluster in designing and managing data communication systems in a nomad cluster environment with the gossip protocol.",,"the effect of the number of nodes on data communication performance in nomad clusters using the gossip protocol. this research aims to understand the effect of the number of nodes on the performance of data communication in nomad clusters using the gossip protocol. through a series of tests, it can be concluded that data communication performance is greatly affected by the number of nodes in the cluster. tests were conducted using two clusters, where one cluster consists of three nodes. the results show that when using a cluster with three nodes, no packet loss occurs in all data transmissions performed, indicating a reliable communication system. the average latency in one data communication cycle varied in each test, but generally remained within the acceptable range of below 100ms based on data communication quality of service parameters. cpu and disc usage remained relatively stable throughout the experiment. although there were slight differences in throughput between clusters, the throughput generally remained above mbps, which is still in the good category according to the research parameters. these results show the importance of taking into account the number of nodes in the cluster in designing and managing data communication systems in a nomad cluster environment with the gossip protocol."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1328,machine learning monitoring model for fertilization and irrigation to support sustainable cassava production systematic literature review,"the manual and time consuming nature of current agronomic technology monitoring of fertilizer and irrigation requirements, the possibility of overusing fertilizer and water, the size of cassava plantations, and the scarcity of human resources are among its drawbacks. efforts to increase the yield of cassava plants tons per ha include monitoring fertilization approach or treatment, as well as water stress or drought using uavs and deep learning. the novel aspect of this research is the creation of a monitoring model for the irrigation and fertilizer to support sustainable cassava production. this study emphasizes the use of unnamed aerial vehicle uav imagery for evaluating the irrigation and fertilization status of cassava crops. the uav is processed by building an orthomosaic, labeling, extracting features, and convolutional neural network cnn modeling. the outcomes are then analyzed to determine the requirements for air pressure and fertilization. important new information on the application of uav technology, multispectral imaging, thermal imaging, among the vegetation indices are the soil adjusted vegetation index savi , leaf color index lci , leaf area index lai , normalized difference water index ndwi , normalized difference red edge index ndre , and green normalized difference vegetation index gndvi .",,"machine learning monitoring model for fertilization and irrigation to support sustainable cassava production systematic literature review. the manual and time consuming nature of current agronomic technology monitoring of fertilizer and irrigation requirements, the possibility of overusing fertilizer and water, the size of cassava plantations, and the scarcity of human resources are among its drawbacks. efforts to increase the yield of cassava plants tons per ha include monitoring fertilization approach or treatment, as well as water stress or drought using uavs and deep learning. the novel aspect of this research is the creation of a monitoring model for the irrigation and fertilizer to support sustainable cassava production. this study emphasizes the use of unnamed aerial vehicle uav imagery for evaluating the irrigation and fertilization status of cassava crops. the uav is processed by building an orthomosaic, labeling, extracting features, and convolutional neural network cnn modeling. the outcomes are then analyzed to determine the requirements for air pressure and fertilization. important new information on the application of uav technology, multispectral imaging, thermal imaging, among the vegetation indices are the soil adjusted vegetation index savi , leaf color index lci , leaf area index lai , normalized difference water index ndwi , normalized difference red edge index ndre , and green normalized difference vegetation index gndvi ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1329,"wave downscaling approach with tcn model, case study in bengkulu, indonesia","when conducting marine operations that rely on wave conditions, such as maritime trade, the fishing industry, and ocean energy, accurate wave downscaling is important, especially in coastal locations with complicated geometries. traditional approaches for wave downscaling are usually obtained by performing nested simulations on a high resolution local grid from global grid information. however, this approach requires high computation resources. in this paper, to downscale global wave height data into a high resolution local wave height with less computation resources, we propose a machine learning based approach to downscaling using the temporal convolutional network tcn model. to train the model, we obtain the wave dataset using the swan model in a local domain. the global datasets are taken from the ecmwf reanalysis era and used to train the model. we choose the coastal area of bengkulu, indonesia, as a case study. the results of tcn are also compared with other models such as lstm and transformers. it showed that tcn demonstrated superior performance with a cc of . , rmse of . , and mape of . , outperforming the other models in terms of accuracy and computational efficiency. it proves that our tcn model can be alternative model to downscale in bengkulus coastal area.",,"wave downscaling approach with tcn model, case study in bengkulu, indonesia. when conducting marine operations that rely on wave conditions, such as maritime trade, the fishing industry, and ocean energy, accurate wave downscaling is important, especially in coastal locations with complicated geometries. traditional approaches for wave downscaling are usually obtained by performing nested simulations on a high resolution local grid from global grid information. however, this approach requires high computation resources. in this paper, to downscale global wave height data into a high resolution local wave height with less computation resources, we propose a machine learning based approach to downscaling using the temporal convolutional network tcn model. to train the model, we obtain the wave dataset using the swan model in a local domain. the global datasets are taken from the ecmwf reanalysis era and used to train the model. we choose the coastal area of bengkulu, indonesia, as a case study. the results of tcn are also compared with other models such as lstm and transformers. it showed that tcn demonstrated superior performance with a cc of . , rmse of . , and mape of . , outperforming the other models in terms of accuracy and computational efficiency. it proves that our tcn model can be alternative model to downscale in bengkulus coastal area."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1195,comparison of efficientnetb0 and efficientnetb7 models in classifying malaria based on blood cells,"malaria is a disease caused by the bite of malaria mosquitoes, which spreads through blood. malaria mosquitoes will spread the plasmodium parasite through their bites. early malaria identification is essential so the disease can be prevented immediately. through data science, which utilizes the cnn model, the classification of blood infected with parasites can be predicted accurately. this research uses data obtained from kaggle website with , image samples. the data is divided into two classes, parasite infected and uninfected, which are then divided again into two types. the first class is training data divided into of the total data and the other as validation data. this research used two test scenarios to obtain a more effective classification model. the first scenario uses hyperparameter tuning and the efficientnetb0 model with classification results of . meanwhile, the classification achievement for scenario two was by utilizing efficientnetb7.",,"comparison of efficientnetb0 and efficientnetb7 models in classifying malaria based on blood cells. malaria is a disease caused by the bite of malaria mosquitoes, which spreads through blood. malaria mosquitoes will spread the plasmodium parasite through their bites. early malaria identification is essential so the disease can be prevented immediately. through data science, which utilizes the cnn model, the classification of blood infected with parasites can be predicted accurately. this research uses data obtained from kaggle website with , image samples. the data is divided into two classes, parasite infected and uninfected, which are then divided again into two types. the first class is training data divided into of the total data and the other as validation data. this research used two test scenarios to obtain a more effective classification model. the first scenario uses hyperparameter tuning and the efficientnetb0 model with classification results of . meanwhile, the classification achievement for scenario two was by utilizing efficientnetb7."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1321,"enhancing remote sensing image quality through data fusion and synthetic aperture radar sar a comparative analysis of cnn, lightweight convnet, and vgg16 models","remote sensing technology benefits many parties, especially for carrying out land surveillance with comprehensive coverage without needing to move the equipment close to photograph the area. however, this technology needs to improve the image quality depends on natural conditions, so objects such as fog, clouds, and smoke can interfere with the image results. this study uses data fusion techniques to enhance the quality of remote sensing images affected by natural conditions. the method involves using synthetic aperture radar sar to combine adjacent satellite images from different viewpoints, thereby improving image coverage. three image classification models were evaluated to process the fused data convolutional neural network cnn , lightweight convnet, and visual geometry group vgg16 . the results indicate that all three models achieve similar accuracy and execution speed, namely . , with vgg16 demonstrating a slight superiority over the others, namely . .",,"enhancing remote sensing image quality through data fusion and synthetic aperture radar sar a comparative analysis of cnn, lightweight convnet, and vgg16 models. remote sensing technology benefits many parties, especially for carrying out land surveillance with comprehensive coverage without needing to move the equipment close to photograph the area. however, this technology needs to improve the image quality depends on natural conditions, so objects such as fog, clouds, and smoke can interfere with the image results. this study uses data fusion techniques to enhance the quality of remote sensing images affected by natural conditions. the method involves using synthetic aperture radar sar to combine adjacent satellite images from different viewpoints, thereby improving image coverage. three image classification models were evaluated to process the fused data convolutional neural network cnn , lightweight convnet, and visual geometry group vgg16 . the results indicate that all three models achieve similar accuracy and execution speed, namely . , with vgg16 demonstrating a slight superiority over the others, namely . ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1385,evaluating readiness and acceptance of artificial intelligence adoption among elementary school teachers,"artificial intelligence ai is a computer system that mimics the human brain s ability to process information and make decisions. ai technology is used to learn patterns in data and make predictions or decisions based on that learning. despite the potential benefits of ai in education, elementary school teachers face significant challenges in adopting ai technology due to limited training, lack of resources, and resistance to change. this research aims to identify the factors influencing the adoption of ai technology among primary school teachers in west java, indonesia. the study involved participants and employed a quantitative approach. specific factors influencing ai adoption were identified by developing a model for ai based teaching and learning and assessing readiness factors. the results identified optimism, innovativeness, insecurity, discomfort, perceived validity, trust, usefulness, and ease of use as critical factors for successful ai adoption among primary school teachers in west java. the customized adoption model provides a practical roadmap for integrating ai into teaching and learning processes, addressing regional specificities while remaining relevant to similar educational challenges worldwide. the assessment of readiness factors offers actionable insights for fostering a supportive environment for technology integration. the study concludes with recommendations for future research and implications for educators, administrators, and policymakers.",,"evaluating readiness and acceptance of artificial intelligence adoption among elementary school teachers. artificial intelligence ai is a computer system that mimics the human brain s ability to process information and make decisions. ai technology is used to learn patterns in data and make predictions or decisions based on that learning. despite the potential benefits of ai in education, elementary school teachers face significant challenges in adopting ai technology due to limited training, lack of resources, and resistance to change. this research aims to identify the factors influencing the adoption of ai technology among primary school teachers in west java, indonesia. the study involved participants and employed a quantitative approach. specific factors influencing ai adoption were identified by developing a model for ai based teaching and learning and assessing readiness factors. the results identified optimism, innovativeness, insecurity, discomfort, perceived validity, trust, usefulness, and ease of use as critical factors for successful ai adoption among primary school teachers in west java. the customized adoption model provides a practical roadmap for integrating ai into teaching and learning processes, addressing regional specificities while remaining relevant to similar educational challenges worldwide. the assessment of readiness factors offers actionable insights for fostering a supportive environment for technology integration. the study concludes with recommendations for future research and implications for educators, administrators, and policymakers."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1076,detection of drowsiness in drivers using image processing and support vector machine svm classification,"accidents can be caused by external factors on the road, vehicle conditions, or internal factors such as drowsiness. drowsiness while driving poses risks to the driver and others. an early detection system is crucial to alert drivers to stop or rest if they show signs of drowsiness. physical signs of drowsiness include a lethargic facial expression, frequent eye blinking, continuous yawning, or nodding off. a detection system utilizing image processing and machine learning can observe these signs by detecting facial landmarks and analyzing activities such as eye blinking, yawning, and head tilt. this study aims to classify the drowsiness condition based on these three factors. the classification process is conducted using machine learning with the support vector machine svm method to determine whether a person is drowsy or not. the dataset consists of the number of eye blinks, head tilts, and yawns. conditions are classified into two classes, drowsy and not drowsy. in this study, the svm classification method can predict drowsiness with an accuracy of up to in the conducted tests.",,"detection of drowsiness in drivers using image processing and support vector machine svm classification. accidents can be caused by external factors on the road, vehicle conditions, or internal factors such as drowsiness. drowsiness while driving poses risks to the driver and others. an early detection system is crucial to alert drivers to stop or rest if they show signs of drowsiness. physical signs of drowsiness include a lethargic facial expression, frequent eye blinking, continuous yawning, or nodding off. a detection system utilizing image processing and machine learning can observe these signs by detecting facial landmarks and analyzing activities such as eye blinking, yawning, and head tilt. this study aims to classify the drowsiness condition based on these three factors. the classification process is conducted using machine learning with the support vector machine svm method to determine whether a person is drowsy or not. the dataset consists of the number of eye blinks, head tilts, and yawns. conditions are classified into two classes, drowsy and not drowsy. in this study, the svm classification method can predict drowsiness with an accuracy of up to in the conducted tests."
https://join.if.uinsgd.ac.id/index.php/join/article/view/941,identification of inpari hdb superior rice seeds based on android in realtime with artificial neural network,"rice is a staple food for humans living in east asia. rice is a crystal fruit. the latin name for rice is oryza sativa. rice plants are days old. the selection of quality rice seeds by farmers is seen from the bright yellow color of the rice without black brown spots, its large size and rounder. rice seeds that are not of good quality are dark brown in color, have black brown spots, and are flat in shape. the absence of superior rice recognition technology that is not android based in real time is the main reason for this research. the focus of this research is to identify superior and non superior rice in inpari hdb rice with a high recognition accuracy rate of more than percent with a viewing angle of degrees using the real time ann method. the training data used in this research was datasets consisting of superior rice datasets and non superior datasets. the smart model for classifying rice seeds that has been built in this research is generally able to run well where the classification accuracy obtained is quite good. the classification accuracy of the ann model during training of the neural network model was able to classify rice seeds with an accuracy of with the confidence value of the real time classification results ranging from . real time classification of rice grains with maximum accuracy of and many grains .",,"identification of inpari hdb superior rice seeds based on android in realtime with artificial neural network. rice is a staple food for humans living in east asia. rice is a crystal fruit. the latin name for rice is oryza sativa. rice plants are days old. the selection of quality rice seeds by farmers is seen from the bright yellow color of the rice without black brown spots, its large size and rounder. rice seeds that are not of good quality are dark brown in color, have black brown spots, and are flat in shape. the absence of superior rice recognition technology that is not android based in real time is the main reason for this research. the focus of this research is to identify superior and non superior rice in inpari hdb rice with a high recognition accuracy rate of more than percent with a viewing angle of degrees using the real time ann method. the training data used in this research was datasets consisting of superior rice datasets and non superior datasets. the smart model for classifying rice seeds that has been built in this research is generally able to run well where the classification accuracy obtained is quite good. the classification accuracy of the ann model during training of the neural network model was able to classify rice seeds with an accuracy of with the confidence value of the real time classification results ranging from . real time classification of rice grains with maximum accuracy of and many grains ."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1113,prediction of solar radiation data for garlic production in magelang regency using long short term memory,"garlic importation in indonesia is frequently carried out to meet the high domestic market demand. to reduce dependency on imports, the development of local garlic production is crucial. this study aims to determine the optimal solar radiation for garlic growth using the long short term memory lstm algorithm. this algorithm was selected due to its ability to analyze time series data and predict long term patterns. the lstm model was trained with the adam optimizer, using a configuration of epochs, a batch size of , and a dropout rate of . to prevent overfitting. the model evaluation results show an indicating good accuracy with a rmse of . , a mean squared error mse of . , and a correlation coefficient of . , although it still has limitations in capturing extreme data fluctuations. the study found that in magelang regency especially in the sub districts of windusari, grabag, ngablak, pakis, dukun, kaliangkrik, and kajoran have optimal solar radiation for garlic cultivation between march and may, with a radiation range of w m to w m. these findings provide valuable guidance for farmers in determining the optimal planting period, potentially enhancing local garlic production and reducing import dependency.",,"prediction of solar radiation data for garlic production in magelang regency using long short term memory. garlic importation in indonesia is frequently carried out to meet the high domestic market demand. to reduce dependency on imports, the development of local garlic production is crucial. this study aims to determine the optimal solar radiation for garlic growth using the long short term memory lstm algorithm. this algorithm was selected due to its ability to analyze time series data and predict long term patterns. the lstm model was trained with the adam optimizer, using a configuration of epochs, a batch size of , and a dropout rate of . to prevent overfitting. the model evaluation results show an indicating good accuracy with a rmse of . , a mean squared error mse of . , and a correlation coefficient of . , although it still has limitations in capturing extreme data fluctuations. the study found that in magelang regency especially in the sub districts of windusari, grabag, ngablak, pakis, dukun, kaliangkrik, and kajoran have optimal solar radiation for garlic cultivation between march and may, with a radiation range of w m to w m. these findings provide valuable guidance for farmers in determining the optimal planting period, potentially enhancing local garlic production and reducing import dependency."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1318,predictive performance evaluation of arima and hybrid arima lstm models for particulate matter concentration,"this study provides an objective evaluation of prediction performance models for particulate matter policy for industrial stakeholders by comparing the arima and hybrid arima lstm models for predicting air quality data from the industrial environment. in the case of pm . concentration, we have an rmse value of . and an error ratio of . for the arima model and an rmse value of . and an error ratio of . for the hybrid arima lstm model. meanwhile, for pm . concentration, we obtain an rmse value of . , an error ratio of . for the arima model, an rmse value of . , and an error ratio of . for the hybrid arima lstm model. according to this study, the arima model, which is found in autoarima and represents the best model, is , , for pm1. and , , for pm2. . the hybrid arima lstm model outperforms the arima model in terms of prediction accuracy, as evidenced by the rmse and error ratio values, which are improved by approximately . and . for pm1. and . and . for pm2. , respectively, since the hybrid arima lstm model can accommodate variable length sequences and capture long term relationships to become noise resistant, which makes higher prediction accuracy possible.",,"predictive performance evaluation of arima and hybrid arima lstm models for particulate matter concentration. this study provides an objective evaluation of prediction performance models for particulate matter policy for industrial stakeholders by comparing the arima and hybrid arima lstm models for predicting air quality data from the industrial environment. in the case of pm . concentration, we have an rmse value of . and an error ratio of . for the arima model and an rmse value of . and an error ratio of . for the hybrid arima lstm model. meanwhile, for pm . concentration, we obtain an rmse value of . , an error ratio of . for the arima model, an rmse value of . , and an error ratio of . for the hybrid arima lstm model. according to this study, the arima model, which is found in autoarima and represents the best model, is , , for pm1. and , , for pm2. . the hybrid arima lstm model outperforms the arima model in terms of prediction accuracy, as evidenced by the rmse and error ratio values, which are improved by approximately . and . for pm1. and . and . for pm2. , respectively, since the hybrid arima lstm model can accommodate variable length sequences and capture long term relationships to become noise resistant, which makes higher prediction accuracy possible."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1326,file integrity monitoring as a method for detecting and preventing web defacement attacks,"the cybersecurity landscape in indonesia recorded an increase in cyberattacks in . one of the types of attacks observed was web defacement attacks targeting government websites. in , there were a total of , web defacement attacks in indonesia, with the majority occurring in the governmental sector. in proactive efforts to monitor and prevent web defacement attacks, this study implemented the open source tool wazuh and activated the file integrity monitoring module to detect file changes in the system. testing was conducted with two types of attacks brute force attacks to gain system access and web defacement attacks involving script insertion to trigger alerts from the file integrity monitoring. the results of the testing show that the implementation of wazuh and the file integrity monitoring module can real time detect malicious activities and file additions, so that it can be used to mitigate cyberattacks.",,"file integrity monitoring as a method for detecting and preventing web defacement attacks. the cybersecurity landscape in indonesia recorded an increase in cyberattacks in . one of the types of attacks observed was web defacement attacks targeting government websites. in , there were a total of , web defacement attacks in indonesia, with the majority occurring in the governmental sector. in proactive efforts to monitor and prevent web defacement attacks, this study implemented the open source tool wazuh and activated the file integrity monitoring module to detect file changes in the system. testing was conducted with two types of attacks brute force attacks to gain system access and web defacement attacks involving script insertion to trigger alerts from the file integrity monitoring. the results of the testing show that the implementation of wazuh and the file integrity monitoring module can real time detect malicious activities and file additions, so that it can be used to mitigate cyberattacks."
https://join.if.uinsgd.ac.id/index.php/join/article/view/1349,reviewing the framework of blockchain in fake news detection,"in the social media environment, fake news is a significant issue. it might be online or offline, depending on the field of journalism. concerns have been expressed by media and publishing houses, who are looking for solutions to the problem. one of the solutions the industry has to offer in this area is blockchain. it could be digital security trading, source or identity verification, or quotes following a certain news piece, photo, or video. it s miles of shared document generation to deliver timely files, and it s done with the help of a specific article, video, or image that has been addressed. this will no longer assist the fact abuser in verifying the details. this will help the fact abuser confirm the details, but it will also offer documentation of metadata generated at all phases. it allows you to cut the expense of disseminating false information by forwarding and explicit disclosure to persons who have first hand knowledge of the subject. the proposed structure for acquiring fake news is supported by the blockchain age, which allows news organizations to deliver their content to their subscribers transparently. this framework was created for journalists and can be integrated into any current platform to publish a news piece and include asset statistics.",,"reviewing the framework of blockchain in fake news detection. in the social media environment, fake news is a significant issue. it might be online or offline, depending on the field of journalism. concerns have been expressed by media and publishing houses, who are looking for solutions to the problem. one of the solutions the industry has to offer in this area is blockchain. it could be digital security trading, source or identity verification, or quotes following a certain news piece, photo, or video. it s miles of shared document generation to deliver timely files, and it s done with the help of a specific article, video, or image that has been addressed. this will no longer assist the fact abuser in verifying the details. this will help the fact abuser confirm the details, but it will also offer documentation of metadata generated at all phases. it allows you to cut the expense of disseminating false information by forwarding and explicit disclosure to persons who have first hand knowledge of the subject. the proposed structure for acquiring fake news is supported by the blockchain age, which allows news organizations to deliver their content to their subscribers transparently. this framework was created for journalists and can be integrated into any current platform to publish a news piece and include asset statistics."
